INFO  - 2020-01-12 15:08:15.097; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-01-12 15:08:15.469; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-01-12 15:08:15.949; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-01-12 15:08:16.788; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-01-12 15:08:16.895; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-01-12 15:08:16.896; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-01-12 15:08:16.905; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
WARN  - 2020-01-12 15:08:19.195; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2020-01-12 15:08:20.416; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
WARN  - 2020-01-12 15:08:21.283; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:08:23.397; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2020-01-12 15:08:23.506; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 8404 ms
INFO  - 2020-01-12 15:08:23.761; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-01-12 15:08:23.988; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-01-12 15:08:24.274; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-01-12 15:08:24.794; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1033 ms
WARN  - 2020-01-12 15:08:25.672; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:08:28.401; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:08:31.457; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:08:34.500; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:08:37.466; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:08:40.277; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:08:43.499; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:08:46.589; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:08:49.512; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:08:52.678; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:08:55.693; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:08:58.863; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:09:02.029; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:09:04.855; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:09:07.923; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:09:10.852; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:09:14.085; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:09:17.088; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:09:20.202; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:09:23.316; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:09:26.289; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:09:29.203; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:09:32.270; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2020-01-12 15:09:32.982; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
WARN  - 2020-01-12 15:09:35.412; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:09:38.544; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:09:41.630; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:09:44.749; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:09:47.671; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:09:50.653; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:09:53.623; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:09:56.849; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:10:00.064; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:10:02.984; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:10:06.094; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:10:09.261; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:10:12.325; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:10:15.240; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:10:18.404; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:10:21.569; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:10:24.791; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:10:27.864; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:10:30.997; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:10:33.823; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:10:36.853; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:10:39.875; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:10:42.854; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:10:45.917; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:10:48.777; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:10:51.844; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:10:54.910; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:10:57.979; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:11:00.983; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:11:03.845; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:11:06.756; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:11:09.870; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:11:12.836; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:11:15.964; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:11:19.039; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:11:22.204; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:11:25.337; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:11:28.306; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:11:31.479; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:11:34.340; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:11:37.454; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:11:40.617; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:11:43.730; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:11:46.593; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:11:49.656; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:11:52.532; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:11:55.751; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:11:58.916; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:12:02.033; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:12:04.995; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:12:08.130; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:12:11.396; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:12:14.354; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:12:17.216; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:12:20.129; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:12:23.291; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:12:26.153; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:12:29.114; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:12:32.280; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:12:35.191; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:12:38.201; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:12:41.064; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:12:43.930; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:12:46.890; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:12:49.855; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:12:52.766; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:12:55.692; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:12:58.705; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:13:01.868; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:13:04.883; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:13:07.999; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:13:11.189; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:13:14.354; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:13:17.264; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:13:20.226; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:13:23.160; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:13:26.153; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:13:29.263; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:13:32.343; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:13:35.301; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:13:38.398; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:13:41.720; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:13:44.560; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:13:47.746; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:13:50.934; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:13:54.117; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:13:57.134; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:14:00.047; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:14:02.909; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:14:05.908; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:14:09.119; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:14:12.230; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:14:15.394; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:14:18.369; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:14:21.484; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:14:24.651; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:14:27.608; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:14:30.521; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:14:33.521; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:14:36.737; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:14:39.918; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:14:42.970; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:14:45.982; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:14:49.042; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:14:52.202; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:14:55.286; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:14:58.403; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:15:01.418; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:15:04.482; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:15:07.342; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:15:10.258; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:15:13.425; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:15:16.537; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:15:19.653; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:15:22.778; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:15:25.931; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:15:29.144; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:15:32.003; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:15:35.035; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:15:38.203; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:15:41.417; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:15:44.430; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:15:47.443; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:15:50.507; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:15:53.466; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:15:56.530; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:15:59.492; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:16:02.694; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:16:05.770; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:16:09.001; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:16:12.184; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:16:15.403; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:16:18.509; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:16:21.442; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:16:24.485; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:16:27.427; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:16:30.523; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:16:33.554; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:16:36.576; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:16:39.839; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-01-12 15:16:42.806; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2020-01-12 15:16:47.438; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-01-12 15:16:47.578; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-01-12 15:16:47.583; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-01-12 15:16:47.584; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-01-12 15:16:47.585; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-01-12 15:16:47.728; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2020-01-12 15:16:47.849; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-01-12 15:16:47.849; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2020-01-12 15:16:47.964; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-01-12 15:16:47.965; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-01-12 15:16:47.975; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2020-01-12 15:16:48.090; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-01-12 15:16:48.090; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2020-01-12 15:16:48.196; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-01-12 15:16:48.197; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-01-12 15:16:48.233; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2020-01-12 15:16:48.344; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-01-12 15:16:48.344; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2020-01-12 15:16:48.451; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-01-12 15:16:48.452; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-01-12 15:16:48.492; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2020-01-12 15:16:48.621; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-01-12 15:16:48.621; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2020-01-12 15:16:48.733; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-01-12 15:16:48.734; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-01-12 15:16:48.784; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2020-01-12 15:16:48.889; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-01-12 15:16:48.889; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2020-01-12 15:16:48.993; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-01-12 15:16:48.994; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-01-12 15:16:49.025; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2020-01-12 15:16:49.143; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-01-12 15:16:49.144; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2020-01-12 15:16:49.251; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-01-12 15:16:49.252; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-01-12 15:16:50.189; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 1
INFO  - 2020-01-12 15:16:50.192; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-01-12 15:16:50.192; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-01-12 15:16:51.199; org.apache.kafka.clients.consumer.internals.Fetcher; [Consumer clientId=consumer-1, groupId=test-consumer-group] Resetting offset for partition 1708E-0 to offset 6.
INFO  - 2020-01-12 15:17:50.707; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-01-12 15:17:50.726; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-01-12 15:17:50.738; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-01-12 15:17:50.738; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-01-12 15:17:56.630; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-01-12 15:17:56.874; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-01-12 15:17:57.329; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-01-12 15:17:58.118; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-01-12 15:17:58.214; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-01-12 15:17:58.214; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-01-12 15:17:58.222; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-01-12 15:17:58.492; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-01-12 15:17:58.495; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-01-12 15:17:58.500; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-01-12 15:17:58.500; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-01-12 15:17:58.500; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-01-12 15:17:58.552; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 3
INFO  - 2020-01-12 15:17:58.558; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-01-12 15:17:58.559; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-01-12 15:18:01.373; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-01-12 15:18:03.887; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 7254 ms
INFO  - 2020-01-12 15:18:04.091; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-01-12 15:18:04.318; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-01-12 15:18:04.553; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-01-12 15:18:05.396; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1304 ms
INFO  - 2020-01-12 15:18:10.924; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-01-12 15:18:10.935; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-01-12 15:18:10.937; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-01-12 15:18:14.812; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-01-12 15:18:15.076; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-01-12 15:18:15.570; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-01-12 15:18:16.334; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-01-12 15:18:16.428; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-01-12 15:18:16.428; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-01-12 15:18:16.437; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-01-12 15:18:16.665; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-01-12 15:18:16.669; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-01-12 15:18:16.673; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-01-12 15:18:16.673; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-01-12 15:18:16.674; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-01-12 15:18:16.699; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 5
INFO  - 2020-01-12 15:18:16.702; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-01-12 15:18:16.702; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-01-12 15:18:19.506; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-01-12 15:18:22.095; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 7278 ms
INFO  - 2020-01-12 15:18:22.283; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-01-12 15:18:22.473; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-01-12 15:18:22.733; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-01-12 15:18:23.070; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 787 ms
INFO  - 2020-01-12 15:18:42.289; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-01-12 15:32:52.055; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-01-12 15:32:52.061; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-01-12 15:32:52.075; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-01-12 15:32:52.076; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-01-12 15:32:57.992; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-01-12 15:32:58.217; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-01-12 15:32:58.667; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-01-12 15:32:59.421; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-01-12 15:32:59.509; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-01-12 15:32:59.510; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-01-12 15:32:59.518; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-01-12 15:32:59.739; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-01-12 15:32:59.744; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-01-12 15:32:59.748; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-01-12 15:32:59.749; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-01-12 15:32:59.749; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-01-12 15:32:59.765; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 7
INFO  - 2020-01-12 15:32:59.767; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-01-12 15:32:59.767; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-01-12 15:33:03.462; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-01-12 15:33:06.065; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 8069 ms
INFO  - 2020-01-12 15:33:06.269; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-01-12 15:33:06.495; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-01-12 15:33:06.756; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-01-12 15:33:07.113; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 844 ms
INFO  - 2020-01-12 15:33:08.633; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-01-12 15:33:08.639; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-01-12 15:33:08.640; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-01-12 15:33:12.635; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-01-12 15:33:13.054; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-01-12 15:33:13.522; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-01-12 15:33:14.300; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-01-12 15:33:14.391; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-01-12 15:33:14.391; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-01-12 15:33:14.399; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-01-12 15:33:14.648; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-01-12 15:33:14.651; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-01-12 15:33:14.658; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-01-12 15:33:14.658; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-01-12 15:33:14.659; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-01-12 15:33:14.680; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 9
INFO  - 2020-01-12 15:33:14.683; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-01-12 15:33:14.683; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-01-12 15:33:17.654; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-01-12 15:33:20.234; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 7595 ms
INFO  - 2020-01-12 15:33:20.432; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-01-12 15:33:20.659; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-01-12 15:33:20.912; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-01-12 15:33:21.313; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 881 ms
INFO  - 2020-01-12 15:33:24.236; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-01-12 15:33:24.241; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-01-12 15:33:24.243; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-01-12 15:33:29.861; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-01-12 15:33:30.084; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-01-12 15:33:30.527; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-01-12 15:33:31.490; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-01-12 15:33:31.580; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-01-12 15:33:31.580; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-01-12 15:33:31.589; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-01-12 15:33:31.838; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-01-12 15:33:31.840; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-01-12 15:33:31.845; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-01-12 15:33:31.846; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-01-12 15:33:31.846; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-01-12 15:33:31.993; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 11
INFO  - 2020-01-12 15:33:31.996; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-01-12 15:33:31.996; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-01-12 15:33:35.268; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-01-12 15:33:38.566; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 8702 ms
INFO  - 2020-01-12 15:33:38.781; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-01-12 15:33:39.423; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-01-12 15:33:44.470; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-01-12 15:33:48.757; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 9975 ms
INFO  - 2020-01-12 15:33:51.469; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-01-12 15:33:51.474; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-01-12 15:33:51.475; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-01-12 15:34:14.615; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
ERROR - 2020-01-12 15:34:15.048; org.springframework.web.context.ContextLoader; Context initialization failed
java.lang.OutOfMemoryError: GC overhead limit exceeded
INFO  - 2020-02-12 11:54:55.895; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 11:54:56.307; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 11:54:56.987; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 11:54:57.835; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 11:54:57.960; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 11:54:57.961; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 11:54:57.974; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 11:54:58.477; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 11:54:58.480; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 11:54:58.486; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 11:54:58.487; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 11:54:58.487; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 11:54:58.678; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 13
INFO  - 2020-02-12 11:54:58.680; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 11:54:58.680; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 11:55:01.194; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 11:55:04.167; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 8268 ms
INFO  - 2020-02-12 11:55:04.915; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 11:55:05.242; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 11:55:06.113; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 11:55:06.526; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1610 ms
INFO  - 2020-02-12 11:55:19.030; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-12 12:46:59.555; org.apache.kafka.clients.FetchSessionHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 0: org.apache.kafka.common.errors.DisconnectException.
INFO  - 2020-02-12 12:46:59.557; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
WARN  - 2020-02-12 13:04:26.855; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
INFO  - 2020-02-12 13:04:26.991; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
ERROR - 2020-02-12 13:04:27.092; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetCommitResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Offset commit failed on partition 1708E-0 at offset 6: The coordinator is not aware of this member.
WARN  - 2020-02-12 13:04:27.095; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$4; [Consumer clientId=consumer-1, groupId=test-consumer-group] Asynchronous auto-commit of offsets {1708E-0=OffsetAndMetadata{offset=6, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
WARN  - 2020-02-12 13:04:27.095; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Synchronous auto-commit of offsets {1708E-0=OffsetAndMetadata{offset=6, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
INFO  - 2020-02-12 13:04:27.095; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions [1708E-0]
INFO  - 2020-02-12 13:04:27.095; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: [1708E-0]
INFO  - 2020-02-12 13:04:27.095; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 13:04:27.216; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 15
INFO  - 2020-02-12 13:04:27.216; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 13:04:27.216; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 13:04:29.420; org.apache.kafka.clients.FetchSessionHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 0: org.apache.kafka.common.errors.DisconnectException.
INFO  - 2020-02-12 13:04:29.445; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
WARN  - 2020-02-12 13:04:44.003; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:04:46.123; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:04:48.340; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:04:50.771; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:04:53.656; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:04:56.582; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:04:59.516; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:05:02.437; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:05:05.524; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:05:08.596; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:05:11.580; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:05:14.453; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:05:17.582; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:05:20.567; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:05:23.443; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:05:26.323; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:05:29.253; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:05:32.428; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:05:35.365; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:05:38.502; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:05:41.496; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:05:44.702; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:05:47.891; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:05:50.769; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:05:53.600; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:05:56.789; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:05:59.768; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:06:02.956; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:06:06.190; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:06:09.423; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:06:12.509; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:06:15.651; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:06:18.831; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:06:21.961; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:06:24.935; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:06:27.765; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:06:30.648; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:06:33.676; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:06:36.508; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:06:39.398; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:06:42.434; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:06:45.561; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:06:48.383; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:06:51.459; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:06:54.539; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:06:57.424; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:07:00.300; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:07:03.324; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:07:06.351; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:07:09.229; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:07:12.056; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:07:15.131; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:07:18.334; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:07:21.410; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:07:24.489; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:07:27.617; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 13:07:30.699; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
INFO  - 2020-02-12 17:21:53.316; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 17:21:53.678; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 17:21:54.278; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 17:21:54.984; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 17:21:55.101; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 17:21:55.101; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 17:21:55.111; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
WARN  - 2020-02-12 17:21:57.297; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2020-02-12 17:21:57.822; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
WARN  - 2020-02-12 17:21:59.357; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2020-02-12 17:22:00.282; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 6962 ms
INFO  - 2020-02-12 17:22:00.469; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 17:22:00.671; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 17:22:00.917; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 17:22:01.299; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 830 ms
WARN  - 2020-02-12 17:22:01.491; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:22:03.750; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:22:06.159; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:22:08.971; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:22:11.989; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:22:15.054; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:22:18.019; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:22:20.985; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:22:23.952; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:22:26.813; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:22:29.980; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:22:33.046; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:22:36.112; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:22:38.974; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:22:42.138; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:22:45.153; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:22:48.219; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:22:51.386; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:22:54.350; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:22:57.363; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:23:00.432; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:23:03.552; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:23:06.516; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:23:09.681; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:23:12.901; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:23:16.067; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:23:18.932; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:23:22.150; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:23:25.218; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:23:28.132; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:23:31.253; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:23:34.435; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:23:37.602; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:23:40.772; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:23:43.839; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:23:46.907; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:23:49.923; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:23:52.788; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:23:55.752; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:23:58.818; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:24:01.731; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:24:04.845; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:24:07.759; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:24:10.723; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:24:13.586; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:24:16.703; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:24:19.565; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:24:22.784; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:24:25.848; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:24:29.013; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:24:31.827; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:24:34.997; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:24:38.011; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:24:40.977; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:24:44.097; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:24:47.264; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:24:50.282; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:24:53.244; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:24:56.208; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:24:59.272; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:25:02.286; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:25:05.455; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:25:08.526; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:25:11.343; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:25:14.358; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-12 17:25:17.321; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2020-02-12 17:25:18.544; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 17:25:18.558; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 17:25:18.562; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 17:25:18.563; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 17:25:18.563; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 17:25:18.583; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2020-02-12 17:25:18.690; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 17:25:18.690; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2020-02-12 17:25:18.793; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 17:25:18.794; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 17:25:18.800; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2020-02-12 17:25:18.905; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 17:25:18.906; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2020-02-12 17:25:19.009; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 17:25:19.010; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 17:25:19.024; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2020-02-12 17:25:19.130; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 17:25:19.130; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2020-02-12 17:25:19.239; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 17:25:19.241; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 17:25:19.244; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2020-02-12 17:25:19.366; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 17:25:19.367; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2020-02-12 17:25:19.474; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 17:25:19.474; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 17:25:19.478; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2020-02-12 17:25:19.583; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 17:25:19.584; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2020-02-12 17:25:19.687; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 17:25:19.688; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 17:25:19.694; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2020-02-12 17:25:19.798; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 17:25:19.799; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2020-02-12 17:25:19.907; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 17:25:19.908; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 17:25:34.769; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 16
INFO  - 2020-02-12 17:25:34.772; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 17:25:34.772; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 17:26:13.402; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-12 17:46:38.963; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 17:46:38.986; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 17:46:38.993; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-12 17:46:38.994; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 17:46:47.602; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 17:46:47.964; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 17:46:48.443; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 17:46:49.511; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 17:46:49.618; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 17:46:49.618; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 17:46:49.628; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 17:46:49.943; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 17:46:49.949; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 17:46:49.958; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 17:46:49.959; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 17:46:49.959; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 17:46:50.018; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 18
INFO  - 2020-02-12 17:46:50.021; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 17:46:50.022; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 17:46:52.942; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 17:46:55.267; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 7662 ms
INFO  - 2020-02-12 17:46:55.461; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 17:46:55.687; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 17:46:56.312; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 17:46:56.675; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1213 ms
INFO  - 2020-02-12 17:59:24.590; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 17:59:24.598; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 17:59:24.600; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 17:59:39.974; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 17:59:40.196; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 17:59:40.620; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 17:59:41.284; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 17:59:41.380; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 17:59:41.380; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 17:59:41.389; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 17:59:41.595; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 17:59:41.599; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 17:59:41.604; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 17:59:41.604; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 17:59:41.604; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 17:59:41.648; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 20
INFO  - 2020-02-12 17:59:41.652; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 17:59:41.652; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 17:59:44.339; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 17:59:47.238; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 7261 ms
INFO  - 2020-02-12 17:59:47.402; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 17:59:47.558; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 17:59:47.770; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 17:59:48.093; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 691 ms
INFO  - 2020-02-12 18:00:50.263; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 18:00:50.274; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 18:00:50.276; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 18:00:56.568; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 18:00:56.777; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 18:00:57.236; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 18:00:57.951; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 18:00:58.059; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 18:00:58.059; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 18:00:58.068; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 18:00:58.306; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 18:00:58.309; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 18:00:58.313; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 18:00:58.313; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 18:00:58.314; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 18:00:58.337; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 22
INFO  - 2020-02-12 18:00:58.340; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 18:00:58.340; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 18:01:00.696; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 18:01:03.716; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 7144 ms
INFO  - 2020-02-12 18:01:03.859; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
WARN  - 2020-02-12 18:01:04.022; org.springframework.context.support.AbstractApplicationContext; Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'articleController' defined in file [C:\Users\Legna\workspace\yangjinjing-cms\target\classes\com\yangjinjing\cms\controller\ArticleController.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.yangjinjing.cms.controller.ArticleController]: Constructor threw exception; nested exception is java.lang.Error: Unresolved compilation problems: 
	Syntax error, insert "enum Identifier" to complete EnumHeader
	Syntax error, insert "EnumBody" to complete EnumDeclaration

ERROR - 2020-02-12 18:01:04.023; org.springframework.web.servlet.FrameworkServlet; Context initialization failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'articleController' defined in file [C:\Users\Legna\workspace\yangjinjing-cms\target\classes\com\yangjinjing\cms\controller\ArticleController.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.yangjinjing.cms.controller.ArticleController]: Constructor threw exception; nested exception is java.lang.Error: Unresolved compilation problems: 
	Syntax error, insert "enum Identifier" to complete EnumHeader
	Syntax error, insert "EnumBody" to complete EnumDeclaration

	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1287)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1181)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549)
	at org.springframework.web.servlet.FrameworkServlet.configureAndRefreshWebApplicationContext(FrameworkServlet.java:701)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:667)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:715)
	at org.springframework.web.servlet.FrameworkServlet.initWebApplicationContext(FrameworkServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.initServletBean(FrameworkServlet.java:529)
	at org.springframework.web.servlet.HttpServletBean.init(HttpServletBean.java:169)
	at javax.servlet.GenericServlet.init(GenericServlet.java:244)
	at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:669)
	at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:426)
	at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:760)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:374)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.startWebapp(JettyWebAppContext.java:360)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:785)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:287)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.doStart(JettyWebAppContext.java:428)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo.restartWebApp(JettyRunMojo.java:553)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo$1.onPathWatchEvents(JettyRunMojo.java:405)
	at org.eclipse.jetty.util.PathWatcher.notifyEvents(PathWatcher.java:1366)
	at org.eclipse.jetty.util.PathWatcher.run(PathWatcher.java:1190)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.yangjinjing.cms.controller.ArticleController]: Constructor threw exception; nested exception is java.lang.Error: Unresolved compilation problems: 
	Syntax error, insert "enum Identifier" to complete EnumHeader
	Syntax error, insert "EnumBody" to complete EnumDeclaration

	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:184)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:87)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1279)
	... 34 more
Caused by: java.lang.Error: Unresolved compilation problems: 
	Syntax error, insert "enum Identifier" to complete EnumHeader
	Syntax error, insert "EnumBody" to complete EnumDeclaration

	at com.yangjinjing.cms.controller.ArticleController.<init>(ArticleController.java:163)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:172)
	... 36 more
INFO  - 2020-02-12 18:01:16.264; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 18:01:16.271; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 18:01:16.272; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 18:01:25.253; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 18:01:25.746; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 18:01:26.151; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 18:01:27.945; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 18:01:28.034; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 18:01:28.034; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 18:01:28.041; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 18:01:28.282; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 18:01:28.286; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 18:01:28.293; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 18:01:28.294; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 18:01:28.294; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 18:01:28.320; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 24
INFO  - 2020-02-12 18:01:28.328; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 18:01:28.329; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 18:01:31.065; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 18:01:33.134; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 7877 ms
INFO  - 2020-02-12 18:01:33.299; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 18:01:33.472; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 18:01:33.771; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 18:01:34.037; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 737 ms
INFO  - 2020-02-12 18:02:26.693; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 18:02:26.699; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 18:02:26.701; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 18:02:53.980; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 18:02:54.727; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 18:02:55.104; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 18:02:56.008; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 18:02:56.091; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 18:02:56.091; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 18:02:56.099; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 18:02:58.178; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 18:02:58.182; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 18:02:58.185; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 18:02:58.185; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 18:02:58.185; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 18:02:58.202; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 26
INFO  - 2020-02-12 18:02:58.204; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 18:02:58.204; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 18:03:06.494; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 18:04:19.889; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2020-02-12 18:05:14.344; org.apache.kafka.clients.FetchSessionHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 0: org.apache.kafka.common.errors.DisconnectException.
INFO  - 2020-02-12 18:05:58.937; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
ERROR - 2020-02-12 18:06:00.100; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetCommitResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Offset commit failed on partition 1708E-0 at offset 6: The coordinator is not aware of this member.
WARN  - 2020-02-12 18:06:00.355; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$4; [Consumer clientId=consumer-1, groupId=test-consumer-group] Asynchronous auto-commit of offsets {1708E-0=OffsetAndMetadata{offset=6, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
WARN  - 2020-02-12 18:06:00.356; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Synchronous auto-commit of offsets {1708E-0=OffsetAndMetadata{offset=6, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
INFO  - 2020-02-12 18:06:00.827; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions [1708E-0]
INFO  - 2020-02-12 18:06:00.827; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: [1708E-0]
INFO  - 2020-02-12 18:06:00.828; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 18:06:01.392; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 187409 ms
INFO  - 2020-02-12 18:06:01.615; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 28
INFO  - 2020-02-12 18:06:01.616; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 18:06:01.616; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 18:06:07.135; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 18:06:37.922; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 18:08:17.930; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 18:08:18.411; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 18:08:18.979; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 18:08:20.039; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 18:08:20.210; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 18:08:20.210; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 18:08:20.221; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 18:08:20.666; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 18:08:20.675; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 18:08:20.685; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 18:08:20.686; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 18:08:20.686; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 18:08:20.704; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 30
INFO  - 2020-02-12 18:08:20.706; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 18:08:20.706; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 18:08:23.895; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 18:08:27.587; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 9653 ms
INFO  - 2020-02-12 18:08:27.902; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 18:08:28.339; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 18:08:29.351; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 18:08:29.979; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 2077 ms
INFO  - 2020-02-12 18:08:30.468; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-12 18:11:18.376; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 18:11:18.383; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 18:11:18.388; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-12 18:11:18.389; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 18:11:21.500; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 18:11:21.771; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 18:11:22.268; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 18:11:22.999; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 18:11:23.095; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 18:11:23.096; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 18:11:23.105; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 18:11:23.361; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 18:11:23.365; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 18:11:23.372; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 18:11:23.373; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 18:11:23.373; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 18:11:23.396; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 32
INFO  - 2020-02-12 18:11:23.398; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 18:11:23.399; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 18:11:26.075; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 18:11:28.951; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 7448 ms
INFO  - 2020-02-12 18:11:29.136; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
WARN  - 2020-02-12 18:11:29.308; org.springframework.context.support.AbstractApplicationContext; Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'articleController': Lookup method resolution failed; nested exception is java.lang.IllegalStateException: Failed to introspect Class [com.yangjinjing.cms.controller.ArticleController] from ClassLoader [WebAppClassLoader=@2d07e2ea]
ERROR - 2020-02-12 18:11:29.309; org.springframework.web.servlet.FrameworkServlet; Context initialization failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'articleController': Lookup method resolution failed; nested exception is java.lang.IllegalStateException: Failed to introspect Class [com.yangjinjing.cms.controller.ArticleController] from ClassLoader [WebAppClassLoader=@2d07e2ea]
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.determineCandidateConstructors(AutowiredAnnotationBeanPostProcessor.java:265)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.determineConstructorsFromBeanPostProcessors(AbstractAutowireCapableBeanFactory.java:1253)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1168)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549)
	at org.springframework.web.servlet.FrameworkServlet.configureAndRefreshWebApplicationContext(FrameworkServlet.java:701)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:667)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:715)
	at org.springframework.web.servlet.FrameworkServlet.initWebApplicationContext(FrameworkServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.initServletBean(FrameworkServlet.java:529)
	at org.springframework.web.servlet.HttpServletBean.init(HttpServletBean.java:169)
	at javax.servlet.GenericServlet.init(GenericServlet.java:244)
	at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:669)
	at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:426)
	at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:760)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:374)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.startWebapp(JettyWebAppContext.java:360)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:785)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:287)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.doStart(JettyWebAppContext.java:428)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo.restartWebApp(JettyRunMojo.java:553)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo$1.onPathWatchEvents(JettyRunMojo.java:405)
	at org.eclipse.jetty.util.PathWatcher.notifyEvents(PathWatcher.java:1366)
	at org.eclipse.jetty.util.PathWatcher.run(PathWatcher.java:1190)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalStateException: Failed to introspect Class [com.yangjinjing.cms.controller.ArticleController] from ClassLoader [WebAppClassLoader=@2d07e2ea]
	at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:686)
	at org.springframework.util.ReflectionUtils.doWithMethods(ReflectionUtils.java:583)
	at org.springframework.util.ReflectionUtils.doWithMethods(ReflectionUtils.java:568)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.determineCandidateConstructors(AutowiredAnnotationBeanPostProcessor.java:248)
	... 35 more
Caused by: java.lang.NoClassDefFoundError: Model
	at java.lang.Class.getDeclaredMethods0(Native Method)
	at java.lang.Class.privateGetDeclaredMethods(Class.java:2701)
	at java.lang.Class.getDeclaredMethods(Class.java:1975)
	at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:668)
	... 38 more
Caused by: java.lang.ClassNotFoundException: Model
	at org.codehaus.plexus.classworlds.strategy.SelfFirstStrategy.loadClass(SelfFirstStrategy.java:50)
	at org.codehaus.plexus.classworlds.realm.ClassRealm.unsynchronizedLoadClass(ClassRealm.java:271)
	at org.codehaus.plexus.classworlds.realm.ClassRealm.loadClass(ClassRealm.java:247)
	at org.codehaus.plexus.classworlds.realm.ClassRealm.loadClass(ClassRealm.java:239)
	at org.eclipse.jetty.webapp.WebAppClassLoader.loadClass(WebAppClassLoader.java:565)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	... 42 more
INFO  - 2020-02-12 18:11:40.551; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 18:11:40.558; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 18:11:40.560; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 18:11:44.446; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 18:11:44.708; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 18:11:45.098; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 18:11:45.866; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 18:11:45.945; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 18:11:45.946; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 18:11:45.953; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 18:11:46.210; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 18:11:46.217; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 18:11:46.222; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 18:11:46.222; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 18:11:46.223; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 18:11:46.236; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 34
INFO  - 2020-02-12 18:11:46.238; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 18:11:46.238; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 18:11:48.626; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 18:11:51.384; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 6933 ms
INFO  - 2020-02-12 18:11:51.578; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
WARN  - 2020-02-12 18:11:51.814; org.springframework.context.support.AbstractApplicationContext; Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'articleController': Lookup method resolution failed; nested exception is java.lang.IllegalStateException: Failed to introspect Class [com.yangjinjing.cms.controller.ArticleController] from ClassLoader [WebAppClassLoader=@2de3d68a]
ERROR - 2020-02-12 18:11:51.815; org.springframework.web.servlet.FrameworkServlet; Context initialization failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'articleController': Lookup method resolution failed; nested exception is java.lang.IllegalStateException: Failed to introspect Class [com.yangjinjing.cms.controller.ArticleController] from ClassLoader [WebAppClassLoader=@2de3d68a]
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.determineCandidateConstructors(AutowiredAnnotationBeanPostProcessor.java:265)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.determineConstructorsFromBeanPostProcessors(AbstractAutowireCapableBeanFactory.java:1253)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1168)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549)
	at org.springframework.web.servlet.FrameworkServlet.configureAndRefreshWebApplicationContext(FrameworkServlet.java:701)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:667)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:715)
	at org.springframework.web.servlet.FrameworkServlet.initWebApplicationContext(FrameworkServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.initServletBean(FrameworkServlet.java:529)
	at org.springframework.web.servlet.HttpServletBean.init(HttpServletBean.java:169)
	at javax.servlet.GenericServlet.init(GenericServlet.java:244)
	at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:669)
	at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:426)
	at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:760)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:374)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.startWebapp(JettyWebAppContext.java:360)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:785)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:287)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.doStart(JettyWebAppContext.java:428)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo.restartWebApp(JettyRunMojo.java:553)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo$1.onPathWatchEvents(JettyRunMojo.java:405)
	at org.eclipse.jetty.util.PathWatcher.notifyEvents(PathWatcher.java:1366)
	at org.eclipse.jetty.util.PathWatcher.run(PathWatcher.java:1190)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalStateException: Failed to introspect Class [com.yangjinjing.cms.controller.ArticleController] from ClassLoader [WebAppClassLoader=@2de3d68a]
	at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:686)
	at org.springframework.util.ReflectionUtils.doWithMethods(ReflectionUtils.java:583)
	at org.springframework.util.ReflectionUtils.doWithMethods(ReflectionUtils.java:568)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.determineCandidateConstructors(AutowiredAnnotationBeanPostProcessor.java:248)
	... 35 more
Caused by: java.lang.NoClassDefFoundError: Model
	at java.lang.Class.getDeclaredMethods0(Native Method)
	at java.lang.Class.privateGetDeclaredMethods(Class.java:2701)
	at java.lang.Class.getDeclaredMethods(Class.java:1975)
	at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:668)
	... 38 more
Caused by: java.lang.ClassNotFoundException: Model
	at org.codehaus.plexus.classworlds.strategy.SelfFirstStrategy.loadClass(SelfFirstStrategy.java:50)
	at org.codehaus.plexus.classworlds.realm.ClassRealm.unsynchronizedLoadClass(ClassRealm.java:271)
	at org.codehaus.plexus.classworlds.realm.ClassRealm.loadClass(ClassRealm.java:247)
	at org.codehaus.plexus.classworlds.realm.ClassRealm.loadClass(ClassRealm.java:239)
	at org.eclipse.jetty.webapp.WebAppClassLoader.loadClass(WebAppClassLoader.java:565)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	... 42 more
INFO  - 2020-02-12 18:11:58.207; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 18:11:58.213; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 18:11:58.215; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 18:12:01.961; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 18:12:02.167; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 18:12:02.544; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 18:12:03.213; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 18:12:03.313; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 18:12:03.313; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 18:12:03.321; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 18:12:03.686; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 18:12:03.689; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 18:12:03.692; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 18:12:03.693; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 18:12:03.693; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 18:12:03.717; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 36
INFO  - 2020-02-12 18:12:03.721; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 18:12:03.721; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 18:12:06.114; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 18:12:08.428; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 6465 ms
INFO  - 2020-02-12 18:12:08.591; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
WARN  - 2020-02-12 18:12:08.753; org.springframework.context.support.AbstractApplicationContext; Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'articleController': Lookup method resolution failed; nested exception is java.lang.IllegalStateException: Failed to introspect Class [com.yangjinjing.cms.controller.ArticleController] from ClassLoader [WebAppClassLoader=@79dff60c]
ERROR - 2020-02-12 18:12:08.754; org.springframework.web.servlet.FrameworkServlet; Context initialization failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'articleController': Lookup method resolution failed; nested exception is java.lang.IllegalStateException: Failed to introspect Class [com.yangjinjing.cms.controller.ArticleController] from ClassLoader [WebAppClassLoader=@79dff60c]
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.determineCandidateConstructors(AutowiredAnnotationBeanPostProcessor.java:265)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.determineConstructorsFromBeanPostProcessors(AbstractAutowireCapableBeanFactory.java:1253)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1168)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549)
	at org.springframework.web.servlet.FrameworkServlet.configureAndRefreshWebApplicationContext(FrameworkServlet.java:701)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:667)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:715)
	at org.springframework.web.servlet.FrameworkServlet.initWebApplicationContext(FrameworkServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.initServletBean(FrameworkServlet.java:529)
	at org.springframework.web.servlet.HttpServletBean.init(HttpServletBean.java:169)
	at javax.servlet.GenericServlet.init(GenericServlet.java:244)
	at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:669)
	at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:426)
	at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:760)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:374)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.startWebapp(JettyWebAppContext.java:360)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:785)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:287)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.doStart(JettyWebAppContext.java:428)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo.restartWebApp(JettyRunMojo.java:553)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo$1.onPathWatchEvents(JettyRunMojo.java:405)
	at org.eclipse.jetty.util.PathWatcher.notifyEvents(PathWatcher.java:1366)
	at org.eclipse.jetty.util.PathWatcher.run(PathWatcher.java:1190)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalStateException: Failed to introspect Class [com.yangjinjing.cms.controller.ArticleController] from ClassLoader [WebAppClassLoader=@79dff60c]
	at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:686)
	at org.springframework.util.ReflectionUtils.doWithMethods(ReflectionUtils.java:583)
	at org.springframework.util.ReflectionUtils.doWithMethods(ReflectionUtils.java:568)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.determineCandidateConstructors(AutowiredAnnotationBeanPostProcessor.java:248)
	... 35 more
Caused by: java.lang.NoClassDefFoundError: Model
	at java.lang.Class.getDeclaredMethods0(Native Method)
	at java.lang.Class.privateGetDeclaredMethods(Class.java:2701)
	at java.lang.Class.getDeclaredMethods(Class.java:1975)
	at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:668)
	... 38 more
Caused by: java.lang.ClassNotFoundException: Model
	at org.codehaus.plexus.classworlds.strategy.SelfFirstStrategy.loadClass(SelfFirstStrategy.java:50)
	at org.codehaus.plexus.classworlds.realm.ClassRealm.unsynchronizedLoadClass(ClassRealm.java:271)
	at org.codehaus.plexus.classworlds.realm.ClassRealm.loadClass(ClassRealm.java:247)
	at org.codehaus.plexus.classworlds.realm.ClassRealm.loadClass(ClassRealm.java:239)
	at org.eclipse.jetty.webapp.WebAppClassLoader.loadClass(WebAppClassLoader.java:565)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	... 42 more
INFO  - 2020-02-12 18:12:13.535; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 18:12:13.543; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 18:12:13.546; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 18:12:21.270; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 18:12:21.457; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 18:12:21.811; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 18:12:22.490; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 18:12:22.571; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 18:12:22.571; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 18:12:22.578; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 18:12:23.049; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 18:12:23.052; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 18:12:23.064; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 18:12:23.064; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 18:12:23.064; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 18:12:23.112; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 38
INFO  - 2020-02-12 18:12:23.115; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 18:12:23.115; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 18:12:25.393; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 18:12:27.832; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 6559 ms
INFO  - 2020-02-12 18:12:27.992; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
WARN  - 2020-02-12 18:12:28.133; org.springframework.context.support.AbstractApplicationContext; Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'articleController': Lookup method resolution failed; nested exception is java.lang.IllegalStateException: Failed to introspect Class [com.yangjinjing.cms.controller.ArticleController] from ClassLoader [WebAppClassLoader=@5702dfc6]
ERROR - 2020-02-12 18:12:28.134; org.springframework.web.servlet.FrameworkServlet; Context initialization failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'articleController': Lookup method resolution failed; nested exception is java.lang.IllegalStateException: Failed to introspect Class [com.yangjinjing.cms.controller.ArticleController] from ClassLoader [WebAppClassLoader=@5702dfc6]
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.determineCandidateConstructors(AutowiredAnnotationBeanPostProcessor.java:265)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.determineConstructorsFromBeanPostProcessors(AbstractAutowireCapableBeanFactory.java:1253)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1168)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549)
	at org.springframework.web.servlet.FrameworkServlet.configureAndRefreshWebApplicationContext(FrameworkServlet.java:701)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:667)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:715)
	at org.springframework.web.servlet.FrameworkServlet.initWebApplicationContext(FrameworkServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.initServletBean(FrameworkServlet.java:529)
	at org.springframework.web.servlet.HttpServletBean.init(HttpServletBean.java:169)
	at javax.servlet.GenericServlet.init(GenericServlet.java:244)
	at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:669)
	at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:426)
	at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:760)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:374)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.startWebapp(JettyWebAppContext.java:360)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:785)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:287)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.doStart(JettyWebAppContext.java:428)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo.restartWebApp(JettyRunMojo.java:553)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo$1.onPathWatchEvents(JettyRunMojo.java:405)
	at org.eclipse.jetty.util.PathWatcher.notifyEvents(PathWatcher.java:1366)
	at org.eclipse.jetty.util.PathWatcher.run(PathWatcher.java:1190)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalStateException: Failed to introspect Class [com.yangjinjing.cms.controller.ArticleController] from ClassLoader [WebAppClassLoader=@5702dfc6]
	at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:686)
	at org.springframework.util.ReflectionUtils.doWithMethods(ReflectionUtils.java:583)
	at org.springframework.util.ReflectionUtils.doWithMethods(ReflectionUtils.java:568)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.determineCandidateConstructors(AutowiredAnnotationBeanPostProcessor.java:248)
	... 35 more
Caused by: java.lang.NoClassDefFoundError: Model
	at java.lang.Class.getDeclaredMethods0(Native Method)
	at java.lang.Class.privateGetDeclaredMethods(Class.java:2701)
	at java.lang.Class.getDeclaredMethods(Class.java:1975)
	at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:668)
	... 38 more
Caused by: java.lang.ClassNotFoundException: Model
	at org.codehaus.plexus.classworlds.strategy.SelfFirstStrategy.loadClass(SelfFirstStrategy.java:50)
	at org.codehaus.plexus.classworlds.realm.ClassRealm.unsynchronizedLoadClass(ClassRealm.java:271)
	at org.codehaus.plexus.classworlds.realm.ClassRealm.loadClass(ClassRealm.java:247)
	at org.codehaus.plexus.classworlds.realm.ClassRealm.loadClass(ClassRealm.java:239)
	at org.eclipse.jetty.webapp.WebAppClassLoader.loadClass(WebAppClassLoader.java:565)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	... 42 more
INFO  - 2020-02-12 18:12:33.152; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 18:12:33.168; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 18:12:33.170; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 18:12:39.659; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 18:12:40.139; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 18:12:40.498; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 18:12:41.123; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 18:12:41.211; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 18:12:41.211; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 18:12:41.220; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 18:12:41.453; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 18:12:41.457; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 18:12:41.461; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 18:12:41.462; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 18:12:41.462; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 18:12:41.486; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 40
INFO  - 2020-02-12 18:12:41.489; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 18:12:41.489; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 18:12:44.159; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 18:12:47.076; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 7414 ms
INFO  - 2020-02-12 18:12:47.215; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
WARN  - 2020-02-12 18:12:47.371; org.springframework.context.support.AbstractApplicationContext; Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'articleController': Lookup method resolution failed; nested exception is java.lang.IllegalStateException: Failed to introspect Class [com.yangjinjing.cms.controller.ArticleController] from ClassLoader [WebAppClassLoader=@4b4eb66]
ERROR - 2020-02-12 18:12:47.372; org.springframework.web.servlet.FrameworkServlet; Context initialization failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'articleController': Lookup method resolution failed; nested exception is java.lang.IllegalStateException: Failed to introspect Class [com.yangjinjing.cms.controller.ArticleController] from ClassLoader [WebAppClassLoader=@4b4eb66]
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.determineCandidateConstructors(AutowiredAnnotationBeanPostProcessor.java:265)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.determineConstructorsFromBeanPostProcessors(AbstractAutowireCapableBeanFactory.java:1253)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1168)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549)
	at org.springframework.web.servlet.FrameworkServlet.configureAndRefreshWebApplicationContext(FrameworkServlet.java:701)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:667)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:715)
	at org.springframework.web.servlet.FrameworkServlet.initWebApplicationContext(FrameworkServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.initServletBean(FrameworkServlet.java:529)
	at org.springframework.web.servlet.HttpServletBean.init(HttpServletBean.java:169)
	at javax.servlet.GenericServlet.init(GenericServlet.java:244)
	at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:669)
	at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:426)
	at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:760)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:374)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.startWebapp(JettyWebAppContext.java:360)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:785)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:287)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.doStart(JettyWebAppContext.java:428)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo.restartWebApp(JettyRunMojo.java:553)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo$1.onPathWatchEvents(JettyRunMojo.java:405)
	at org.eclipse.jetty.util.PathWatcher.notifyEvents(PathWatcher.java:1366)
	at org.eclipse.jetty.util.PathWatcher.run(PathWatcher.java:1190)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalStateException: Failed to introspect Class [com.yangjinjing.cms.controller.ArticleController] from ClassLoader [WebAppClassLoader=@4b4eb66]
	at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:686)
	at org.springframework.util.ReflectionUtils.doWithMethods(ReflectionUtils.java:583)
	at org.springframework.util.ReflectionUtils.doWithMethods(ReflectionUtils.java:568)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.determineCandidateConstructors(AutowiredAnnotationBeanPostProcessor.java:248)
	... 35 more
Caused by: java.lang.NoClassDefFoundError: Model
	at java.lang.Class.getDeclaredMethods0(Native Method)
	at java.lang.Class.privateGetDeclaredMethods(Class.java:2701)
	at java.lang.Class.getDeclaredMethods(Class.java:1975)
	at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:668)
	... 38 more
Caused by: java.lang.ClassNotFoundException: Model
	at org.codehaus.plexus.classworlds.strategy.SelfFirstStrategy.loadClass(SelfFirstStrategy.java:50)
	at org.codehaus.plexus.classworlds.realm.ClassRealm.unsynchronizedLoadClass(ClassRealm.java:271)
	at org.codehaus.plexus.classworlds.realm.ClassRealm.loadClass(ClassRealm.java:247)
	at org.codehaus.plexus.classworlds.realm.ClassRealm.loadClass(ClassRealm.java:239)
	at org.eclipse.jetty.webapp.WebAppClassLoader.loadClass(WebAppClassLoader.java:565)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	... 42 more
INFO  - 2020-02-12 18:15:26.607; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 18:15:26.617; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 18:15:26.619; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 18:15:35.850; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 18:15:36.583; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 18:15:37.656; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 18:15:39.366; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 18:15:39.466; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 18:15:39.466; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 18:15:39.475; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 18:15:40.268; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 18:15:40.272; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 18:15:40.277; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 18:15:40.278; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 18:15:40.278; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 18:15:40.315; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 42
INFO  - 2020-02-12 18:15:40.317; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 18:15:40.318; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 18:15:44.398; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
ERROR - 2020-02-12 18:15:56.267; org.springframework.data.elasticsearch.repository.support.AbstractElasticsearchRepository; failed to load elasticsearch nodes : NoNodeAvailableException[None of the configured nodes were available: [{vdjHyu9}{vdjHyu9rTyiZkpRqeeazIw}{H5AycC_PSGmkrBwiAVtm8g}{192.168.198.128}{192.168.198.128:9300}{ml.machine_memory=1813213184, ml.max_open_jobs=20, xpack.installed=true, ml.enabled=true}]]; nested: NodeDisconnectedException[[vdjHyu9][192.168.198.128:9300][indices:admin/exists] disconnected];; org.elasticsearch.transport.NodeDisconnectedException: [vdjHyu9][192.168.198.128:9300][indices:admin/exists] disconnected
INFO  - 2020-02-12 18:16:03.982; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 28128 ms
INFO  - 2020-02-12 18:16:04.868; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 18:16:06.904; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 18:16:10.279; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 18:16:14.700; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 9831 ms
INFO  - 2020-02-12 18:43:06.782; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 18:43:07.125; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 18:43:07.507; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 18:43:08.251; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 18:43:08.492; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 18:43:08.493; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 18:43:08.501; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 18:43:08.900; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 18:43:08.904; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 18:43:08.907; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 18:43:08.907; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 18:43:08.908; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 18:43:08.923; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 44
INFO  - 2020-02-12 18:43:08.925; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 18:43:08.925; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 18:43:11.140; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 18:43:13.950; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 7165 ms
INFO  - 2020-02-12 18:43:14.190; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 18:43:14.380; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 18:43:14.638; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 18:43:15.033; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 843 ms
INFO  - 2020-02-12 18:43:20.630; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-12 18:54:24.017; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 18:54:24.307; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 18:54:24.720; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 18:54:25.399; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 18:54:25.624; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 18:54:25.624; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 18:54:25.632; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 18:54:25.873; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 18:54:25.875; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 18:54:25.879; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 18:54:25.879; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 18:54:25.880; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 18:54:25.893; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 46
INFO  - 2020-02-12 18:54:25.895; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 18:54:25.895; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 18:54:28.289; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 18:54:30.844; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 6824 ms
INFO  - 2020-02-12 18:54:31.031; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 18:54:31.197; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 18:54:31.459; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 18:54:31.822; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 791 ms
INFO  - 2020-02-12 19:05:04.882; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 19:05:04.889; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 19:05:04.891; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 19:05:08.624; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 19:05:08.893; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 19:05:09.402; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 19:05:10.454; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 19:05:10.626; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 19:05:10.626; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 19:05:10.643; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 19:05:11.041; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 19:05:11.045; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 19:05:11.052; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 19:05:11.053; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 19:05:11.053; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 19:05:11.076; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 48
INFO  - 2020-02-12 19:05:11.079; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 19:05:11.079; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 19:05:14.150; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 19:05:16.850; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 8221 ms
INFO  - 2020-02-12 19:05:17.029; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 19:05:17.191; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 19:05:17.389; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 19:05:17.659; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 629 ms
INFO  - 2020-02-12 19:07:09.571; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 19:07:09.935; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 19:07:10.318; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 19:07:11.035; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 19:07:11.313; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 19:07:11.313; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 19:07:11.321; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 19:07:11.579; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 19:07:11.584; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 19:07:11.589; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 19:07:11.590; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 19:07:11.590; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 19:07:11.608; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 50
INFO  - 2020-02-12 19:07:11.610; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 19:07:11.611; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 19:07:14.018; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 19:07:16.737; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 7163 ms
INFO  - 2020-02-12 19:07:16.944; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 19:07:17.148; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 19:07:17.382; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 19:07:17.738; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 794 ms
INFO  - 2020-02-12 19:07:26.269; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-12 19:08:56.803; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 19:08:56.810; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 19:08:56.816; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-12 19:08:56.817; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 19:09:00.139; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 19:09:00.356; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 19:09:00.783; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 19:09:01.683; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 19:09:01.772; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 19:09:01.772; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 19:09:01.781; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 19:09:02.082; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 19:09:02.085; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 19:09:02.090; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 19:09:02.091; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 19:09:02.091; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 19:09:02.113; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 52
INFO  - 2020-02-12 19:09:02.115; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 19:09:02.116; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 19:09:04.544; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 19:09:06.892; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 6751 ms
INFO  - 2020-02-12 19:09:07.062; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 19:09:07.534; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 19:09:07.786; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 19:09:08.088; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1026 ms
INFO  - 2020-02-12 19:09:11.510; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 19:09:11.515; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 19:09:11.516; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 19:09:14.787; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 19:09:15.061; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 19:09:15.474; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 19:09:16.287; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 19:09:16.367; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 19:09:16.367; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 19:09:16.374; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 19:09:16.564; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 19:09:16.567; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 19:09:16.572; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 19:09:16.572; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 19:09:16.573; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 19:09:16.585; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 54
INFO  - 2020-02-12 19:09:16.587; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 19:09:16.588; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 19:09:19.116; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 19:09:22.250; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 7459 ms
INFO  - 2020-02-12 19:09:22.416; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 19:09:22.685; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 19:09:22.995; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 19:09:23.663; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1247 ms
INFO  - 2020-02-12 19:54:03.640; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 19:54:04.026; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 19:54:04.433; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 19:54:05.162; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 19:54:05.256; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 19:54:05.256; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 19:54:05.265; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 19:54:05.904; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 19:54:05.907; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 19:54:05.913; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 19:54:05.914; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 19:54:05.914; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 19:54:05.979; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 56
INFO  - 2020-02-12 19:54:05.981; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 19:54:05.981; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 19:54:08.348; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 19:54:10.852; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 7209 ms
INFO  - 2020-02-12 19:54:11.019; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 19:54:11.228; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 19:54:11.525; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 19:54:11.921; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 902 ms
INFO  - 2020-02-12 19:54:36.362; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-12 20:00:55.490; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 20:00:55.497; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 20:00:55.502; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-12 20:00:55.503; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 20:00:58.874; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 20:00:59.113; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 20:00:59.519; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 20:01:00.570; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 20:01:00.670; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 20:01:00.670; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 20:01:00.679; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 20:01:01.070; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 20:01:01.073; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 20:01:01.077; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 20:01:01.078; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 20:01:01.078; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 20:01:01.094; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 58
INFO  - 2020-02-12 20:01:01.097; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 20:01:01.097; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 20:01:03.588; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 20:01:05.977; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 7100 ms
INFO  - 2020-02-12 20:01:06.126; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 20:01:06.320; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 20:01:06.597; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 20:01:07.047; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 920 ms
INFO  - 2020-02-12 20:01:25.496; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-12 20:04:31.922; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 20:04:31.927; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 20:04:31.934; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-12 20:04:31.935; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 20:04:38.826; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 20:04:39.049; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 20:04:39.455; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 20:12:40.537; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 20:12:41.087; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 20:12:41.766; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 20:12:42.993; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 20:12:43.415; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 20:12:43.415; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 20:12:43.426; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 20:12:43.878; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 20:12:43.884; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 20:12:43.891; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 20:12:43.891; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 20:12:43.892; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 20:12:43.909; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 60
INFO  - 2020-02-12 20:12:43.911; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 20:12:43.912; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 20:12:47.527; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 20:12:51.250; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 10708 ms
INFO  - 2020-02-12 20:12:51.493; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 20:12:51.907; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 20:12:52.372; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 20:12:53.044; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1551 ms
INFO  - 2020-02-12 20:13:00.393; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-12 20:23:38.588; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 20:23:38.614; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 20:23:38.621; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-12 20:23:38.622; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 20:23:41.874; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 20:23:42.116; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 20:23:42.534; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 20:23:43.234; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 20:23:43.329; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 20:23:43.330; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 20:23:43.338; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 20:23:43.585; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 20:23:43.589; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 20:23:43.595; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 20:23:43.596; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 20:23:43.596; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 20:23:43.615; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 62
INFO  - 2020-02-12 20:23:43.618; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 20:23:43.619; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 20:23:46.209; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 20:23:48.323; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 6446 ms
INFO  - 2020-02-12 20:23:48.475; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 20:23:48.717; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 20:23:49.000; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 20:23:49.338; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 863 ms
INFO  - 2020-02-12 20:23:51.454; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 20:23:51.461; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 20:23:51.463; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 20:23:55.813; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 20:23:56.003; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 20:23:56.414; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 20:23:57.129; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 20:23:57.214; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 20:23:57.214; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 20:23:57.221; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 20:23:57.504; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 20:23:57.507; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 20:23:57.511; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 20:23:57.511; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 20:23:57.512; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 20:23:57.619; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 64
INFO  - 2020-02-12 20:23:57.621; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 20:23:57.622; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 20:24:00.134; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 20:24:03.185; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 7369 ms
INFO  - 2020-02-12 20:24:03.336; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 20:24:03.537; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 20:24:03.817; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 20:24:04.167; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 830 ms
INFO  - 2020-02-12 20:25:18.794; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 20:25:18.799; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 20:25:18.801; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 20:25:26.957; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 20:25:27.242; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 20:25:27.594; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 20:25:28.263; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 20:25:28.343; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 20:25:28.344; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 20:25:28.351; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 20:25:28.565; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 20:25:28.568; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 20:25:28.572; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 20:25:28.572; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 20:25:28.572; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 20:25:28.586; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 66
INFO  - 2020-02-12 20:25:28.588; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 20:25:28.588; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 20:25:30.965; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 20:25:33.573; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 6614 ms
INFO  - 2020-02-12 20:25:33.735; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 20:25:33.895; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 20:25:34.092; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 20:25:34.356; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 620 ms
INFO  - 2020-02-12 20:29:53.540; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 20:29:53.545; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 20:29:53.546; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 20:30:07.481; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 20:30:07.664; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 20:30:08.006; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 20:30:08.619; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 20:30:08.697; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 20:30:08.697; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 20:30:08.704; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 20:30:08.921; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 20:30:08.923; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 20:30:08.927; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 20:30:08.927; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 20:30:08.927; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 20:30:08.939; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 68
INFO  - 2020-02-12 20:30:08.941; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 20:30:08.942; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 20:30:11.227; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 20:30:13.285; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 5801 ms
INFO  - 2020-02-12 20:30:13.422; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 20:30:13.617; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 20:30:13.870; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 20:30:14.140; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 717 ms
INFO  - 2020-02-12 20:31:59.500; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 20:31:59.505; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 20:31:59.507; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 20:32:04.352; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 20:32:04.553; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 20:32:04.916; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 20:32:05.970; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 20:32:06.051; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 20:32:06.051; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 20:32:06.059; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 20:32:06.280; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 20:32:06.283; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 20:32:06.287; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 20:32:06.288; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 20:32:06.288; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 20:32:06.301; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 70
INFO  - 2020-02-12 20:32:06.303; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 20:32:06.303; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 20:32:09.443; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 20:32:12.857; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 8501 ms
INFO  - 2020-02-12 20:32:13.007; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 20:32:13.199; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 20:32:13.437; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 20:32:18.312; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 5304 ms
INFO  - 2020-02-12 20:32:55.875; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 20:32:55.880; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 20:32:55.882; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 20:58:36.549; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 20:58:36.970; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 20:58:37.621; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 20:58:38.307; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 20:58:38.431; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 20:58:38.431; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 20:58:38.439; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 20:58:38.906; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 20:58:38.952; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 20:58:38.956; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 20:58:38.956; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 20:58:38.956; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 20:58:40.082; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 72
INFO  - 2020-02-12 20:58:40.084; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 20:58:40.085; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 20:58:41.264; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 20:58:43.663; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 7111 ms
INFO  - 2020-02-12 20:58:43.902; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 20:58:44.106; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 20:58:44.387; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 20:58:44.777; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 875 ms
INFO  - 2020-02-12 20:59:03.739; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-12 21:01:42.889; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 21:01:42.895; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 21:01:42.902; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-12 21:01:42.903; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 21:01:46.308; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 21:01:46.537; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 21:01:46.978; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 21:01:47.641; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 21:01:47.730; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 21:01:47.730; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 21:01:47.739; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 21:01:47.990; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 21:01:47.992; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 21:01:47.997; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 21:01:47.998; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 21:01:47.998; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 21:01:48.051; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 74
INFO  - 2020-02-12 21:01:48.054; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 21:01:48.055; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 21:01:50.309; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 21:01:52.839; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 6526 ms
INFO  - 2020-02-12 21:01:53.020; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 21:01:53.195; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 21:01:53.417; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 21:01:53.707; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 687 ms
INFO  - 2020-02-12 21:02:14.022; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 21:02:14.029; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 21:02:14.031; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 21:02:18.675; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 21:02:18.955; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 21:02:19.366; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 21:02:20.152; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 21:02:20.241; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 21:02:20.242; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 21:02:20.249; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 21:02:20.537; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 21:02:20.552; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 21:02:20.556; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 21:02:20.557; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 21:02:20.557; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 21:02:20.594; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 76
INFO  - 2020-02-12 21:02:20.597; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 21:02:20.597; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 21:02:22.840; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 21:02:25.048; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 6368 ms
INFO  - 2020-02-12 21:02:25.201; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 21:02:25.381; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 21:02:25.644; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 21:02:25.929; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 727 ms
INFO  - 2020-02-12 21:02:57.873; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 21:02:57.879; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 21:02:57.881; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 21:03:02.346; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 21:03:02.532; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 21:03:02.880; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 21:03:03.570; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 21:03:03.654; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 21:03:03.654; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 21:03:03.666; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 21:03:03.966; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 21:03:03.969; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 21:03:03.972; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 21:03:03.973; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 21:03:03.973; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 21:03:03.995; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 78
INFO  - 2020-02-12 21:03:03.997; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 21:03:03.997; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 21:03:06.423; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 21:03:09.000; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 6652 ms
INFO  - 2020-02-12 21:03:09.141; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 21:03:09.329; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 21:03:09.561; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 21:03:09.853; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 712 ms
INFO  - 2020-02-12 21:03:21.850; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 21:03:21.858; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 21:03:21.859; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 21:03:26.196; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 21:03:26.374; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 21:03:26.724; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 21:03:27.371; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 21:03:27.635; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 21:03:27.635; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 21:03:27.642; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 21:03:27.819; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 21:03:27.822; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 21:03:27.825; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 21:03:27.825; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 21:03:27.825; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 21:03:27.837; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 80
INFO  - 2020-02-12 21:03:27.839; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 21:03:27.839; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 21:03:30.221; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 21:03:32.598; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 6399 ms
INFO  - 2020-02-12 21:03:32.792; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 21:03:32.998; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 21:03:33.251; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 21:03:33.550; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 758 ms
INFO  - 2020-02-12 21:03:37.136; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 21:03:37.143; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 21:03:37.146; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 21:04:04.610; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 21:04:05.389; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 21:04:05.788; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 21:04:06.466; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 21:04:06.551; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 21:04:06.551; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 21:04:06.559; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 21:04:07.062; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 21:04:07.064; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 21:04:07.068; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 21:04:07.069; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 21:04:07.069; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 21:04:07.120; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 82
INFO  - 2020-02-12 21:04:07.121; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 21:04:07.121; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 21:04:09.680; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 21:04:13.054; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 8440 ms
INFO  - 2020-02-12 21:04:13.248; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 21:04:13.437; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 21:04:14.976; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 21:04:15.995; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 2747 ms
INFO  - 2020-02-12 21:04:28.160; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-12 21:07:34.390; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 21:07:34.397; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 21:07:34.403; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-12 21:07:34.404; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 21:07:50.591; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 21:07:51.447; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 21:07:53.034; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 21:07:54.898; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 21:07:55.159; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 21:07:55.159; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 21:07:55.167; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 21:07:57.071; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 21:07:57.073; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 21:07:57.077; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 21:07:57.077; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 21:07:57.077; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 21:07:57.089; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 84
INFO  - 2020-02-12 21:07:57.091; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 21:07:57.091; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 21:08:03.471; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
ERROR - 2020-02-12 21:08:08.342; org.springframework.data.elasticsearch.repository.support.AbstractElasticsearchRepository; failed to load elasticsearch nodes : org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes are available: [{#transport#-1}{z00j0otWSdKd8SwU3AonqA}{192.168.198.128}{192.168.198.128:9300}]
INFO  - 2020-02-12 21:08:13.977; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 23383 ms
INFO  - 2020-02-12 21:08:14.520; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 21:08:15.775; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 21:08:17.596; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 21:08:20.454; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 5934 ms
INFO  - 2020-02-12 21:19:53.574; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 21:19:53.916; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 21:19:54.309; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 21:19:55.087; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 21:19:55.317; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 21:19:55.317; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 21:19:55.326; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 21:19:55.527; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 21:19:55.530; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 21:19:55.533; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 21:19:55.534; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 21:19:55.534; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 21:19:55.548; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 86
INFO  - 2020-02-12 21:19:55.550; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 21:19:55.550; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 21:19:57.984; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 21:20:00.757; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 7179 ms
INFO  - 2020-02-12 21:20:00.984; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 21:20:01.193; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 21:20:01.487; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 21:20:01.870; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 885 ms
INFO  - 2020-02-12 21:20:13.457; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-12 21:34:14.217; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 21:34:14.222; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 21:34:14.227; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-12 21:34:14.228; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 21:34:21.652; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 21:34:21.915; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 21:34:22.273; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 21:34:22.976; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 21:34:23.061; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 21:34:23.061; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 21:34:23.069; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 21:34:23.293; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 21:34:23.296; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 21:34:23.300; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 21:34:23.301; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 21:34:23.301; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 21:34:23.341; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 88
INFO  - 2020-02-12 21:34:23.343; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 21:34:23.344; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 21:34:25.635; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 21:34:27.855; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 6200 ms
INFO  - 2020-02-12 21:34:28.000; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 21:34:28.185; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 21:34:28.458; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 21:34:28.823; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 823 ms
INFO  - 2020-02-12 21:34:39.966; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 21:34:39.972; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 21:34:39.974; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 21:34:44.273; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 21:34:44.518; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 21:34:44.976; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 21:34:45.702; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 21:34:45.800; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 21:34:45.800; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 21:34:45.808; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 21:34:46.076; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 21:34:46.080; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 21:34:46.086; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 21:34:46.086; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 21:34:46.086; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 21:34:46.100; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 90
INFO  - 2020-02-12 21:34:46.102; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 21:34:46.103; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 21:34:48.786; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 21:34:51.089; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 6812 ms
INFO  - 2020-02-12 21:34:51.245; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
WARN  - 2020-02-12 21:34:51.415; org.springframework.context.support.AbstractApplicationContext; Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'adminController' defined in file [C:\Users\Legna\workspace\yangjinjing-cms\target\classes\com\yangjinjing\cms\controller\AdminController.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.yangjinjing.cms.controller.AdminController]: Constructor threw exception; nested exception is java.lang.Error: Unresolved compilation problem: 
	Syntax error on token "ArticleRep", delete this token

ERROR - 2020-02-12 21:34:51.417; org.springframework.web.servlet.FrameworkServlet; Context initialization failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'adminController' defined in file [C:\Users\Legna\workspace\yangjinjing-cms\target\classes\com\yangjinjing\cms\controller\AdminController.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.yangjinjing.cms.controller.AdminController]: Constructor threw exception; nested exception is java.lang.Error: Unresolved compilation problem: 
	Syntax error on token "ArticleRep", delete this token

	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1287)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1181)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549)
	at org.springframework.web.servlet.FrameworkServlet.configureAndRefreshWebApplicationContext(FrameworkServlet.java:701)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:667)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:715)
	at org.springframework.web.servlet.FrameworkServlet.initWebApplicationContext(FrameworkServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.initServletBean(FrameworkServlet.java:529)
	at org.springframework.web.servlet.HttpServletBean.init(HttpServletBean.java:169)
	at javax.servlet.GenericServlet.init(GenericServlet.java:244)
	at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:669)
	at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:426)
	at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:760)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:374)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.startWebapp(JettyWebAppContext.java:360)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:785)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:287)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.doStart(JettyWebAppContext.java:428)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo.restartWebApp(JettyRunMojo.java:553)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo$1.onPathWatchEvents(JettyRunMojo.java:405)
	at org.eclipse.jetty.util.PathWatcher.notifyEvents(PathWatcher.java:1366)
	at org.eclipse.jetty.util.PathWatcher.run(PathWatcher.java:1190)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.yangjinjing.cms.controller.AdminController]: Constructor threw exception; nested exception is java.lang.Error: Unresolved compilation problem: 
	Syntax error on token "ArticleRep", delete this token

	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:184)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:87)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1279)
	... 34 more
Caused by: java.lang.Error: Unresolved compilation problem: 
	Syntax error on token "ArticleRep", delete this token

	at com.yangjinjing.cms.controller.AdminController.<init>(AdminController.java:30)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:172)
	... 36 more
INFO  - 2020-02-12 21:35:17.230; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 21:35:17.236; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 21:35:17.238; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 21:35:31.332; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 21:35:31.516; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 21:35:31.885; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 21:35:32.542; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 21:35:32.635; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 21:35:32.636; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 21:35:32.644; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 21:35:32.959; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 21:35:32.964; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 21:35:32.969; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 21:35:32.970; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 21:35:32.970; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 21:35:32.994; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 92
INFO  - 2020-02-12 21:35:32.997; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 21:35:32.997; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 21:35:35.461; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 21:35:37.713; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 6379 ms
INFO  - 2020-02-12 21:35:37.854; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 21:35:38.031; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 21:35:38.246; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 21:35:38.499; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 644 ms
INFO  - 2020-02-12 21:35:51.994; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 21:35:52.000; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 21:35:52.002; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 21:35:59.493; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 21:35:59.716; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 21:36:00.063; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 21:36:00.714; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 21:36:00.796; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 21:36:00.796; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 21:36:00.803; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 21:36:01.016; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 21:36:01.079; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 21:36:01.085; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 21:36:01.085; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 21:36:01.086; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 21:36:01.102; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 94
INFO  - 2020-02-12 21:36:01.104; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 21:36:01.105; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 21:36:03.387; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 21:36:05.553; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 6057 ms
INFO  - 2020-02-12 21:36:05.687; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 21:36:05.869; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 21:36:06.102; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 21:36:06.403; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 716 ms
INFO  - 2020-02-12 21:36:18.003; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 21:36:18.008; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 21:36:18.009; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 21:36:40.335; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 21:36:40.695; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 21:36:41.320; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 21:36:42.420; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 21:36:42.555; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 21:36:42.556; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 21:36:42.566; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 21:36:42.813; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 21:36:42.817; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 21:36:42.823; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 21:36:42.823; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 21:36:42.824; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 21:36:42.868; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 96
INFO  - 2020-02-12 21:36:42.871; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 21:36:42.871; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 21:36:45.710; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 21:36:49.646; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 9306 ms
INFO  - 2020-02-12 21:36:53.830; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 21:36:56.759; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 21:36:58.502; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 21:37:00.097; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 6266 ms
INFO  - 2020-02-12 21:37:12.180; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 21:37:12.210; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 21:37:12.212; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 21:39:42.004; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 21:39:42.343; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 21:39:42.735; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 21:39:43.494; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 21:39:43.726; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 21:39:43.727; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 21:39:43.735; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 21:39:43.934; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 21:39:43.957; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 21:39:43.960; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 21:39:43.961; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 21:39:43.961; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 21:39:44.013; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 98
INFO  - 2020-02-12 21:39:44.015; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 21:39:44.016; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 21:39:46.331; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 21:39:48.831; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 6823 ms
INFO  - 2020-02-12 21:39:49.048; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 21:39:49.269; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 21:39:49.529; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 21:39:49.904; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 856 ms
INFO  - 2020-02-12 21:40:41.915; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-12 21:43:28.589; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 21:43:28.596; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 21:43:28.602; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-12 21:43:28.603; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 21:43:33.006; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 21:43:33.360; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 21:43:33.924; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 21:43:34.736; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 21:43:34.871; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 21:43:34.871; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 21:43:34.879; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 21:43:35.190; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 21:43:35.193; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 21:43:35.199; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 21:43:35.199; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 21:43:35.200; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 21:43:35.266; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 100
INFO  - 2020-02-12 21:43:35.269; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 21:43:35.270; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 21:43:37.668; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 21:43:39.965; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 6955 ms
INFO  - 2020-02-12 21:43:40.128; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 21:43:40.339; org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor; Autowired annotation should only be used on methods with parameters: public java.lang.String com.yangjinjing.cms.controller.UserController.home()
INFO  - 2020-02-12 21:43:40.623; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 21:43:41.052; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 923 ms
INFO  - 2020-02-12 21:44:01.492; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 21:44:01.499; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 21:44:01.501; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 21:44:04.877; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 21:44:05.205; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 21:44:05.613; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 21:44:06.374; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 21:44:06.468; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 21:44:06.469; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 21:44:06.476; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 21:44:06.677; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 21:44:06.680; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 21:44:06.684; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 21:44:06.685; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 21:44:06.685; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 21:44:06.698; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 102
INFO  - 2020-02-12 21:44:06.701; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 21:44:06.701; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 21:44:09.061; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 21:44:11.272; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 6392 ms
INFO  - 2020-02-12 21:44:11.421; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
WARN  - 2020-02-12 21:44:11.596; org.springframework.context.support.AbstractApplicationContext; Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'userController' defined in file [C:\Users\Legna\workspace\yangjinjing-cms\target\classes\com\yangjinjing\cms\controller\UserController.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.yangjinjing.cms.controller.UserController]: Constructor threw exception; nested exception is java.lang.Error: Unresolved compilation problems: 
	Syntax error on token "ArticleRep", delete this token
	The method home in type UserController can only set one of public / protected / private

ERROR - 2020-02-12 21:44:11.597; org.springframework.web.servlet.FrameworkServlet; Context initialization failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'userController' defined in file [C:\Users\Legna\workspace\yangjinjing-cms\target\classes\com\yangjinjing\cms\controller\UserController.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.yangjinjing.cms.controller.UserController]: Constructor threw exception; nested exception is java.lang.Error: Unresolved compilation problems: 
	Syntax error on token "ArticleRep", delete this token
	The method home in type UserController can only set one of public / protected / private

	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1287)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1181)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549)
	at org.springframework.web.servlet.FrameworkServlet.configureAndRefreshWebApplicationContext(FrameworkServlet.java:701)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:667)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:715)
	at org.springframework.web.servlet.FrameworkServlet.initWebApplicationContext(FrameworkServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.initServletBean(FrameworkServlet.java:529)
	at org.springframework.web.servlet.HttpServletBean.init(HttpServletBean.java:169)
	at javax.servlet.GenericServlet.init(GenericServlet.java:244)
	at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:669)
	at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:426)
	at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:760)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:374)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.startWebapp(JettyWebAppContext.java:360)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:785)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:287)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.doStart(JettyWebAppContext.java:428)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo.restartWebApp(JettyRunMojo.java:553)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo$1.onPathWatchEvents(JettyRunMojo.java:405)
	at org.eclipse.jetty.util.PathWatcher.notifyEvents(PathWatcher.java:1366)
	at org.eclipse.jetty.util.PathWatcher.run(PathWatcher.java:1190)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.yangjinjing.cms.controller.UserController]: Constructor threw exception; nested exception is java.lang.Error: Unresolved compilation problems: 
	Syntax error on token "ArticleRep", delete this token
	The method home in type UserController can only set one of public / protected / private

	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:184)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:87)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1279)
	... 34 more
Caused by: java.lang.Error: Unresolved compilation problems: 
	Syntax error on token "ArticleRep", delete this token
	The method home in type UserController can only set one of public / protected / private

	at com.yangjinjing.cms.controller.UserController.<init>(UserController.java:56)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:172)
	... 36 more
INFO  - 2020-02-12 21:44:13.879; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 21:44:13.886; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 21:44:13.888; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 21:44:17.449; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 21:44:17.637; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 21:44:17.989; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 21:44:18.657; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 21:44:18.742; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 21:44:18.743; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 21:44:18.751; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 21:44:19.314; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 21:44:19.318; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 21:44:19.322; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 21:44:19.322; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 21:44:19.323; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 21:44:19.498; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 104
INFO  - 2020-02-12 21:44:19.501; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 21:44:19.501; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 21:44:21.389; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 21:44:24.052; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 6600 ms
INFO  - 2020-02-12 21:44:24.250; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 21:44:24.780; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 21:44:25.106; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 855 ms
INFO  - 2020-02-12 21:44:28.985; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-12 21:44:28.991; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-12 21:44:28.992; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-12 21:44:34.514; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-12 21:44:34.748; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-12 21:44:35.150; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-12 21:44:35.821; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-12 21:44:35.905; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-12 21:44:35.905; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-12 21:44:35.916; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-12 21:44:36.171; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-12 21:44:36.173; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-12 21:44:36.177; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-12 21:44:36.178; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-12 21:44:36.178; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-12 21:44:36.191; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 106
INFO  - 2020-02-12 21:44:36.193; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-12 21:44:36.193; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-12 21:44:38.455; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-12 21:44:40.882; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 6365 ms
INFO  - 2020-02-12 21:44:41.047; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-12 21:44:41.552; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-12 21:44:41.881; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 833 ms
INFO  - 2020-02-12 21:45:11.552; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-12 21:51:15.264; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2020-02-12 21:51:31.001; org.apache.kafka.clients.FetchSessionHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 0: org.apache.kafka.common.errors.DisconnectException.
WARN  - 2020-02-12 21:51:52.056; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-12 21:52:13.212; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
INFO  - 2020-02-13 13:35:35.114; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-13 13:35:35.679; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 13:35:36.263; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 13:35:37.407; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 13:35:37.863; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 13:35:37.864; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 13:35:37.896; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 13:35:43.217; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
WARN  - 2020-02-13 13:35:59.260; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
ERROR - 2020-02-13 13:36:07.044; org.springframework.data.elasticsearch.repository.support.AbstractElasticsearchRepository; failed to load elasticsearch nodes : org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes are available: [{#transport#-1}{Q5HPyk6nRhmEQBW9u3GDLA}{192.168.198.128}{192.168.198.128:9300}]
INFO  - 2020-02-13 13:36:08.878; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 33755 ms
INFO  - 2020-02-13 13:36:09.268; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-13 13:36:10.405; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-13 13:36:11.213; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1944 ms
WARN  - 2020-02-13 13:36:20.322; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-13 13:36:41.427; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2020-02-13 13:36:44.760; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
WARN  - 2020-02-13 13:37:02.684; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-13 13:37:24.195; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-13 13:37:46.058; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-13 13:38:07.968; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2020-02-13 13:38:09.353; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 13:38:09.367; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 13:38:09.374; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 13:38:09.376; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 13:38:09.378; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 13:38:09.485; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 108
INFO  - 2020-02-13 13:38:09.489; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 13:38:09.489; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 13:57:54.012; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-13 13:57:54.097; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@53f65459, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3b088d51, org.springframework.test.context.support.DirtiesContextTestExecutionListener@1786dec2, org.springframework.test.context.transaction.TransactionalTestExecutionListener@74650e52, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@15d0c81b]
INFO  - 2020-02-13 13:57:54.769; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 13:57:55.580; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 13:57:57.215; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 13:57:58.124; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 13:57:58.124; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 13:57:58.136; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 13:57:58.981; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 13:57:58.984; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 13:57:58.988; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 13:57:58.988; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 13:57:58.989; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 13:58:01.000; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Attempt to heartbeat failed since group is rebalancing
INFO  - 2020-02-13 13:58:01.003; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions [1708E-0]
INFO  - 2020-02-13 13:58:01.003; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: [1708E-0]
INFO  - 2020-02-13 13:58:01.003; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 13:58:01.100; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 109
INFO  - 2020-02-13 13:58:01.100; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 109
INFO  - 2020-02-13 13:58:01.101; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-13 13:58:01.102; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-13 13:58:01.107; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 13:58:01.108; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 13:58:06.838; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 13:58:15.417; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-13 13:58:15.455; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@53f65459, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3b088d51, org.springframework.test.context.support.DirtiesContextTestExecutionListener@1786dec2, org.springframework.test.context.transaction.TransactionalTestExecutionListener@74650e52, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@15d0c81b]
INFO  - 2020-02-13 13:58:15.941; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 13:58:16.637; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 13:58:17.694; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 13:58:18.608; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 13:58:18.608; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 13:58:18.615; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 13:58:18.929; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 13:58:18.930; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 13:58:18.934; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 13:58:18.934; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 13:58:18.935; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 13:58:22.396; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 110
INFO  - 2020-02-13 13:58:22.398; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 13:58:22.399; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 13:58:22.530; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 13:58:26.555; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 13:58:26.577; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 13:58:26.580; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 13:59:01.191; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-13 13:59:01.225; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@53f65459, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3b088d51, org.springframework.test.context.support.DirtiesContextTestExecutionListener@1786dec2, org.springframework.test.context.transaction.TransactionalTestExecutionListener@74650e52, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@15d0c81b]
INFO  - 2020-02-13 13:59:01.689; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 13:59:02.316; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 13:59:03.431; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 13:59:04.340; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 13:59:04.341; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 13:59:04.350; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 13:59:04.645; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 13:59:04.648; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 13:59:04.653; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 13:59:04.654; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 13:59:04.654; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 13:59:04.734; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 112
INFO  - 2020-02-13 13:59:04.737; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 13:59:04.738; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 13:59:08.328; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 13:59:11.979; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 13:59:11.990; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 13:59:11.991; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 14:02:22.836; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-13 14:02:22.879; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@53f65459, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3b088d51, org.springframework.test.context.support.DirtiesContextTestExecutionListener@1786dec2, org.springframework.test.context.transaction.TransactionalTestExecutionListener@74650e52, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@15d0c81b]
INFO  - 2020-02-13 14:02:23.493; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 14:02:24.222; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 14:02:25.317; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 14:02:26.297; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 14:02:26.297; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 14:02:26.304; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 14:02:26.603; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 14:02:26.606; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 14:02:26.610; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 14:02:26.611; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 14:02:26.612; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 14:02:26.649; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 114
INFO  - 2020-02-13 14:02:26.653; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 14:02:26.653; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 14:02:30.536; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 14:02:34.336; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 14:02:34.353; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 14:02:34.355; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 14:03:18.018; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-13 14:03:18.069; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@53f65459, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3b088d51, org.springframework.test.context.support.DirtiesContextTestExecutionListener@1786dec2, org.springframework.test.context.transaction.TransactionalTestExecutionListener@74650e52, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@15d0c81b]
INFO  - 2020-02-13 14:03:18.502; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 14:03:19.136; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 14:03:20.144; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 14:03:20.960; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 14:03:20.960; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 14:03:20.970; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 14:03:21.240; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 14:03:21.241; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 14:03:21.245; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 14:03:21.245; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 14:03:21.245; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 14:03:21.310; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 116
INFO  - 2020-02-13 14:03:21.313; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 14:03:21.315; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 14:03:24.852; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 14:03:28.294; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 14:03:28.348; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 14:03:28.349; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 14:05:40.015; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-13 14:05:40.060; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@53f65459, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3b088d51, org.springframework.test.context.support.DirtiesContextTestExecutionListener@1786dec2, org.springframework.test.context.transaction.TransactionalTestExecutionListener@74650e52, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@15d0c81b]
INFO  - 2020-02-13 14:05:40.513; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 14:05:41.213; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 14:05:42.441; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 14:05:43.341; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 14:05:43.342; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 14:05:43.349; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 14:05:43.724; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 14:05:43.727; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 14:05:43.732; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 14:05:43.733; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 14:05:43.733; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 14:05:43.788; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 118
INFO  - 2020-02-13 14:05:43.792; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 14:05:43.792; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 14:05:47.464; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 14:05:50.924; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 14:05:50.942; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 14:05:50.948; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 14:06:28.665; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-13 14:06:28.707; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@53f65459, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3b088d51, org.springframework.test.context.support.DirtiesContextTestExecutionListener@1786dec2, org.springframework.test.context.transaction.TransactionalTestExecutionListener@74650e52, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@15d0c81b]
INFO  - 2020-02-13 14:06:29.192; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 14:06:29.888; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 14:06:30.991; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 14:06:31.942; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 14:06:31.942; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 14:06:31.955; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 14:06:32.236; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 14:06:32.238; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 14:06:32.242; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 14:06:32.243; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 14:06:32.243; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 14:06:32.266; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 120
INFO  - 2020-02-13 14:06:32.272; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 14:06:32.272; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 14:06:35.963; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 14:06:39.522; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 14:06:39.581; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 14:06:39.584; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 14:07:01.004; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-13 14:07:01.063; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@53f65459, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3b088d51, org.springframework.test.context.support.DirtiesContextTestExecutionListener@1786dec2, org.springframework.test.context.transaction.TransactionalTestExecutionListener@74650e52, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@15d0c81b]
INFO  - 2020-02-13 14:07:01.536; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 14:07:02.264; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 14:07:03.381; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 14:07:04.210; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 14:07:04.210; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 14:07:04.229; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 14:07:04.490; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 14:07:04.493; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 14:07:04.499; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 14:07:04.499; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 14:07:04.500; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 14:07:04.517; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 122
INFO  - 2020-02-13 14:07:04.519; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 14:07:04.519; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 14:07:08.153; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 14:07:12.029; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 14:07:12.050; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 14:07:12.063; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 14:07:58.883; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-13 14:07:58.928; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@53f65459, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3b088d51, org.springframework.test.context.support.DirtiesContextTestExecutionListener@1786dec2, org.springframework.test.context.transaction.TransactionalTestExecutionListener@74650e52, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@15d0c81b]
INFO  - 2020-02-13 14:07:59.385; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 14:08:00.015; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 14:08:01.115; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 14:08:01.968; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 14:08:01.968; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 14:08:01.981; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 14:08:02.268; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 14:08:02.269; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 14:08:02.276; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 14:08:02.276; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 14:08:02.277; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 14:08:02.358; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 124
INFO  - 2020-02-13 14:08:02.361; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 14:08:02.362; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 14:08:05.905; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 14:08:09.394; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 14:08:09.413; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 14:08:09.415; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 14:09:35.517; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-13 14:09:35.546; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@53f65459, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3b088d51, org.springframework.test.context.support.DirtiesContextTestExecutionListener@1786dec2, org.springframework.test.context.transaction.TransactionalTestExecutionListener@74650e52, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@15d0c81b]
INFO  - 2020-02-13 14:09:36.000; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 14:09:36.644; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 14:09:37.689; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 14:09:38.592; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 14:09:38.593; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 14:09:38.607; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 14:09:38.880; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 14:09:38.882; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 14:09:38.895; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 14:09:38.896; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 14:09:38.896; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 14:09:38.927; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 126
INFO  - 2020-02-13 14:09:38.929; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 14:09:38.929; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 14:09:42.572; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 14:09:46.114; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 14:09:46.123; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 14:09:46.132; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 14:10:23.473; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-13 14:10:23.512; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@53f65459, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3b088d51, org.springframework.test.context.support.DirtiesContextTestExecutionListener@1786dec2, org.springframework.test.context.transaction.TransactionalTestExecutionListener@74650e52, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@15d0c81b]
INFO  - 2020-02-13 14:10:23.977; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 14:10:24.619; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 14:10:25.686; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 14:10:26.613; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 14:10:26.613; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 14:10:26.620; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 14:10:26.889; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 14:10:26.891; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 14:10:26.897; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 14:10:26.897; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 14:10:26.898; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 14:10:26.925; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 128
INFO  - 2020-02-13 14:10:26.926; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 14:10:26.927; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 14:10:30.622; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 14:10:34.189; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 14:10:34.204; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 14:10:34.207; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 14:11:00.499; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-13 14:11:00.537; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@53f65459, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3b088d51, org.springframework.test.context.support.DirtiesContextTestExecutionListener@1786dec2, org.springframework.test.context.transaction.TransactionalTestExecutionListener@74650e52, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@15d0c81b]
INFO  - 2020-02-13 14:11:00.950; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 14:11:01.532; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 14:11:02.611; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 14:11:03.493; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 14:11:03.493; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 14:11:03.500; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 14:11:03.820; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 14:11:03.821; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 14:11:03.825; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 14:11:03.825; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 14:11:03.825; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 14:11:03.858; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 130
INFO  - 2020-02-13 14:11:03.861; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 14:11:03.861; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 14:11:07.852; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 14:11:11.546; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 14:11:11.557; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 14:11:11.560; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 14:12:07.465; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-13 14:12:07.504; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@53f65459, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3b088d51, org.springframework.test.context.support.DirtiesContextTestExecutionListener@1786dec2, org.springframework.test.context.transaction.TransactionalTestExecutionListener@74650e52, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@15d0c81b]
INFO  - 2020-02-13 14:12:08.212; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 14:12:08.984; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 14:12:10.154; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 14:12:11.065; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 14:12:11.065; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 14:12:11.082; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 14:12:11.440; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 14:12:11.442; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 14:12:11.446; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 14:12:11.446; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 14:12:11.446; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 14:12:11.469; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 132
INFO  - 2020-02-13 14:12:11.472; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 14:12:11.473; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 14:12:15.250; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 14:12:18.853; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 14:12:18.866; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 14:12:18.868; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 14:26:35.816; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-13 14:26:35.852; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@53f65459, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3b088d51, org.springframework.test.context.support.DirtiesContextTestExecutionListener@1786dec2, org.springframework.test.context.transaction.TransactionalTestExecutionListener@74650e52, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@15d0c81b]
INFO  - 2020-02-13 14:26:36.292; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 14:26:36.878; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 14:26:37.978; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 14:26:38.840; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 14:26:38.840; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 14:26:38.850; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 14:26:39.116; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 14:26:39.118; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 14:26:39.123; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 14:26:39.124; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 14:26:39.125; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 14:26:39.182; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 134
INFO  - 2020-02-13 14:26:39.184; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 14:26:39.185; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 14:26:42.913; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 14:26:46.410; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 14:26:46.418; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 14:26:46.420; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 14:26:54.116; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-13 14:26:54.147; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@53f65459, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3b088d51, org.springframework.test.context.support.DirtiesContextTestExecutionListener@1786dec2, org.springframework.test.context.transaction.TransactionalTestExecutionListener@74650e52, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@15d0c81b]
INFO  - 2020-02-13 14:26:54.623; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 14:26:55.395; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 14:26:56.535; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 14:26:57.445; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 14:26:57.445; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 14:26:57.459; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 14:26:57.797; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 14:26:57.799; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 14:26:57.803; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 14:26:57.804; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 14:26:57.804; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 14:26:57.851; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 136
INFO  - 2020-02-13 14:26:57.854; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 14:26:57.855; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 14:27:01.606; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 14:27:05.177; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 14:27:05.199; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 14:27:05.201; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 14:27:23.606; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-13 14:27:23.651; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@394e1a0f, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@27a5f880, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@1d29cf23, org.springframework.test.context.support.DirtiesContextTestExecutionListener@5f282abb, org.springframework.test.context.transaction.TransactionalTestExecutionListener@167fdd33, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1e965684]
INFO  - 2020-02-13 14:27:24.068; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 14:27:24.720; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 14:27:25.801; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 14:27:26.698; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 14:27:26.700; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 14:27:26.711; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 14:27:26.999; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 14:27:27.002; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 14:27:27.007; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 14:27:27.007; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 14:27:27.008; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 14:27:27.048; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 138
INFO  - 2020-02-13 14:27:27.051; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 14:27:27.051; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 14:27:30.733; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 14:27:34.423; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 14:27:34.435; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 14:27:34.442; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 14:28:04.983; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-13 14:28:05.028; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@53f65459, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3b088d51, org.springframework.test.context.support.DirtiesContextTestExecutionListener@1786dec2, org.springframework.test.context.transaction.TransactionalTestExecutionListener@74650e52, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@15d0c81b]
INFO  - 2020-02-13 14:28:05.510; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 14:28:06.255; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 14:28:07.347; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 14:28:08.272; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 14:28:08.272; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 14:28:08.288; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 14:28:08.602; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 14:28:08.605; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 14:28:08.611; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 14:28:08.611; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 14:28:08.612; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 14:28:08.648; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 140
INFO  - 2020-02-13 14:28:08.652; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 14:28:08.652; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 14:28:12.341; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 14:28:15.876; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 14:28:15.896; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 14:28:15.900; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 14:29:00.921; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-13 14:29:00.964; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@53f65459, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3b088d51, org.springframework.test.context.support.DirtiesContextTestExecutionListener@1786dec2, org.springframework.test.context.transaction.TransactionalTestExecutionListener@74650e52, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@15d0c81b]
INFO  - 2020-02-13 14:29:01.466; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 14:29:02.060; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 14:29:03.165; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 14:29:04.119; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 14:29:04.119; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 14:29:04.127; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 14:29:04.517; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 14:29:04.519; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 14:29:04.525; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 14:29:04.526; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 14:29:04.527; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 14:29:04.563; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 142
INFO  - 2020-02-13 14:29:04.565; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 14:29:04.566; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 14:29:08.310; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 14:29:11.618; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 14:29:11.632; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 14:29:11.642; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 14:34:25.987; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-13 14:34:26.025; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@53f65459, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3b088d51, org.springframework.test.context.support.DirtiesContextTestExecutionListener@1786dec2, org.springframework.test.context.transaction.TransactionalTestExecutionListener@74650e52, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@15d0c81b]
INFO  - 2020-02-13 14:34:26.567; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 14:34:27.200; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 14:34:28.320; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 14:34:29.257; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 14:34:29.257; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 14:34:29.266; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 14:34:29.524; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 14:34:29.525; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 14:34:29.529; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 14:34:29.529; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 14:34:29.530; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 14:34:29.564; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 144
INFO  - 2020-02-13 14:34:29.568; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 14:34:29.568; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 14:34:33.269; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 14:34:37.011; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 14:34:37.030; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 14:34:37.035; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 14:43:47.522; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-13 14:43:47.565; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@53f65459, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3b088d51, org.springframework.test.context.support.DirtiesContextTestExecutionListener@1786dec2, org.springframework.test.context.transaction.TransactionalTestExecutionListener@74650e52, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@15d0c81b]
INFO  - 2020-02-13 14:43:48.053; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 14:43:48.816; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 14:43:49.895; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 14:43:50.821; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 14:43:50.821; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 14:43:50.835; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 14:43:51.114; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 14:43:51.115; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 14:43:51.120; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 14:43:51.122; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 14:43:51.123; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 14:43:51.156; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 146
INFO  - 2020-02-13 14:43:51.160; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 14:43:51.160; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 14:43:54.769; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 14:43:59.393; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 14:43:59.404; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 14:43:59.406; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 14:48:50.424; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-13 14:48:50.454; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@53f65459, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3b088d51, org.springframework.test.context.support.DirtiesContextTestExecutionListener@1786dec2, org.springframework.test.context.transaction.TransactionalTestExecutionListener@74650e52, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@15d0c81b]
INFO  - 2020-02-13 14:48:50.915; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 14:48:51.504; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 14:48:52.544; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 14:48:53.437; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 14:48:53.438; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 14:48:53.451; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 14:48:53.728; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 14:48:53.730; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 14:48:53.732; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 14:48:53.733; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 14:48:53.733; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 14:48:53.781; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 148
INFO  - 2020-02-13 14:48:53.782; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 14:48:53.783; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 14:48:57.291; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 14:49:01.714; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 14:49:01.725; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 14:49:01.727; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 15:02:48.945; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-13 15:02:48.999; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@27a5f880, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@1d29cf23, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@5f282abb, org.springframework.test.context.support.DirtiesContextTestExecutionListener@167fdd33, org.springframework.test.context.transaction.TransactionalTestExecutionListener@1e965684, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@4d95d2a2]
INFO  - 2020-02-13 15:02:49.468; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 15:02:50.546; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 15:02:51.827; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 15:02:52.813; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 15:02:52.814; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 15:02:52.828; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 15:02:53.280; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 15:02:53.283; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 15:02:53.287; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 15:02:53.287; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 15:02:53.288; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 15:02:53.309; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 150
INFO  - 2020-02-13 15:02:53.311; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 15:02:53.311; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 15:02:56.885; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 15:03:01.064; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-13 15:03:02.071; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 15:03:02.084; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 15:03:02.108; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-13 15:03:02.109; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 15:15:10.693; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-13 15:15:10.733; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@53f65459, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@3b088d51, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@1786dec2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@74650e52, org.springframework.test.context.transaction.TransactionalTestExecutionListener@15d0c81b, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@6acdbdf5]
INFO  - 2020-02-13 15:15:11.247; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 15:15:11.890; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 15:15:12.944; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 15:15:13.798; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 15:15:13.799; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 15:15:13.809; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 15:15:14.088; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 15:15:14.091; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 15:15:14.096; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 15:15:14.097; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 15:15:14.097; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 15:15:14.133; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 152
INFO  - 2020-02-13 15:15:14.135; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 15:15:14.136; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 15:15:17.737; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 15:15:21.387; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-13 15:15:21.738; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 15:15:21.748; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 15:15:21.755; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-13 15:15:21.756; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 15:16:51.509; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-13 15:16:51.543; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@53f65459, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@3b088d51, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@1786dec2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@74650e52, org.springframework.test.context.transaction.TransactionalTestExecutionListener@15d0c81b, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@6acdbdf5]
INFO  - 2020-02-13 15:16:52.201; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 15:16:53.017; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 15:16:54.155; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 15:16:55.011; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 15:16:55.011; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 15:16:55.029; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 15:16:55.332; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 15:16:55.339; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 15:16:55.348; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 15:16:55.349; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 15:16:55.350; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 15:16:55.379; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 154
INFO  - 2020-02-13 15:16:55.381; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 15:16:55.382; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 15:16:59.113; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 15:17:02.633; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-13 15:17:03.069; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 15:17:03.094; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 15:17:03.101; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-13 15:17:03.102; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 15:20:08.678; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-13 15:20:08.711; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@53f65459, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@3b088d51, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@1786dec2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@74650e52, org.springframework.test.context.transaction.TransactionalTestExecutionListener@15d0c81b, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@6acdbdf5]
INFO  - 2020-02-13 15:20:09.205; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 15:20:10.126; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 15:20:11.252; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 15:20:12.149; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 15:20:12.149; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 15:20:12.165; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 15:20:12.487; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 15:20:12.489; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 15:20:12.494; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 15:20:12.495; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 15:20:12.495; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 15:20:12.542; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 156
INFO  - 2020-02-13 15:20:12.545; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 15:20:12.545; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 15:20:16.109; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 15:20:19.695; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-13 15:20:20.006; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 15:20:20.017; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 15:20:20.028; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-13 15:20:20.030; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 15:43:59.191; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-13 15:43:59.743; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 15:44:00.598; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 15:44:01.711; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 15:44:01.851; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 15:44:01.852; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 15:44:01.865; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 15:44:02.505; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 15:44:02.509; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 15:44:02.516; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 15:44:02.517; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 15:44:02.517; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 15:44:02.591; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 158
INFO  - 2020-02-13 15:44:02.595; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 15:44:02.595; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 15:44:05.971; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 15:44:10.313; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 11118 ms
INFO  - 2020-02-13 15:44:10.621; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-13 15:44:11.725; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-13 15:44:12.369; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1747 ms
INFO  - 2020-02-13 15:44:33.386; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-13 15:45:31.306; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 15:45:31.317; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 15:45:31.331; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-13 15:45:31.334; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 15:45:38.761; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-13 15:45:39.115; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 15:45:40.081; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 15:45:41.399; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 15:45:41.614; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 15:45:41.614; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 15:45:41.637; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 15:45:42.228; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 15:45:42.234; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 15:45:42.243; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 15:45:42.243; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 15:45:42.244; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 15:45:42.288; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 160
INFO  - 2020-02-13 15:45:42.295; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 15:45:42.296; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 15:45:46.157; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 15:45:50.010; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 11243 ms
INFO  - 2020-02-13 15:45:50.261; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-13 15:45:52.576; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-13 15:45:53.099; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 2838 ms
INFO  - 2020-02-13 15:45:58.857; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 15:45:58.867; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 15:45:58.869; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 15:46:07.631; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-13 15:46:08.375; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 15:46:09.180; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 15:46:10.957; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 15:46:11.155; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 15:46:11.156; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 15:46:11.188; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 15:46:11.630; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 15:46:11.635; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 15:46:11.642; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 15:46:11.643; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 15:46:11.643; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 15:46:11.685; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 162
INFO  - 2020-02-13 15:46:11.690; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 15:46:11.691; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 15:46:16.408; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 15:46:23.474; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 15835 ms
INFO  - 2020-02-13 15:46:23.858; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-13 15:46:24.959; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-13 15:46:30.998; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 7140 ms
INFO  - 2020-02-13 15:46:37.285; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 15:46:37.290; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 15:46:37.292; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 15:47:19.840; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-13 15:47:20.490; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 15:47:21.178; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 15:47:22.810; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 15:47:23.457; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 15:47:23.458; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 15:47:23.476; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 15:47:23.989; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 15:47:23.994; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 15:47:24.004; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 15:47:24.004; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 15:47:24.005; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 15:47:24.055; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 164
INFO  - 2020-02-13 15:47:24.058; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 15:47:24.058; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 15:47:27.626; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 15:47:32.048; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 12198 ms
INFO  - 2020-02-13 15:47:32.414; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-13 15:47:33.450; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-13 15:47:34.675; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 2260 ms
INFO  - 2020-02-13 15:48:55.345; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 15:48:55.357; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 15:48:55.362; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 15:48:59.272; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-13 15:48:59.607; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 15:49:00.232; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 15:49:01.507; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 15:49:01.690; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 15:49:01.690; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 15:49:01.712; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 15:49:02.169; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 15:49:02.175; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 15:49:02.180; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 15:49:02.181; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 15:49:02.182; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 15:49:02.247; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 166
INFO  - 2020-02-13 15:49:02.252; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 15:49:02.252; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 15:49:05.507; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 15:49:08.620; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 9342 ms
INFO  - 2020-02-13 15:49:08.836; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-13 15:49:09.544; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-13 15:49:10.243; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1406 ms
INFO  - 2020-02-13 15:51:31.802; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 15:51:31.811; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 15:51:31.814; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 15:51:36.055; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-13 15:51:36.372; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 15:51:36.986; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 15:51:38.090; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 15:51:38.211; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 15:51:38.211; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 15:51:38.227; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 15:51:38.574; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 15:51:38.576; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 15:51:38.580; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 15:51:38.580; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 15:51:38.580; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 15:51:38.594; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 168
INFO  - 2020-02-13 15:51:38.596; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 15:51:38.596; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 16:20:52.037; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-13 16:20:52.478; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 16:20:53.261; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 16:20:59.795; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 16:21:01.881; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 16:21:02.089; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 16:21:02.090; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 16:21:02.101; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 16:21:02.561; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 16:21:02.565; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 16:21:02.573; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 16:21:02.574; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 16:21:02.575; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 16:21:02.591; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 170
INFO  - 2020-02-13 16:21:02.597; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 16:21:02.597; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 16:21:03.094; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 11051 ms
INFO  - 2020-02-13 16:21:03.429; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
WARN  - 2020-02-13 16:21:03.938; org.springframework.context.support.AbstractApplicationContext; Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleController': Unsatisfied dependency expressed through field 'kfk'; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'org.springframework.kafka.core.KafkaTemplate<java.lang.String, java.lang.String>' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)}
ERROR - 2020-02-13 16:21:03.940; org.springframework.web.servlet.FrameworkServlet; Context initialization failed
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleController': Unsatisfied dependency expressed through field 'kfk'; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'org.springframework.kafka.core.KafkaTemplate<java.lang.String, java.lang.String>' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)}
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:596)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:374)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1395)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549)
	at org.springframework.web.servlet.FrameworkServlet.configureAndRefreshWebApplicationContext(FrameworkServlet.java:701)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:667)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:715)
	at org.springframework.web.servlet.FrameworkServlet.initWebApplicationContext(FrameworkServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.initServletBean(FrameworkServlet.java:529)
	at org.springframework.web.servlet.HttpServletBean.init(HttpServletBean.java:169)
	at javax.servlet.GenericServlet.init(GenericServlet.java:244)
	at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:669)
	at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:426)
	at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:760)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:374)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.startWebapp(JettyWebAppContext.java:360)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:785)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:287)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.doStart(JettyWebAppContext.java:428)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:138)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)
	at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:113)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.doStart(ContextHandlerCollection.java:167)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:138)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)
	at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:113)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:138)
	at org.eclipse.jetty.server.Server.start(Server.java:419)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:108)
	at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:113)
	at org.eclipse.jetty.server.Server.doStart(Server.java:386)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.maven.plugin.AbstractJettyMojo.startJetty(AbstractJettyMojo.java:467)
	at org.eclipse.jetty.maven.plugin.AbstractJettyMojo.execute(AbstractJettyMojo.java:329)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo.execute(JettyRunMojo.java:179)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:210)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:156)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:148)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:117)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:305)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:957)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:289)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:193)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'org.springframework.kafka.core.KafkaTemplate<java.lang.String, java.lang.String>' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)}
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.raiseNoMatchingBeanFound(DefaultListableBeanFactory.java:1654)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1213)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1167)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:593)
	... 71 more
INFO  - 2020-02-13 16:22:43.437; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 16:22:43.451; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 16:22:43.453; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 16:22:47.509; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-13 16:22:47.902; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 16:22:48.572; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 16:22:54.277; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 16:22:56.339; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 16:22:56.488; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 16:22:56.489; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 16:22:56.498; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 16:22:57.050; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 16:22:57.055; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 16:22:57.061; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 16:22:57.062; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 16:22:57.063; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 16:22:57.118; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 172
INFO  - 2020-02-13 16:22:57.120; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 16:22:57.121; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 16:22:57.298; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 9784 ms
INFO  - 2020-02-13 16:22:57.603; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
WARN  - 2020-02-13 16:22:57.972; org.springframework.context.support.AbstractApplicationContext; Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleController': Unsatisfied dependency expressed through field 'kfk'; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'org.springframework.kafka.core.KafkaTemplate<java.lang.String, java.lang.String>' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)}
ERROR - 2020-02-13 16:22:57.973; org.springframework.web.servlet.FrameworkServlet; Context initialization failed
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleController': Unsatisfied dependency expressed through field 'kfk'; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'org.springframework.kafka.core.KafkaTemplate<java.lang.String, java.lang.String>' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)}
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:596)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:374)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1395)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549)
	at org.springframework.web.servlet.FrameworkServlet.configureAndRefreshWebApplicationContext(FrameworkServlet.java:701)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:667)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:715)
	at org.springframework.web.servlet.FrameworkServlet.initWebApplicationContext(FrameworkServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.initServletBean(FrameworkServlet.java:529)
	at org.springframework.web.servlet.HttpServletBean.init(HttpServletBean.java:169)
	at javax.servlet.GenericServlet.init(GenericServlet.java:244)
	at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:669)
	at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:426)
	at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:760)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:374)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.startWebapp(JettyWebAppContext.java:360)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:785)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:287)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.doStart(JettyWebAppContext.java:428)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo.restartWebApp(JettyRunMojo.java:553)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo$1.onPathWatchEvents(JettyRunMojo.java:405)
	at org.eclipse.jetty.util.PathWatcher.notifyEvents(PathWatcher.java:1366)
	at org.eclipse.jetty.util.PathWatcher.run(PathWatcher.java:1190)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'org.springframework.kafka.core.KafkaTemplate<java.lang.String, java.lang.String>' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)}
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.raiseNoMatchingBeanFound(DefaultListableBeanFactory.java:1654)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1213)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1167)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:593)
	... 36 more
INFO  - 2020-02-13 16:25:01.124; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-13 16:25:01.663; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 16:25:02.306; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 16:25:08.209; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 16:25:10.219; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 16:25:10.381; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 16:25:10.381; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 16:25:10.391; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 16:25:10.876; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 16:25:10.882; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 16:25:10.889; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 16:25:10.890; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 16:25:10.890; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 16:25:10.944; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 174
INFO  - 2020-02-13 16:25:10.952; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 16:25:10.953; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 16:25:11.491; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 10362 ms
INFO  - 2020-02-13 16:25:11.830; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-13 16:25:12.839; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-13 16:25:13.398; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1568 ms
INFO  - 2020-02-13 16:25:42.035; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-13 16:26:04.324; org.apache.kafka.common.config.AbstractConfig; ProducerConfig values: 
	acks = 1
	batch.size = 1638
	bootstrap.servers = [192.168.198.128:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  - 2020-02-13 16:26:04.365; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 16:26:04.366; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
WARN  - 2020-02-13 16:26:07.052; org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater; [Producer clientId=producer-1] Error while fetching metadata with correlation id 2 : {article=LEADER_NOT_AVAILABLE}
INFO  - 2020-02-13 16:26:07.053; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
WARN  - 2020-02-13 16:26:07.271; org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater; [Producer clientId=producer-1] Error while fetching metadata with correlation id 5 : {article=LEADER_NOT_AVAILABLE}
WARN  - 2020-02-13 16:26:07.443; org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater; [Producer clientId=producer-1] Error while fetching metadata with correlation id 6 : {article=LEADER_NOT_AVAILABLE}
WARN  - 2020-02-13 16:26:07.568; org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater; [Producer clientId=producer-1] Error while fetching metadata with correlation id 7 : {article=LEADER_NOT_AVAILABLE}
WARN  - 2020-02-13 16:26:07.692; org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater; [Producer clientId=producer-1] Error while fetching metadata with correlation id 8 : {article=LEADER_NOT_AVAILABLE}
WARN  - 2020-02-13 16:26:07.815; org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater; [Producer clientId=producer-1] Error while fetching metadata with correlation id 9 : {article=LEADER_NOT_AVAILABLE}
WARN  - 2020-02-13 16:26:07.919; org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater; [Producer clientId=producer-1] Error while fetching metadata with correlation id 10 : {article=LEADER_NOT_AVAILABLE}
WARN  - 2020-02-13 16:26:08.027; org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater; [Producer clientId=producer-1] Error while fetching metadata with correlation id 11 : {article=LEADER_NOT_AVAILABLE}
WARN  - 2020-02-13 16:26:08.130; org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater; [Producer clientId=producer-1] Error while fetching metadata with correlation id 12 : {article=LEADER_NOT_AVAILABLE}
WARN  - 2020-02-13 16:26:08.235; org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater; [Producer clientId=producer-1] Error while fetching metadata with correlation id 13 : {article=LEADER_NOT_AVAILABLE}
WARN  - 2020-02-13 16:26:08.357; org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater; [Producer clientId=producer-1] Error while fetching metadata with correlation id 14 : {article=LEADER_NOT_AVAILABLE}
WARN  - 2020-02-13 16:26:08.468; org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater; [Producer clientId=producer-1] Error while fetching metadata with correlation id 15 : {article=LEADER_NOT_AVAILABLE}
WARN  - 2020-02-13 16:26:08.571; org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater; [Producer clientId=producer-1] Error while fetching metadata with correlation id 16 : {article=LEADER_NOT_AVAILABLE}
INFO  - 2020-02-13 16:27:30.260; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 16:27:30.268; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 16:27:30.270; org.apache.kafka.clients.producer.KafkaProducer; [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
INFO  - 2020-02-13 16:27:30.275; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 16:27:31.867; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-13 16:27:34.378; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-13 16:27:34.859; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 16:27:35.730; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 16:27:41.630; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 16:27:43.573; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 16:27:43.720; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 16:27:43.721; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 16:27:43.735; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 16:27:44.147; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 16:27:44.153; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 16:27:44.158; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 16:27:44.159; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 16:27:44.159; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 16:27:44.197; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 176
INFO  - 2020-02-13 16:27:44.199; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 16:27:44.200; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 16:27:44.394; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 10011 ms
INFO  - 2020-02-13 16:27:44.578; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-13 16:27:45.397; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-13 16:27:46.091; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1513 ms
INFO  - 2020-02-13 16:30:28.219; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-13 16:30:28.650; org.apache.kafka.common.config.AbstractConfig; ProducerConfig values: 
	acks = 1
	batch.size = 1638
	bootstrap.servers = [192.168.198.128:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  - 2020-02-13 16:30:28.677; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 16:30:28.678; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 16:30:28.704; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 16:31:25.164; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 16:31:25.227; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 16:31:25.229; org.apache.kafka.clients.producer.KafkaProducer; [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
INFO  - 2020-02-13 16:31:25.232; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 16:31:26.281; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-13 16:31:28.711; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-13 16:31:29.109; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 16:31:30.086; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 16:31:36.636; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 16:31:38.555; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 16:31:38.682; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 16:31:38.683; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 16:31:38.695; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 16:31:39.426; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 16:31:39.436; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 16:31:39.443; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 16:31:39.444; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 16:31:39.444; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 16:31:39.526; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 178
INFO  - 2020-02-13 16:31:39.535; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 16:31:39.535; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 16:31:39.741; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 11027 ms
INFO  - 2020-02-13 16:31:40.010; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-13 16:31:41.727; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-13 16:31:43.154; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 3144 ms
INFO  - 2020-02-13 16:32:13.168; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-13 16:32:13.771; org.apache.kafka.common.config.AbstractConfig; ProducerConfig values: 
	acks = 1
	batch.size = 1638
	bootstrap.servers = [192.168.198.128:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  - 2020-02-13 16:32:13.833; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 16:32:13.835; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 16:32:13.849; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 16:32:37.740; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 16:32:37.744; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 16:32:37.746; org.apache.kafka.clients.producer.KafkaProducer; [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
INFO  - 2020-02-13 16:32:37.750; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 16:32:38.889; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-13 16:32:41.174; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-13 16:32:41.454; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 16:32:41.997; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 16:32:47.812; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 16:32:49.677; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 16:32:49.785; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 16:32:49.786; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 16:32:49.798; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 16:32:50.203; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 16:32:50.207; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 16:32:50.220; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 16:32:50.220; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 16:32:50.220; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 16:32:50.278; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 180
INFO  - 2020-02-13 16:32:50.282; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 16:32:50.283; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 16:32:50.484; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 9305 ms
INFO  - 2020-02-13 16:32:50.706; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-13 16:32:51.474; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-13 16:32:51.972; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1265 ms
INFO  - 2020-02-13 16:33:01.227; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 16:33:01.234; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 16:33:01.236; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 16:33:15.318; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-13 16:33:15.776; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 16:33:16.346; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 16:33:22.577; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 16:33:24.958; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 16:33:25.162; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 16:33:25.163; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 16:33:25.180; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 16:33:25.738; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 16:33:25.742; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 16:33:25.748; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 16:33:25.749; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 16:33:25.749; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 16:33:25.819; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 182
INFO  - 2020-02-13 16:33:25.824; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [1708E-0]
INFO  - 2020-02-13 16:33:25.824; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [1708E-0]
INFO  - 2020-02-13 16:33:26.005; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 10682 ms
INFO  - 2020-02-13 16:33:26.296; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-13 16:33:27.516; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-13 16:33:28.430; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 2133 ms
INFO  - 2020-02-13 16:33:44.774; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-13 16:33:50.383; org.apache.kafka.common.config.AbstractConfig; ProducerConfig values: 
	acks = 1
	batch.size = 1638
	bootstrap.servers = [192.168.198.128:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  - 2020-02-13 16:33:50.439; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 16:33:50.439; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 16:33:50.452; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 16:36:04.848; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 16:36:04.853; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 16:36:04.854; org.apache.kafka.clients.producer.KafkaProducer; [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
INFO  - 2020-02-13 16:36:04.857; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 16:36:06.761; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-13 16:36:17.762; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-13 16:36:18.091; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 16:36:19.468; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
WARN  - 2020-02-13 16:36:20.538; org.springframework.context.support.AbstractApplicationContext; Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'messageListenerContainer' defined in class path resource [consumer.xml]: Cannot resolve reference to bean 'containerProperties' while setting constructor argument; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'containerProperties' defined in class path resource [consumer.xml]: Cannot resolve reference to bean 'MsgListener' while setting bean property 'messageListener'; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named 'MsgListener' available
ERROR - 2020-02-13 16:36:20.548; org.springframework.web.context.ContextLoader; Context initialization failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'messageListenerContainer' defined in class path resource [consumer.xml]: Cannot resolve reference to bean 'containerProperties' while setting constructor argument; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'containerProperties' defined in class path resource [consumer.xml]: Cannot resolve reference to bean 'MsgListener' while setting bean property 'messageListener'; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named 'MsgListener' available
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:378)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:110)
	at org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:676)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:188)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1325)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1171)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549)
	at org.springframework.web.context.ContextLoader.configureAndRefreshWebApplicationContext(ContextLoader.java:400)
	at org.springframework.web.context.ContextLoader.initWebApplicationContext(ContextLoader.java:291)
	at org.springframework.web.context.ContextLoaderListener.contextInitialized(ContextLoaderListener.java:103)
	at org.eclipse.jetty.server.handler.ContextHandler.callContextInitialized(ContextHandler.java:890)
	at org.eclipse.jetty.servlet.ServletContextHandler.callContextInitialized(ServletContextHandler.java:558)
	at org.eclipse.jetty.server.handler.ContextHandler.startContext(ContextHandler.java:853)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:370)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.startWebapp(JettyWebAppContext.java:360)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:785)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:287)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.doStart(JettyWebAppContext.java:428)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo.restartWebApp(JettyRunMojo.java:553)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo$1.onPathWatchEvents(JettyRunMojo.java:405)
	at org.eclipse.jetty.util.PathWatcher.notifyEvents(PathWatcher.java:1366)
	at org.eclipse.jetty.util.PathWatcher.run(PathWatcher.java:1190)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'containerProperties' defined in class path resource [consumer.xml]: Cannot resolve reference to bean 'MsgListener' while setting bean property 'messageListener'; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named 'MsgListener' available
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:378)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:110)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1665)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1417)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:367)
	... 34 more
Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named 'MsgListener' available
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanDefinition(DefaultListableBeanFactory.java:775)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getMergedLocalBeanDefinition(AbstractBeanFactory.java:1221)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:294)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:367)
	... 44 more
INFO  - 2020-02-13 16:39:28.772; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-13 16:39:29.413; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 16:39:30.128; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
WARN  - 2020-02-13 16:39:31.349; org.springframework.context.support.AbstractApplicationContext; Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'messageListenerContainer' defined in class path resource [consumer.xml]: Cannot resolve reference to bean 'containerProperties' while setting constructor argument; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'containerProperties' defined in class path resource [consumer.xml]: Cannot resolve reference to bean 'MsgListener' while setting bean property 'messageListener'; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named 'MsgListener' available
ERROR - 2020-02-13 16:39:31.359; org.springframework.web.context.ContextLoader; Context initialization failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'messageListenerContainer' defined in class path resource [consumer.xml]: Cannot resolve reference to bean 'containerProperties' while setting constructor argument; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'containerProperties' defined in class path resource [consumer.xml]: Cannot resolve reference to bean 'MsgListener' while setting bean property 'messageListener'; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named 'MsgListener' available
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:378)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:110)
	at org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:676)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:188)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1325)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1171)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549)
	at org.springframework.web.context.ContextLoader.configureAndRefreshWebApplicationContext(ContextLoader.java:400)
	at org.springframework.web.context.ContextLoader.initWebApplicationContext(ContextLoader.java:291)
	at org.springframework.web.context.ContextLoaderListener.contextInitialized(ContextLoaderListener.java:103)
	at org.eclipse.jetty.server.handler.ContextHandler.callContextInitialized(ContextHandler.java:890)
	at org.eclipse.jetty.servlet.ServletContextHandler.callContextInitialized(ServletContextHandler.java:558)
	at org.eclipse.jetty.server.handler.ContextHandler.startContext(ContextHandler.java:853)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:370)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.startWebapp(JettyWebAppContext.java:360)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:785)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:287)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.doStart(JettyWebAppContext.java:428)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:138)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)
	at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:113)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.doStart(ContextHandlerCollection.java:167)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:138)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)
	at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:113)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:138)
	at org.eclipse.jetty.server.Server.start(Server.java:419)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:108)
	at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:113)
	at org.eclipse.jetty.server.Server.doStart(Server.java:386)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.maven.plugin.AbstractJettyMojo.startJetty(AbstractJettyMojo.java:467)
	at org.eclipse.jetty.maven.plugin.AbstractJettyMojo.execute(AbstractJettyMojo.java:329)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo.execute(JettyRunMojo.java:179)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:210)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:156)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:148)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:117)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:305)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:957)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:289)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:193)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'containerProperties' defined in class path resource [consumer.xml]: Cannot resolve reference to bean 'MsgListener' while setting bean property 'messageListener'; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named 'MsgListener' available
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:378)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:110)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1665)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1417)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:367)
	... 69 more
Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named 'MsgListener' available
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanDefinition(DefaultListableBeanFactory.java:775)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getMergedLocalBeanDefinition(AbstractBeanFactory.java:1221)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:294)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:367)
	... 79 more
INFO  - 2020-02-13 16:39:58.273; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-13 16:39:58.925; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 16:39:59.449; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 16:40:05.878; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 16:40:07.829; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 16:40:07.937; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 16:40:07.937; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 16:40:07.945; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 16:40:08.422; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 16:40:08.427; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 16:40:08.432; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 16:40:08.433; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 16:40:08.433; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 16:40:08.510; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 184
INFO  - 2020-02-13 16:40:08.518; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-13 16:40:08.519; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-13 16:40:08.859; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 10573 ms
INFO  - 2020-02-13 16:40:08.982; org.apache.kafka.clients.consumer.internals.Fetcher; [Consumer clientId=consumer-1, groupId=test-consumer-group] Resetting offset for partition article-0 to offset 4.
INFO  - 2020-02-13 16:40:09.104; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-13 16:40:09.913; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-13 16:40:11.325; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 2219 ms
INFO  - 2020-02-13 16:40:26.775; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-13 16:40:35.097; org.apache.kafka.common.config.AbstractConfig; ProducerConfig values: 
	acks = 1
	batch.size = 1638
	bootstrap.servers = [192.168.198.128:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  - 2020-02-13 16:40:35.151; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 16:40:35.152; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 16:40:35.169; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
ERROR - 2020-02-13 16:40:35.813; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = article, partition = 0, offset = 4, CreateTime = 1581583235184, serialized key size = -1, serialized value size = 8, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = "add141")
org.springframework.jdbc.BadSqlGrammarException: 
### Error updating database.  Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '=articleType+1 where id='"141"'' at line 1
### The error may involve com.yangjinjing.cms.dao.ArticleMapper.addLiuLan-Inline
### The error occurred while setting parameters
### SQL: update cms_article articleType=articleType+1 where id=?
### Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '=articleType+1 where id='"141"'' at line 1
; bad SQL grammar []; nested exception is com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '=articleType+1 where id='"141"'' at line 1
	at org.springframework.jdbc.support.SQLErrorCodeSQLExceptionTranslator.doTranslate(SQLErrorCodeSQLExceptionTranslator.java:234)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy53.update(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.update(SqlSessionTemplate.java:295)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:62)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy54.addLiuLan(Unknown Source)
	at com.yangjinjing.cms.service.impl.ArticleServiceImpl.addLiuLan(ArticleServiceImpl.java:185)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
	at com.sun.proxy.$Proxy58.addLiuLan(Unknown Source)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:34)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:1)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '=articleType+1 where id='"141"'' at line 1
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.Util.getInstance(Util.java:381)
	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1030)
	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:956)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3491)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy85.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 30 more
INFO  - 2020-02-13 16:41:45.746; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 16:41:45.758; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 16:41:45.760; org.apache.kafka.clients.producer.KafkaProducer; [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
INFO  - 2020-02-13 16:41:45.765; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 16:41:47.102; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-13 16:41:50.219; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-13 16:41:50.663; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 16:41:51.592; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 16:41:58.425; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 16:42:00.610; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 16:42:00.776; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 16:42:00.777; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 16:42:00.800; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 16:42:01.417; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 16:42:01.421; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 16:42:01.425; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 16:42:01.426; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 16:42:01.427; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 16:42:01.478; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 186
INFO  - 2020-02-13 16:42:01.482; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-13 16:42:01.483; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-13 16:42:01.711; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 11484 ms
INFO  - 2020-02-13 16:42:01.943; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-13 16:42:02.837; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-13 16:42:03.411; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1468 ms
INFO  - 2020-02-13 16:42:44.197; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-13 16:42:44.653; org.apache.kafka.common.config.AbstractConfig; ProducerConfig values: 
	acks = 1
	batch.size = 1638
	bootstrap.servers = [192.168.198.128:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  - 2020-02-13 16:42:44.711; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 16:42:44.712; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 16:42:44.733; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 16:44:01.317; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 16:44:01.327; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 16:44:01.330; org.apache.kafka.clients.producer.KafkaProducer; [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
INFO  - 2020-02-13 16:44:01.333; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 16:44:03.100; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-13 16:44:06.034; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-13 16:44:06.459; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 16:44:07.269; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
WARN  - 2020-02-13 16:44:09.172; org.springframework.context.support.AbstractApplicationContext; Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'messageListenerContainer' defined in class path resource [consumer.xml]: Cannot resolve reference to bean 'containerProperties' while setting constructor argument; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'containerProperties' defined in class path resource [consumer.xml]: Cannot resolve reference to bean 'msgListener' while setting bean property 'messageListener'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'msgListener': Unsatisfied dependency expressed through field 'service'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleServiceImpl': Unsatisfied dependency expressed through field 'dao'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleMapper' defined in file [C:\Users\Legna\workspace\yangjinjing-cms\target\classes\com\yangjinjing\cms\dao\ArticleMapper.class]: Unsatisfied dependency expressed through bean property 'sqlSessionFactory'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [spring-beans.xml]: Invocation of init method failed; nested exception is java.lang.Error: Unresolved compilation problem: 
	The annotation @Param must define the attribute value

ERROR - 2020-02-13 16:44:09.189; org.springframework.web.context.ContextLoader; Context initialization failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'messageListenerContainer' defined in class path resource [consumer.xml]: Cannot resolve reference to bean 'containerProperties' while setting constructor argument; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'containerProperties' defined in class path resource [consumer.xml]: Cannot resolve reference to bean 'msgListener' while setting bean property 'messageListener'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'msgListener': Unsatisfied dependency expressed through field 'service'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleServiceImpl': Unsatisfied dependency expressed through field 'dao'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleMapper' defined in file [C:\Users\Legna\workspace\yangjinjing-cms\target\classes\com\yangjinjing\cms\dao\ArticleMapper.class]: Unsatisfied dependency expressed through bean property 'sqlSessionFactory'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [spring-beans.xml]: Invocation of init method failed; nested exception is java.lang.Error: Unresolved compilation problem: 
	The annotation @Param must define the attribute value

	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:378)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:110)
	at org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:676)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:188)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1325)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1171)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549)
	at org.springframework.web.context.ContextLoader.configureAndRefreshWebApplicationContext(ContextLoader.java:400)
	at org.springframework.web.context.ContextLoader.initWebApplicationContext(ContextLoader.java:291)
	at org.springframework.web.context.ContextLoaderListener.contextInitialized(ContextLoaderListener.java:103)
	at org.eclipse.jetty.server.handler.ContextHandler.callContextInitialized(ContextHandler.java:890)
	at org.eclipse.jetty.servlet.ServletContextHandler.callContextInitialized(ServletContextHandler.java:558)
	at org.eclipse.jetty.server.handler.ContextHandler.startContext(ContextHandler.java:853)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:370)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.startWebapp(JettyWebAppContext.java:360)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:785)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:287)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.doStart(JettyWebAppContext.java:428)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo.restartWebApp(JettyRunMojo.java:553)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo$1.onPathWatchEvents(JettyRunMojo.java:405)
	at org.eclipse.jetty.util.PathWatcher.notifyEvents(PathWatcher.java:1366)
	at org.eclipse.jetty.util.PathWatcher.run(PathWatcher.java:1190)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'containerProperties' defined in class path resource [consumer.xml]: Cannot resolve reference to bean 'msgListener' while setting bean property 'messageListener'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'msgListener': Unsatisfied dependency expressed through field 'service'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleServiceImpl': Unsatisfied dependency expressed through field 'dao'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleMapper' defined in file [C:\Users\Legna\workspace\yangjinjing-cms\target\classes\com\yangjinjing\cms\dao\ArticleMapper.class]: Unsatisfied dependency expressed through bean property 'sqlSessionFactory'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [spring-beans.xml]: Invocation of init method failed; nested exception is java.lang.Error: Unresolved compilation problem: 
	The annotation @Param must define the attribute value

	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:378)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:110)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1665)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1417)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:367)
	... 34 more
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'msgListener': Unsatisfied dependency expressed through field 'service'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleServiceImpl': Unsatisfied dependency expressed through field 'dao'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleMapper' defined in file [C:\Users\Legna\workspace\yangjinjing-cms\target\classes\com\yangjinjing\cms\dao\ArticleMapper.class]: Unsatisfied dependency expressed through bean property 'sqlSessionFactory'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [spring-beans.xml]: Invocation of init method failed; nested exception is java.lang.Error: Unresolved compilation problem: 
	The annotation @Param must define the attribute value

	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:596)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:374)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1395)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:367)
	... 44 more
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleServiceImpl': Unsatisfied dependency expressed through field 'dao'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleMapper' defined in file [C:\Users\Legna\workspace\yangjinjing-cms\target\classes\com\yangjinjing\cms\dao\ArticleMapper.class]: Unsatisfied dependency expressed through bean property 'sqlSessionFactory'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [spring-beans.xml]: Invocation of init method failed; nested exception is java.lang.Error: Unresolved compilation problem: 
	The annotation @Param must define the attribute value

	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:596)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:374)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1395)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:277)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1247)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1167)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:593)
	... 54 more
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleMapper' defined in file [C:\Users\Legna\workspace\yangjinjing-cms\target\classes\com\yangjinjing\cms\dao\ArticleMapper.class]: Unsatisfied dependency expressed through bean property 'sqlSessionFactory'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [spring-beans.xml]: Invocation of init method failed; nested exception is java.lang.Error: Unresolved compilation problem: 
	The annotation @Param must define the attribute value

	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireByType(AbstractAutowireCapableBeanFactory.java:1499)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1379)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:277)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1247)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1167)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:593)
	... 67 more
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [spring-beans.xml]: Invocation of init method failed; nested exception is java.lang.Error: Unresolved compilation problem: 
	The annotation @Param must define the attribute value

	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1762)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:593)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:277)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1247)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1167)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireByType(AbstractAutowireCapableBeanFactory.java:1484)
	... 78 more
Caused by: java.lang.Error: Unresolved compilation problem: 
	The annotation @Param must define the attribute value

	at com.yangjinjing.cms.dao.ArticleMapper.<clinit>(ArticleMapper.java:164)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:348)
	at org.apache.ibatis.io.ClassLoaderWrapper.classForName(ClassLoaderWrapper.java:186)
	at org.apache.ibatis.io.ClassLoaderWrapper.classForName(ClassLoaderWrapper.java:89)
	at org.apache.ibatis.io.Resources.classForName(Resources.java:261)
	at org.apache.ibatis.builder.xml.XMLMapperBuilder.bindMapperForNamespace(XMLMapperBuilder.java:398)
	at org.apache.ibatis.builder.xml.XMLMapperBuilder.parse(XMLMapperBuilder.java:94)
	at org.mybatis.spring.SqlSessionFactoryBean.buildSqlSessionFactory(SqlSessionFactoryBean.java:520)
	at org.mybatis.spring.SqlSessionFactoryBean.afterPropertiesSet(SqlSessionFactoryBean.java:381)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1821)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1758)
	... 88 more
INFO  - 2020-02-13 16:44:15.546; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-13 16:44:15.861; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 16:44:16.692; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 16:44:21.945; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 16:44:23.796; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 16:44:23.943; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 16:44:23.944; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 16:44:23.955; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 16:44:24.369; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 16:44:24.375; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 16:44:24.382; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 16:44:24.383; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 16:44:24.383; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 16:44:24.412; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 188
INFO  - 2020-02-13 16:44:24.415; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-13 16:44:24.417; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-13 16:44:24.558; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 9009 ms
INFO  - 2020-02-13 16:44:24.791; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-13 16:44:25.537; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-13 16:44:26.062; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1270 ms
INFO  - 2020-02-13 16:44:51.729; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-13 16:44:56.469; org.apache.kafka.common.config.AbstractConfig; ProducerConfig values: 
	acks = 1
	batch.size = 1638
	bootstrap.servers = [192.168.198.128:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  - 2020-02-13 16:44:56.498; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 16:44:56.498; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 16:44:56.511; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 16:52:29.472; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 16:52:29.481; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 16:52:29.482; org.apache.kafka.clients.producer.KafkaProducer; [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
INFO  - 2020-02-13 16:52:29.485; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 16:52:30.681; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-13 16:52:34.522; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-13 16:52:34.892; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 16:52:35.593; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 16:52:41.487; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 16:52:43.575; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 16:52:43.722; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 16:52:43.722; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 16:52:43.731; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 16:52:44.135; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 16:52:44.156; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 16:52:44.169; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 16:52:44.170; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 16:52:44.171; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 16:52:44.259; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 190
INFO  - 2020-02-13 16:52:44.263; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-13 16:52:44.265; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-13 16:52:44.490; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 9961 ms
INFO  - 2020-02-13 16:52:44.698; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-13 16:52:45.712; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-13 16:52:46.260; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1562 ms
INFO  - 2020-02-13 16:53:00.062; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 16:53:00.076; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 16:53:00.079; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 16:53:03.839; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-13 16:53:04.165; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 16:53:04.860; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 16:53:10.577; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 16:53:12.762; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 16:53:12.879; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 16:53:12.879; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 16:53:12.889; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 16:53:13.565; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 16:53:13.575; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 16:53:13.591; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 16:53:13.592; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 16:53:13.593; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 16:53:13.618; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 192
INFO  - 2020-02-13 16:53:13.621; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-13 16:53:13.621; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-13 16:53:13.855; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 10012 ms
INFO  - 2020-02-13 16:53:14.157; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-13 16:53:15.864; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-13 16:53:16.700; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 2542 ms
INFO  - 2020-02-13 16:53:19.284; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 16:53:19.293; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 16:53:19.296; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 16:53:45.202; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-13 16:53:45.765; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 16:53:46.360; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 16:53:53.675; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 16:53:55.800; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 16:53:55.940; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 16:53:55.940; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 16:53:55.956; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 16:53:56.610; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 16:53:56.617; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 16:53:56.622; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 16:53:56.623; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 16:53:56.624; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 16:53:56.671; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 194
INFO  - 2020-02-13 16:53:56.675; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-13 16:53:56.675; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-13 16:53:57.340; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 12128 ms
INFO  - 2020-02-13 16:53:57.588; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-13 16:53:58.288; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-13 16:53:59.221; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1633 ms
INFO  - 2020-02-13 17:21:12.689; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-13 17:21:13.216; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 17:21:13.855; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 17:21:19.229; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 17:21:21.234; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 17:21:21.384; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 17:21:21.384; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 17:21:21.396; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 17:21:22.092; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 17:21:22.104; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 17:21:22.107; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 17:21:22.108; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 17:21:22.108; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 17:21:22.556; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 196
INFO  - 2020-02-13 17:21:22.563; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-13 17:21:22.563; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-13 17:21:22.683; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 9990 ms
INFO  - 2020-02-13 17:21:23.088; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-13 17:21:23.992; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-13 17:21:24.498; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1409 ms
INFO  - 2020-02-13 17:29:40.086; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-13 17:32:19.719; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-13 17:32:20.081; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@6895a785, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@184f6be2, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@56aac163, org.springframework.test.context.support.DirtiesContextTestExecutionListener@1f7030a6, org.springframework.test.context.transaction.TransactionalTestExecutionListener@5a1c0542, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@396f6598]
INFO  - 2020-02-13 17:32:21.138; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 17:32:22.218; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 17:32:33.895; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 17:32:35.841; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 17:32:35.983; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 17:32:35.984; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 17:32:36.008; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 17:32:36.525; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 17:32:36.528; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 17:32:36.539; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 17:32:36.540; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 17:32:36.541; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 17:32:37.544; org.apache.kafka.common.config.AbstractConfig; ProducerConfig values: 
	acks = 1
	batch.size = 1638
	bootstrap.servers = [192.168.198.128:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  - 2020-02-13 17:32:37.706; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Attempt to heartbeat failed since group is rebalancing
INFO  - 2020-02-13 17:32:37.731; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions [article-0]
INFO  - 2020-02-13 17:32:37.732; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: [article-0]
INFO  - 2020-02-13 17:32:37.732; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 17:32:37.743; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 197
INFO  - 2020-02-13 17:32:37.744; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-13 17:32:37.745; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-13 17:32:37.593; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 17:32:37.869; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 17:32:37.873; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 197
INFO  - 2020-02-13 17:32:37.877; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-13 17:32:37.878; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
WARN  - 2020-02-13 17:32:38.097; org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater; [Producer clientId=producer-1] Error while fetching metadata with correlation id 2 : {articles=LEADER_NOT_AVAILABLE}
INFO  - 2020-02-13 17:32:38.099; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
WARN  - 2020-02-13 17:32:38.450; org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater; [Producer clientId=producer-1] Error while fetching metadata with correlation id 5 : {articles=LEADER_NOT_AVAILABLE}
INFO  - 2020-02-13 17:32:38.624; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 17:32:38.734; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 17:32:38.737; org.apache.kafka.clients.producer.KafkaProducer; [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
INFO  - 2020-02-13 17:32:38.766; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 17:32:40.747; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Attempt to heartbeat failed since group is rebalancing
INFO  - 2020-02-13 17:32:40.747; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 17:32:40.748; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 17:32:40.748; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 17:32:40.755; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 198
INFO  - 2020-02-13 17:32:40.756; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-13 17:32:40.756; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-13 17:34:24.347; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-13 17:34:24.370; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@6895a785, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@184f6be2, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@56aac163, org.springframework.test.context.support.DirtiesContextTestExecutionListener@1f7030a6, org.springframework.test.context.transaction.TransactionalTestExecutionListener@5a1c0542, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@396f6598]
INFO  - 2020-02-13 17:34:24.986; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-13 17:34:25.593; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-13 17:34:31.553; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-13 17:34:33.417; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-13 17:34:33.556; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 17:34:33.557; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 17:34:33.563; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-13 17:34:33.897; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 17:34:33.904; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-13 17:34:33.909; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 17:34:33.910; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 17:34:33.912; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 17:34:34.392; org.apache.kafka.common.config.AbstractConfig; ProducerConfig values: 
	acks = 1
	batch.size = 1638
	bootstrap.servers = [192.168.198.128:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  - 2020-02-13 17:34:34.453; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 17:34:34.621; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 17:34:34.639; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-13 17:34:34.700; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-13 17:34:34.785; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Attempt to heartbeat failed since group is rebalancing
INFO  - 2020-02-13 17:34:34.792; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions [article-0]
INFO  - 2020-02-13 17:34:34.792; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: [article-0]
INFO  - 2020-02-13 17:34:34.792; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 17:34:34.812; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-13 17:34:34.814; org.apache.kafka.clients.producer.KafkaProducer; [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
INFO  - 2020-02-13 17:34:34.820; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 199
INFO  - 2020-02-13 17:34:34.822; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-13 17:34:34.823; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-13 17:34:34.823; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-13 17:34:49.825; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Attempt to heartbeat failed since group is rebalancing
INFO  - 2020-02-13 17:34:49.825; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-13 17:34:49.825; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-13 17:34:49.825; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-13 17:34:49.831; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 200
INFO  - 2020-02-13 17:34:49.831; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-13 17:34:49.831; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-13 17:36:23.910; org.apache.kafka.common.config.AbstractConfig; ProducerConfig values: 
	acks = 1
	batch.size = 1638
	bootstrap.servers = [192.168.198.128:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  - 2020-02-13 17:36:23.951; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-13 17:36:23.951; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-13 17:36:23.962; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
ERROR - 2020-02-13 17:36:24.064; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = article, partition = 0, offset = 8, CreateTime = 1581586583965, serialized key size = -1, serialized value size = 8, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = "add141")
com.alibaba.fastjson.JSONException: syntax error, expect {, actual string, pos 0
	at com.alibaba.fastjson.parser.deserializer.JavaBeanDeserializer.deserialze(JavaBeanDeserializer.java:232)
	at com.alibaba.fastjson.parser.deserializer.ASMJavaBeanDeserializer.parseRest(ASMJavaBeanDeserializer.java:100)
	at Fastjson_ASM_Article_1.deserialze(Unknown Source)
	at com.alibaba.fastjson.parser.DefaultJSONParser.parseObject(DefaultJSONParser.java:551)
	at com.alibaba.fastjson.JSON.parseObject(JSON.java:251)
	at com.alibaba.fastjson.JSON.parseObject(JSON.java:227)
	at com.alibaba.fastjson.JSON.parseObject(JSON.java:186)
	at com.alibaba.fastjson.JSON.parseObject(JSON.java:304)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:40)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:1)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
ERROR - 2020-02-13 17:36:43.766; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = article, partition = 0, offset = 9, CreateTime = 1581586603684, serialized key size = -1, serialized value size = 8, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = "add141")
com.alibaba.fastjson.JSONException: syntax error, expect {, actual string, pos 0
	at com.alibaba.fastjson.parser.deserializer.JavaBeanDeserializer.deserialze(JavaBeanDeserializer.java:232)
	at com.alibaba.fastjson.parser.deserializer.ASMJavaBeanDeserializer.parseRest(ASMJavaBeanDeserializer.java:100)
	at Fastjson_ASM_Article_1.deserialze(Unknown Source)
	at com.alibaba.fastjson.parser.DefaultJSONParser.parseObject(DefaultJSONParser.java:551)
	at com.alibaba.fastjson.JSON.parseObject(JSON.java:251)
	at com.alibaba.fastjson.JSON.parseObject(JSON.java:227)
	at com.alibaba.fastjson.JSON.parseObject(JSON.java:186)
	at com.alibaba.fastjson.JSON.parseObject(JSON.java:304)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:40)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:1)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
INFO  - 2020-02-14 13:41:41.561; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-14 13:41:41.667; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@131276c2, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@26aa12dd, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3fd7a715, org.springframework.test.context.support.DirtiesContextTestExecutionListener@711f39f9, org.springframework.test.context.transaction.TransactionalTestExecutionListener@71bbf57e, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@7f13d6e]
INFO  - 2020-02-14 13:41:43.021; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 13:41:44.906; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 13:41:59.894; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 13:42:23.381; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 13:42:23.678; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 13:42:23.678; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 13:42:23.695; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
ERROR - 2020-02-14 13:42:24.545; org.springframework.data.elasticsearch.repository.support.AbstractElasticsearchRepository; failed to load elasticsearch nodes : org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes are available: [{#transport#-1}{iIvrhda-QJGG_p-PjjNkhw}{192.168.198.128}{192.168.198.128:9300}]
INFO  - 2020-02-14 13:42:25.197; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 13:42:25.202; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 13:42:25.203; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 13:44:29.002; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-14 13:44:29.039; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@131276c2, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@26aa12dd, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3fd7a715, org.springframework.test.context.support.DirtiesContextTestExecutionListener@711f39f9, org.springframework.test.context.transaction.TransactionalTestExecutionListener@71bbf57e, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@7f13d6e]
INFO  - 2020-02-14 13:44:29.523; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 13:44:30.094; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 13:44:35.984; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 13:44:58.664; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 13:44:58.776; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 13:44:58.776; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 13:44:58.783; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
ERROR - 2020-02-14 13:44:59.108; org.springframework.data.elasticsearch.repository.support.AbstractElasticsearchRepository; failed to load elasticsearch nodes : org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes are available: [{#transport#-1}{I-2iYJuHS7WEjhcrJrTOHA}{192.168.198.128}{192.168.198.128:9300}]
INFO  - 2020-02-14 13:44:59.370; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 13:44:59.385; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 13:44:59.388; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 14:10:33.856; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-14 14:10:33.888; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@6895a785, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@184f6be2, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@56aac163, org.springframework.test.context.support.DirtiesContextTestExecutionListener@1f7030a6, org.springframework.test.context.transaction.TransactionalTestExecutionListener@5a1c0542, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@396f6598]
INFO  - 2020-02-14 14:10:34.528; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 14:10:35.231; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 14:10:37.538; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 14:10:38.436; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 14:10:38.436; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 14:10:38.446; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 14:10:42.663; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 14:10:45.574; org.apache.kafka.common.config.AbstractConfig; ProducerConfig values: 
	acks = 1
	batch.size = 1638
	bootstrap.servers = [192.168.198.128:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  - 2020-02-14 14:10:45.613; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 14:10:45.613; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 14:10:45.661; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 14:10:49.940; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 14:10:49.945; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 14:10:49.946; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 14:10:51.256; org.apache.kafka.clients.producer.KafkaProducer; [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
INFO  - 2020-02-14 14:13:00.887; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-14 14:13:00.917; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@6895a785, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@184f6be2, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@56aac163, org.springframework.test.context.support.DirtiesContextTestExecutionListener@1f7030a6, org.springframework.test.context.transaction.TransactionalTestExecutionListener@5a1c0542, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@396f6598]
INFO  - 2020-02-14 14:13:01.442; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 14:13:02.074; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 14:13:04.066; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 14:13:04.973; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 14:13:04.973; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 14:13:04.982; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 14:13:05.457; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 14:13:05.461; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 14:13:05.470; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 14:13:05.472; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 14:13:05.473; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 14:13:05.549; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 202
INFO  - 2020-02-14 14:13:05.552; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 14:13:05.552; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 14:13:06.121; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
ERROR - 2020-02-14 14:13:07.685; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = article, partition = 0, offset = 32, CreateTime = 1581660646854, serialized key size = -1, serialized value size = 804, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"articleType":0,"categoryId":1,"channelId":1,"commentCnt":0,"complainCnt":0,"content":"3605000APP... ...  1535","created":1581660645216,"deleted":0,"hits":211066963,"hot":1,"picture":"20191224/f018506e-41ff-4f22-b988-2d0ea0b41c1d","status":0,"title":"3605000APP","updated":1581660645216,"userId":68})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.yangjinjing.cms.dao.ArticleMapper.add-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article(title,content,picture,channel_id,category_id,user_id,hits,hot,status,deleted,created,updated,commentCnt,articleType) VALUES(?,?,?,?,?,?,0,0,0,0,now(),now(),0,?)
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy27.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy28.add(Unknown Source)
	at com.yangjinjing.cms.service.impl.ArticleServiceImpl.add(ArticleServiceImpl.java:65)
	at sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
	at com.sun.proxy.$Proxy32.add(Unknown Source)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:30)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:1)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy39.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 29 more
ERROR - 2020-02-14 14:13:07.982; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = article, partition = 0, offset = 43, CreateTime = 1581660647420, serialized key size = -1, serialized value size = 746, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"articleType":0,"categoryId":1,"channelId":1,"commentCnt":0,"complainCnt":0,"content":"81App Store5002.01  App Store500 2008App Store","created":1581660645216,"deleted":0,"hits":1239313899,"hot":1,"picture":"20191224/f018506e-41ff-4f22-b988-2d0ea0b41c1d","status":0,"title":"81App Store5002","updated":1581660645216,"userId":68})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.yangjinjing.cms.dao.ArticleMapper.add-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article(title,content,picture,channel_id,category_id,user_id,hits,hot,status,deleted,created,updated,commentCnt,articleType) VALUES(?,?,?,?,?,?,0,0,0,0,now(),now(),0,?)
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy27.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy28.add(Unknown Source)
	at com.yangjinjing.cms.service.impl.ArticleServiceImpl.add(ArticleServiceImpl.java:65)
	at sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
	at com.sun.proxy.$Proxy32.add(Unknown Source)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:30)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:1)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy39.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 29 more
ERROR - 2020-02-14 14:13:08.013; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = article, partition = 0, offset = 45, CreateTime = 1581660647442, serialized key size = -1, serialized value size = 739, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"articleType":0,"categoryId":1,"channelId":1,"commentCnt":0,"complainCnt":0,"content":"91 | 20197000  20197000 QuestMobile201912316985.86","created":1581660645216,"deleted":0,"hits":-1556579589,"hot":1,"picture":"20191224/f018506e-41ff-4f22-b988-2d0ea0b41c1d","status":0,"title":"91  20197000","updated":1581660645216,"userId":68})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.yangjinjing.cms.dao.ArticleMapper.add-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article(title,content,picture,channel_id,category_id,user_id,hits,hot,status,deleted,created,updated,commentCnt,articleType) VALUES(?,?,?,?,?,?,0,0,0,0,now(),now(),0,?)
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy27.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy28.add(Unknown Source)
	at com.yangjinjing.cms.service.impl.ArticleServiceImpl.add(ArticleServiceImpl.java:65)
	at sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
	at com.sun.proxy.$Proxy32.add(Unknown Source)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:30)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:1)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy39.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 29 more
ERROR - 2020-02-14 14:13:08.184; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = article, partition = 0, offset = 53, CreateTime = 1581660647611, serialized key size = -1, serialized value size = 721, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"articleType":0,"categoryId":1,"channelId":1,"commentCnt":0,"complainCnt":0,"content":"Facebook  AI TikTok   |  8  TikTok    TikTok ","created":1581660645216,"deleted":0,"hits":-1870619130,"hot":0,"picture":"20191224/f018506e-41ff-4f22-b988-2d0ea0b41c1d","status":0,"title":"Facebook  AI TikTok     8 ","updated":1581660645216,"userId":68})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.yangjinjing.cms.dao.ArticleMapper.add-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article(title,content,picture,channel_id,category_id,user_id,hits,hot,status,deleted,created,updated,commentCnt,articleType) VALUES(?,?,?,?,?,?,0,0,0,0,now(),now(),0,?)
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy27.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy28.add(Unknown Source)
	at com.yangjinjing.cms.service.impl.ArticleServiceImpl.add(ArticleServiceImpl.java:65)
	at sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
	at com.sun.proxy.$Proxy32.add(Unknown Source)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:30)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:1)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy39.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 29 more
ERROR - 2020-02-14 14:13:08.193; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = article, partition = 0, offset = 54, CreateTime = 1581660647632, serialized key size = -1, serialized value size = 647, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"articleType":0,"categoryId":1,"channelId":1,"commentCnt":0,"complainCnt":0,"content":"Galaxy S20 /Galaxy Z Flip 100   Galaxy S20  S20 Galaxy Z Flip  Galaxy Z Flip","created":1581660645216,"deleted":0,"hits":-1115489210,"hot":0,"picture":"20191224/f018506e-41ff-4f22-b988-2d0ea0b41c1d","status":0,"title":"Galaxy S20 Galaxy Z Flip 100 ","updated":1581660645216,"userId":68})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.yangjinjing.cms.dao.ArticleMapper.add-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article(title,content,picture,channel_id,category_id,user_id,hits,hot,status,deleted,created,updated,commentCnt,articleType) VALUES(?,?,?,?,?,?,0,0,0,0,now(),now(),0,?)
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy27.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy28.add(Unknown Source)
	at com.yangjinjing.cms.service.impl.ArticleServiceImpl.add(ArticleServiceImpl.java:65)
	at sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
	at com.sun.proxy.$Proxy32.add(Unknown Source)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:30)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:1)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy39.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 29 more
ERROR - 2020-02-14 14:13:09.315; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = article, partition = 0, offset = 96, CreateTime = 1581660648491, serialized key size = -1, serialized value size = 726, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"articleType":0,"categoryId":1,"channelId":1,"commentCnt":0,"complainCnt":0,"content":"App Store20195005858 2008App Store155020191","created":1581660645216,"deleted":0,"hits":315212446,"hot":0,"picture":"20191224/f018506e-41ff-4f22-b988-2d0ea0b41c1d","status":0,"title":"App Store20195005858","updated":1581660645216,"userId":68})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.yangjinjing.cms.dao.ArticleMapper.add-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article(title,content,picture,channel_id,category_id,user_id,hits,hot,status,deleted,created,updated,commentCnt,articleType) VALUES(?,?,?,?,?,?,0,0,0,0,now(),now(),0,?)
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy27.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy28.add(Unknown Source)
	at com.yangjinjing.cms.service.impl.ArticleServiceImpl.add(ArticleServiceImpl.java:65)
	at sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
	at com.sun.proxy.$Proxy32.add(Unknown Source)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:30)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:1)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy39.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 29 more
INFO  - 2020-02-14 14:13:09.472; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 14:13:12.078; org.apache.kafka.common.config.AbstractConfig; ProducerConfig values: 
	acks = 1
	batch.size = 1638
	bootstrap.servers = [192.168.198.128:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  - 2020-02-14 14:13:12.149; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 14:13:12.149; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 14:13:12.168; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 14:13:12.914; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 14:13:12.924; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 14:13:12.926; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 14:13:14.077; org.apache.kafka.clients.producer.KafkaProducer; [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
INFO  - 2020-02-14 14:13:14.105; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-14 14:13:53.112; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-14 14:13:53.140; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@6895a785, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@184f6be2, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@56aac163, org.springframework.test.context.support.DirtiesContextTestExecutionListener@1f7030a6, org.springframework.test.context.transaction.TransactionalTestExecutionListener@5a1c0542, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@396f6598]
INFO  - 2020-02-14 14:13:53.642; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 14:13:54.295; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 14:13:56.155; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 14:13:57.142; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 14:13:57.142; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 14:13:57.152; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 14:13:57.445; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 14:13:57.447; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 14:13:57.451; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 14:13:57.451; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 14:13:57.451; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 14:13:57.476; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 204
INFO  - 2020-02-14 14:13:57.477; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 14:13:57.477; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 14:13:57.758; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
ERROR - 2020-02-14 14:13:58.777; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = article, partition = 0, offset = 185, CreateTime = 1581660792272, serialized key size = -1, serialized value size = 805, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"articleType":0,"categoryId":1,"channelId":1,"commentCnt":0,"complainCnt":0,"content":"3605000APP... ...  1535","created":1581660791982,"deleted":0,"hits":-716653934,"hot":0,"picture":"20191224/f018506e-41ff-4f22-b988-2d0ea0b41c1d","status":0,"title":"3605000APP","updated":1581660791982,"userId":68})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.yangjinjing.cms.dao.ArticleMapper.add-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article(title,content,picture,channel_id,category_id,user_id,hits,hot,status,deleted,created,updated,commentCnt,articleType) VALUES(?,?,?,?,?,?,0,0,0,0,now(),now(),0,?)
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy27.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy28.add(Unknown Source)
	at com.yangjinjing.cms.service.impl.ArticleServiceImpl.add(ArticleServiceImpl.java:65)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
	at com.sun.proxy.$Proxy32.add(Unknown Source)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:30)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:1)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy39.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 29 more
ERROR - 2020-02-14 14:13:59.091; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = article, partition = 0, offset = 196, CreateTime = 1581660792286, serialized key size = -1, serialized value size = 743, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"articleType":0,"categoryId":1,"channelId":1,"commentCnt":0,"complainCnt":0,"content":"81App Store5002.01  App Store500 2008App Store","created":1581660791982,"deleted":0,"hits":4822350,"hot":0,"picture":"20191224/f018506e-41ff-4f22-b988-2d0ea0b41c1d","status":0,"title":"81App Store5002","updated":1581660791982,"userId":68})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.yangjinjing.cms.dao.ArticleMapper.add-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article(title,content,picture,channel_id,category_id,user_id,hits,hot,status,deleted,created,updated,commentCnt,articleType) VALUES(?,?,?,?,?,?,0,0,0,0,now(),now(),0,?)
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy27.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy28.add(Unknown Source)
	at com.yangjinjing.cms.service.impl.ArticleServiceImpl.add(ArticleServiceImpl.java:65)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
	at com.sun.proxy.$Proxy32.add(Unknown Source)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:30)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:1)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy39.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 29 more
ERROR - 2020-02-14 14:13:59.133; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = article, partition = 0, offset = 198, CreateTime = 1581660792288, serialized key size = -1, serialized value size = 738, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"articleType":0,"categoryId":1,"channelId":1,"commentCnt":0,"complainCnt":0,"content":"91 | 20197000  20197000 QuestMobile201912316985.86","created":1581660791982,"deleted":0,"hits":-610962223,"hot":1,"picture":"20191224/f018506e-41ff-4f22-b988-2d0ea0b41c1d","status":0,"title":"91  20197000","updated":1581660791982,"userId":68})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.yangjinjing.cms.dao.ArticleMapper.add-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article(title,content,picture,channel_id,category_id,user_id,hits,hot,status,deleted,created,updated,commentCnt,articleType) VALUES(?,?,?,?,?,?,0,0,0,0,now(),now(),0,?)
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy27.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy28.add(Unknown Source)
	at com.yangjinjing.cms.service.impl.ArticleServiceImpl.add(ArticleServiceImpl.java:65)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
	at com.sun.proxy.$Proxy32.add(Unknown Source)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:30)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:1)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy39.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 29 more
ERROR - 2020-02-14 14:13:59.304; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = article, partition = 0, offset = 206, CreateTime = 1581660792301, serialized key size = -1, serialized value size = 719, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"articleType":0,"categoryId":1,"channelId":1,"commentCnt":0,"complainCnt":0,"content":"Facebook  AI TikTok   |  8  TikTok    TikTok ","created":1581660791982,"deleted":0,"hits":133013749,"hot":1,"picture":"20191224/f018506e-41ff-4f22-b988-2d0ea0b41c1d","status":0,"title":"Facebook  AI TikTok     8 ","updated":1581660791982,"userId":68})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.yangjinjing.cms.dao.ArticleMapper.add-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article(title,content,picture,channel_id,category_id,user_id,hits,hot,status,deleted,created,updated,commentCnt,articleType) VALUES(?,?,?,?,?,?,0,0,0,0,now(),now(),0,?)
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy27.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy28.add(Unknown Source)
	at com.yangjinjing.cms.service.impl.ArticleServiceImpl.add(ArticleServiceImpl.java:65)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
	at com.sun.proxy.$Proxy32.add(Unknown Source)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:30)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:1)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy39.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 29 more
ERROR - 2020-02-14 14:13:59.317; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = article, partition = 0, offset = 207, CreateTime = 1581660792302, serialized key size = -1, serialized value size = 647, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"articleType":0,"categoryId":1,"channelId":1,"commentCnt":0,"complainCnt":0,"content":"Galaxy S20 /Galaxy Z Flip 100   Galaxy S20  S20 Galaxy Z Flip  Galaxy Z Flip","created":1581660791982,"deleted":0,"hits":-1972434355,"hot":1,"picture":"20191224/f018506e-41ff-4f22-b988-2d0ea0b41c1d","status":0,"title":"Galaxy S20 Galaxy Z Flip 100 ","updated":1581660791982,"userId":68})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.yangjinjing.cms.dao.ArticleMapper.add-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article(title,content,picture,channel_id,category_id,user_id,hits,hot,status,deleted,created,updated,commentCnt,articleType) VALUES(?,?,?,?,?,?,0,0,0,0,now(),now(),0,?)
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy27.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy28.add(Unknown Source)
	at com.yangjinjing.cms.service.impl.ArticleServiceImpl.add(ArticleServiceImpl.java:65)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
	at com.sun.proxy.$Proxy32.add(Unknown Source)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:30)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:1)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy39.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 29 more
ERROR - 2020-02-14 14:14:00.269; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = article, partition = 0, offset = 249, CreateTime = 1581660792431, serialized key size = -1, serialized value size = 726, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"articleType":0,"categoryId":1,"channelId":1,"commentCnt":0,"complainCnt":0,"content":"App Store20195005858 2008App Store155020191","created":1581660791982,"deleted":0,"hits":420397287,"hot":0,"picture":"20191224/f018506e-41ff-4f22-b988-2d0ea0b41c1d","status":0,"title":"App Store20195005858","updated":1581660791982,"userId":68})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.yangjinjing.cms.dao.ArticleMapper.add-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article(title,content,picture,channel_id,category_id,user_id,hits,hot,status,deleted,created,updated,commentCnt,articleType) VALUES(?,?,?,?,?,?,0,0,0,0,now(),now(),0,?)
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy27.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy28.add(Unknown Source)
	at com.yangjinjing.cms.service.impl.ArticleServiceImpl.add(ArticleServiceImpl.java:65)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
	at com.sun.proxy.$Proxy32.add(Unknown Source)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:30)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:1)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy39.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 29 more
INFO  - 2020-02-14 14:14:01.394; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 14:14:04.122; org.apache.kafka.common.config.AbstractConfig; ProducerConfig values: 
	acks = 1
	batch.size = 1638
	bootstrap.servers = [192.168.198.128:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  - 2020-02-14 14:14:04.176; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 14:14:04.177; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 14:14:04.193; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
ERROR - 2020-02-14 14:14:04.823; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = article, partition = 0, offset = 338, CreateTime = 1581660844255, serialized key size = -1, serialized value size = 805, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"articleType":0,"categoryId":1,"channelId":1,"commentCnt":0,"complainCnt":0,"content":"3605000APP... ...  1535","created":1581660843995,"deleted":0,"hits":-431287878,"hot":1,"picture":"20191224/f018506e-41ff-4f22-b988-2d0ea0b41c1d","status":0,"title":"3605000APP","updated":1581660843995,"userId":68})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.yangjinjing.cms.dao.ArticleMapper.add-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article(title,content,picture,channel_id,category_id,user_id,hits,hot,status,deleted,created,updated,commentCnt,articleType) VALUES(?,?,?,?,?,?,0,0,0,0,now(),now(),0,?)
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy27.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy28.add(Unknown Source)
	at com.yangjinjing.cms.service.impl.ArticleServiceImpl.add(ArticleServiceImpl.java:65)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
	at com.sun.proxy.$Proxy32.add(Unknown Source)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:30)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:1)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy39.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 29 more
ERROR - 2020-02-14 14:14:05.047; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = article, partition = 0, offset = 349, CreateTime = 1581660844265, serialized key size = -1, serialized value size = 746, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"articleType":0,"categoryId":1,"channelId":1,"commentCnt":0,"complainCnt":0,"content":"81App Store5002.01  App Store500 2008App Store","created":1581660843995,"deleted":0,"hits":1622942824,"hot":1,"picture":"20191224/f018506e-41ff-4f22-b988-2d0ea0b41c1d","status":0,"title":"81App Store5002","updated":1581660843995,"userId":68})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.yangjinjing.cms.dao.ArticleMapper.add-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article(title,content,picture,channel_id,category_id,user_id,hits,hot,status,deleted,created,updated,commentCnt,articleType) VALUES(?,?,?,?,?,?,0,0,0,0,now(),now(),0,?)
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy27.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy28.add(Unknown Source)
	at com.yangjinjing.cms.service.impl.ArticleServiceImpl.add(ArticleServiceImpl.java:65)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
	at com.sun.proxy.$Proxy32.add(Unknown Source)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:30)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:1)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy39.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 29 more
INFO  - 2020-02-14 14:14:05.050; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 14:14:05.064; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 14:14:05.066; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 14:14:06.985; org.apache.kafka.clients.producer.KafkaProducer; [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
INFO  - 2020-02-14 14:14:07.000; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-14 14:28:56.421; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-14 14:28:56.450; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@53f65459, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@3b088d51, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@1786dec2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@74650e52, org.springframework.test.context.transaction.TransactionalTestExecutionListener@15d0c81b, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@6acdbdf5]
INFO  - 2020-02-14 14:28:56.934; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 14:28:57.588; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 14:28:59.429; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 14:29:00.328; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 14:29:00.328; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 14:29:00.335; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 14:29:00.635; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 14:29:00.638; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 14:29:00.644; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 14:29:00.644; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 14:29:00.645; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 14:29:00.677; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 206
INFO  - 2020-02-14 14:29:00.680; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 14:29:00.681; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 14:29:00.977; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
ERROR - 2020-02-14 14:29:01.989; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = article, partition = 0, offset = 338, CreateTime = 1581660844255, serialized key size = -1, serialized value size = 805, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"articleType":0,"categoryId":1,"channelId":1,"commentCnt":0,"complainCnt":0,"content":"3605000APP... ...  1535","created":1581660843995,"deleted":0,"hits":-431287878,"hot":1,"picture":"20191224/f018506e-41ff-4f22-b988-2d0ea0b41c1d","status":0,"title":"3605000APP","updated":1581660843995,"userId":68})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.yangjinjing.cms.dao.ArticleMapper.add-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article(title,content,picture,channel_id,category_id,user_id,hits,hot,status,deleted,created,updated,commentCnt,articleType) VALUES(?,?,?,?,?,?,0,0,0,0,now(),now(),0,?)
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy27.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy28.add(Unknown Source)
	at com.yangjinjing.cms.service.impl.ArticleServiceImpl.add(ArticleServiceImpl.java:65)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
	at com.sun.proxy.$Proxy32.add(Unknown Source)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:30)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:1)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy39.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 29 more
ERROR - 2020-02-14 14:29:02.225; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = article, partition = 0, offset = 349, CreateTime = 1581660844265, serialized key size = -1, serialized value size = 746, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"articleType":0,"categoryId":1,"channelId":1,"commentCnt":0,"complainCnt":0,"content":"81App Store5002.01  App Store500 2008App Store","created":1581660843995,"deleted":0,"hits":1622942824,"hot":1,"picture":"20191224/f018506e-41ff-4f22-b988-2d0ea0b41c1d","status":0,"title":"81App Store5002","updated":1581660843995,"userId":68})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.yangjinjing.cms.dao.ArticleMapper.add-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article(title,content,picture,channel_id,category_id,user_id,hits,hot,status,deleted,created,updated,commentCnt,articleType) VALUES(?,?,?,?,?,?,0,0,0,0,now(),now(),0,?)
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy27.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy28.add(Unknown Source)
	at com.yangjinjing.cms.service.impl.ArticleServiceImpl.add(ArticleServiceImpl.java:65)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
	at com.sun.proxy.$Proxy32.add(Unknown Source)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:30)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:1)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy39.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 29 more
ERROR - 2020-02-14 14:29:02.265; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = article, partition = 0, offset = 351, CreateTime = 1581660844267, serialized key size = -1, serialized value size = 738, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"articleType":0,"categoryId":1,"channelId":1,"commentCnt":0,"complainCnt":0,"content":"91 | 20197000  20197000 QuestMobile201912316985.86","created":1581660843995,"deleted":0,"hits":1141723028,"hot":0,"picture":"20191224/f018506e-41ff-4f22-b988-2d0ea0b41c1d","status":0,"title":"91  20197000","updated":1581660843995,"userId":68})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.yangjinjing.cms.dao.ArticleMapper.add-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article(title,content,picture,channel_id,category_id,user_id,hits,hot,status,deleted,created,updated,commentCnt,articleType) VALUES(?,?,?,?,?,?,0,0,0,0,now(),now(),0,?)
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy27.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy28.add(Unknown Source)
	at com.yangjinjing.cms.service.impl.ArticleServiceImpl.add(ArticleServiceImpl.java:65)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
	at com.sun.proxy.$Proxy32.add(Unknown Source)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:30)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:1)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy39.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 29 more
ERROR - 2020-02-14 14:29:02.434; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = article, partition = 0, offset = 359, CreateTime = 1581660844275, serialized key size = -1, serialized value size = 719, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"articleType":0,"categoryId":1,"channelId":1,"commentCnt":0,"complainCnt":0,"content":"Facebook  AI TikTok   |  8  TikTok    TikTok ","created":1581660843995,"deleted":0,"hits":154751698,"hot":1,"picture":"20191224/f018506e-41ff-4f22-b988-2d0ea0b41c1d","status":0,"title":"Facebook  AI TikTok     8 ","updated":1581660843995,"userId":68})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.yangjinjing.cms.dao.ArticleMapper.add-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article(title,content,picture,channel_id,category_id,user_id,hits,hot,status,deleted,created,updated,commentCnt,articleType) VALUES(?,?,?,?,?,?,0,0,0,0,now(),now(),0,?)
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy27.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy28.add(Unknown Source)
	at com.yangjinjing.cms.service.impl.ArticleServiceImpl.add(ArticleServiceImpl.java:65)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
	at com.sun.proxy.$Proxy32.add(Unknown Source)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:30)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:1)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy39.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 29 more
ERROR - 2020-02-14 14:29:02.436; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = article, partition = 0, offset = 360, CreateTime = 1581660844276, serialized key size = -1, serialized value size = 645, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"articleType":0,"categoryId":1,"channelId":1,"commentCnt":0,"complainCnt":0,"content":"Galaxy S20 /Galaxy Z Flip 100   Galaxy S20  S20 Galaxy Z Flip  Galaxy Z Flip","created":1581660843995,"deleted":0,"hits":255071304,"hot":0,"picture":"20191224/f018506e-41ff-4f22-b988-2d0ea0b41c1d","status":0,"title":"Galaxy S20 Galaxy Z Flip 100 ","updated":1581660843995,"userId":68})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.yangjinjing.cms.dao.ArticleMapper.add-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article(title,content,picture,channel_id,category_id,user_id,hits,hot,status,deleted,created,updated,commentCnt,articleType) VALUES(?,?,?,?,?,?,0,0,0,0,now(),now(),0,?)
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy27.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy28.add(Unknown Source)
	at com.yangjinjing.cms.service.impl.ArticleServiceImpl.add(ArticleServiceImpl.java:65)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
	at com.sun.proxy.$Proxy32.add(Unknown Source)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:30)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:1)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy39.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 29 more
ERROR - 2020-02-14 14:29:03.412; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = article, partition = 0, offset = 402, CreateTime = 1581660844333, serialized key size = -1, serialized value size = 728, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"articleType":0,"categoryId":1,"channelId":1,"commentCnt":0,"complainCnt":0,"content":"App Store20195005858 2008App Store155020191","created":1581660843995,"deleted":0,"hits":-1528389096,"hot":0,"picture":"20191224/f018506e-41ff-4f22-b988-2d0ea0b41c1d","status":0,"title":"App Store20195005858","updated":1581660843995,"userId":68})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.yangjinjing.cms.dao.ArticleMapper.add-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article(title,content,picture,channel_id,category_id,user_id,hits,hot,status,deleted,created,updated,commentCnt,articleType) VALUES(?,?,?,?,?,?,0,0,0,0,now(),now(),0,?)
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy27.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy28.add(Unknown Source)
	at com.yangjinjing.cms.service.impl.ArticleServiceImpl.add(ArticleServiceImpl.java:65)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
	at com.sun.proxy.$Proxy32.add(Unknown Source)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:30)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:1)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy39.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 29 more
INFO  - 2020-02-14 14:29:04.571; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 14:29:07.582; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 14:29:07.589; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 14:29:07.591; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 14:29:09.162; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-14 14:29:36.828; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-14 14:29:36.863; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@53f65459, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@3b088d51, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@1786dec2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@74650e52, org.springframework.test.context.transaction.TransactionalTestExecutionListener@15d0c81b, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@6acdbdf5]
INFO  - 2020-02-14 14:29:37.385; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 14:29:38.020; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 14:29:40.049; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 14:29:41.006; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 14:29:41.007; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 14:29:41.016; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 14:29:41.386; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 14:29:41.394; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 14:29:41.401; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 14:29:41.401; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 14:29:41.401; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 14:29:41.456; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 208
INFO  - 2020-02-14 14:29:41.459; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 14:29:41.459; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 14:29:45.203; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 14:29:47.650; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-14 14:29:51.445; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 14:29:51.454; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 14:29:51.458; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 14:29:52.694; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-14 14:32:10.942; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-14 14:32:10.976; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@53f65459, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@3b088d51, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@1786dec2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@74650e52, org.springframework.test.context.transaction.TransactionalTestExecutionListener@15d0c81b, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@6acdbdf5]
INFO  - 2020-02-14 14:32:11.475; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 14:32:12.157; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 14:32:14.298; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 14:32:15.189; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 14:32:15.189; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 14:32:15.196; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 14:32:15.640; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 14:32:15.642; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 14:32:15.646; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 14:32:15.647; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 14:32:15.647; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 14:32:15.682; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 210
INFO  - 2020-02-14 14:32:15.686; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 14:32:15.687; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 14:32:19.645; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
ERROR - 2020-02-14 14:32:23.933; org.springframework.data.elasticsearch.repository.support.AbstractElasticsearchRepository; failed to load elasticsearch nodes : org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes are available: [{#transport#-1}{8hCrZD5pR86IDoZauMI_Jg}{192.168.198.128}{192.168.198.128:9300}]
INFO  - 2020-02-14 14:32:24.269; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-14 14:32:25.152; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 14:32:25.179; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 14:32:25.181; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 14:32:26.874; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-14 14:39:04.160; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-14 14:39:04.198; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@53f65459, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@3b088d51, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@1786dec2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@74650e52, org.springframework.test.context.transaction.TransactionalTestExecutionListener@15d0c81b, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@6acdbdf5]
INFO  - 2020-02-14 14:39:04.724; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 14:39:05.602; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 14:39:08.181; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 14:39:09.356; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 14:39:09.356; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 14:39:09.390; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 14:39:11.370; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 14:39:11.402; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 14:39:11.407; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 14:39:11.408; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 14:39:11.408; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 14:39:12.034; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 212
INFO  - 2020-02-14 14:39:12.045; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 14:39:12.045; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 14:39:21.871; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 14:39:25.879; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-14 14:39:28.503; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 14:39:28.527; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 14:39:28.529; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 14:39:30.419; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-14 14:41:10.255; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-14 14:41:10.288; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@53f65459, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@3b088d51, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@1786dec2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@74650e52, org.springframework.test.context.transaction.TransactionalTestExecutionListener@15d0c81b, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@6acdbdf5]
INFO  - 2020-02-14 14:41:10.768; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 14:41:11.403; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 14:41:13.169; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 14:41:14.050; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 14:41:14.050; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 14:41:14.058; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 14:41:14.412; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 14:41:14.414; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 14:41:14.418; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 14:41:14.419; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 14:41:14.420; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 14:41:14.461; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 214
INFO  - 2020-02-14 14:41:14.463; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 14:41:14.463; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 14:41:18.443; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 14:41:21.164; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-14 14:41:21.676; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 14:41:21.711; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 14:41:21.713; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 14:41:22.978; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-14 14:42:11.180; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-14 14:42:11.213; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@53f65459, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@3b088d51, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@1786dec2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@74650e52, org.springframework.test.context.transaction.TransactionalTestExecutionListener@15d0c81b, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@6acdbdf5]
INFO  - 2020-02-14 14:42:11.702; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 14:42:12.443; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 14:42:14.580; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 14:42:15.489; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 14:42:15.490; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 14:42:15.503; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 14:42:15.856; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 14:42:15.863; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 14:42:15.876; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 14:42:15.876; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 14:42:15.877; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 14:42:15.942; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 216
INFO  - 2020-02-14 14:42:15.948; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 14:42:15.950; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 14:42:19.705; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 14:42:22.311; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-14 14:42:26.973; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 14:42:27.556; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 14:42:27.560; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 14:42:29.567; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-14 14:51:27.924; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-14 14:51:28.523; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 14:51:29.076; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 14:51:31.196; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 14:51:31.320; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 14:51:31.320; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 14:51:31.332; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 14:51:31.862; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 14:51:31.866; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 14:51:31.874; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 14:51:31.875; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 14:51:31.875; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 14:51:31.903; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 218
INFO  - 2020-02-14 14:51:31.907; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 14:51:31.908; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 14:51:36.169; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 14:51:38.965; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 11033 ms
INFO  - 2020-02-14 14:51:39.289; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-14 14:51:42.069; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-14 14:51:42.742; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 3453 ms
INFO  - 2020-02-14 14:52:29.888; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
WARN  - 2020-02-14 14:57:05.700; org.springframework.web.servlet.handler.AbstractHandlerExceptionResolver; Resolved [org.springframework.web.bind.MissingServletRequestParameterException: Required int parameter '9' is not present]
WARN  - 2020-02-14 14:57:19.157; org.springframework.web.servlet.handler.AbstractHandlerExceptionResolver; Resolved [org.springframework.web.bind.MissingServletRequestParameterException: Required int parameter '9' is not present]
INFO  - 2020-02-14 14:57:42.148; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 14:57:42.156; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 14:57:42.158; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 14:57:44.005; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-14 14:57:51.961; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-14 14:57:52.682; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 14:57:53.297; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 14:57:55.496; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 14:57:55.606; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 14:57:55.606; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 14:57:55.616; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 14:57:55.967; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 14:57:55.971; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 14:57:55.977; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 14:57:55.978; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 14:57:55.978; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 14:57:56.030; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 220
INFO  - 2020-02-14 14:57:56.034; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 14:57:56.034; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 14:57:59.918; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 14:58:02.756; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 10789 ms
INFO  - 2020-02-14 14:58:02.929; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-14 14:58:03.566; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-14 14:58:04.521; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1592 ms
WARN  - 2020-02-14 14:58:18.989; org.springframework.web.servlet.handler.AbstractHandlerExceptionResolver; Resolved [org.springframework.web.bind.MissingServletRequestParameterException: Required int parameter '9' is not present]
INFO  - 2020-02-14 14:58:24.499; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
WARN  - 2020-02-14 14:58:31.812; org.springframework.web.servlet.handler.AbstractHandlerExceptionResolver; Resolved [org.springframework.web.bind.MissingServletRequestParameterException: Required int parameter '9' is not present]
WARN  - 2020-02-14 14:58:35.511; org.springframework.web.servlet.handler.AbstractHandlerExceptionResolver; Resolved [org.springframework.web.bind.MissingServletRequestParameterException: Required int parameter '9' is not present]
INFO  - 2020-02-14 14:58:55.680; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 14:58:55.688; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 14:58:55.689; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 14:58:56.869; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-14 14:59:04.929; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-14 14:59:05.258; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 14:59:05.821; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 14:59:07.588; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 14:59:07.723; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 14:59:07.723; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 14:59:07.738; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 14:59:08.091; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 14:59:08.096; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 14:59:08.106; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 14:59:08.108; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 14:59:08.108; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 14:59:08.144; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 222
INFO  - 2020-02-14 14:59:08.147; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 14:59:08.147; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 14:59:11.568; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 14:59:13.810; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 8877 ms
INFO  - 2020-02-14 14:59:14.019; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-14 14:59:14.704; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-14 14:59:15.262; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1242 ms
INFO  - 2020-02-14 14:59:29.267; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-14 15:14:33.402; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-14 15:14:33.428; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@53f65459, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@3b088d51, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@1786dec2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@74650e52, org.springframework.test.context.transaction.TransactionalTestExecutionListener@15d0c81b, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@6acdbdf5]
INFO  - 2020-02-14 15:14:33.854; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 15:14:34.464; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 15:14:36.291; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 15:14:37.199; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 15:14:37.199; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 15:14:37.205; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 15:14:37.546; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 15:14:37.550; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 15:14:37.555; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 15:14:37.556; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 15:14:37.556; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 15:14:37.581; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 224
INFO  - 2020-02-14 15:14:37.585; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 15:14:37.585; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 15:14:41.118; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 15:14:43.584; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 15:14:43.609; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 15:14:43.612; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 15:15:02.350; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-14 15:15:02.391; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@27a5f880, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@1d29cf23, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@5f282abb, org.springframework.test.context.support.DirtiesContextTestExecutionListener@167fdd33, org.springframework.test.context.transaction.TransactionalTestExecutionListener@1e965684, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@4d95d2a2]
INFO  - 2020-02-14 15:15:02.793; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 15:15:03.402; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 15:15:05.093; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 15:15:05.985; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 15:15:05.985; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 15:15:05.992; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 15:15:06.348; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 15:15:06.352; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 15:15:06.357; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 15:15:06.358; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 15:15:06.359; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 15:15:06.380; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 226
INFO  - 2020-02-14 15:15:06.382; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 15:15:06.382; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 15:15:09.952; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 15:15:12.271; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-14 15:15:15.246; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 15:15:15.257; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 15:15:15.260; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 15:15:16.496; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-14 15:15:35.341; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-14 15:15:35.369; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@53f65459, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@3b088d51, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@1786dec2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@74650e52, org.springframework.test.context.transaction.TransactionalTestExecutionListener@15d0c81b, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@6acdbdf5]
INFO  - 2020-02-14 15:15:35.775; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 15:15:36.367; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 15:15:38.236; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 15:15:39.113; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 15:15:39.113; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 15:15:39.122; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 15:15:39.518; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 15:15:39.521; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 15:15:39.530; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 15:15:39.530; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 15:15:39.531; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 15:15:39.563; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 228
INFO  - 2020-02-14 15:15:39.567; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 15:15:39.567; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 15:15:43.042; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 15:15:45.438; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 15:15:45.451; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 15:15:45.453; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 15:16:08.467; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-14 15:16:08.498; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@53f65459, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@3b088d51, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@1786dec2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@74650e52, org.springframework.test.context.transaction.TransactionalTestExecutionListener@15d0c81b, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@6acdbdf5]
INFO  - 2020-02-14 15:16:08.948; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 15:16:09.555; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 15:16:11.318; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 15:16:12.220; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 15:16:12.221; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 15:16:12.230; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 15:16:12.573; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 15:16:12.577; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 15:16:12.583; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 15:16:12.583; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 15:16:12.583; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 15:16:12.607; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 230
INFO  - 2020-02-14 15:16:12.608; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 15:16:12.608; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 15:16:16.250; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 15:16:18.575; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 15:16:18.586; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 15:16:18.588; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 15:16:50.911; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-14 15:16:50.941; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@27a5f880, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@1d29cf23, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@5f282abb, org.springframework.test.context.support.DirtiesContextTestExecutionListener@167fdd33, org.springframework.test.context.transaction.TransactionalTestExecutionListener@1e965684, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@4d95d2a2]
INFO  - 2020-02-14 15:16:51.324; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 15:16:51.960; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 15:16:53.746; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 15:16:54.619; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 15:16:54.620; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 15:16:54.628; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 15:16:54.953; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 15:16:54.956; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 15:16:54.959; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 15:16:54.960; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 15:16:54.960; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 15:16:54.996; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 232
INFO  - 2020-02-14 15:16:54.998; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 15:16:54.999; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 15:16:58.656; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 15:17:01.224; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-14 15:17:03.570; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 15:17:03.581; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 15:17:03.583; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 15:17:05.277; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-14 15:56:45.174; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-14 15:56:45.638; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 15:56:46.333; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 15:56:48.852; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 15:56:48.994; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 15:56:48.994; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 15:56:49.008; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 15:56:49.459; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 15:56:49.465; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 15:56:49.474; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 15:56:49.474; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 15:56:49.475; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 15:56:49.529; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 234
INFO  - 2020-02-14 15:56:49.534; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 15:56:49.534; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 15:56:53.203; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 15:56:56.235; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 11056 ms
INFO  - 2020-02-14 15:56:56.540; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-14 15:56:57.255; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-14 15:56:58.485; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1945 ms
INFO  - 2020-02-14 15:58:01.394; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-14 15:59:16.909; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 15:59:16.920; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 15:59:16.923; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 15:59:18.386; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-14 15:59:26.701; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-14 15:59:27.245; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 15:59:28.170; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 15:59:30.274; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 15:59:30.436; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 15:59:30.437; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 15:59:30.451; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 15:59:31.288; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 15:59:31.300; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 15:59:31.308; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 15:59:31.309; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 15:59:31.309; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 15:59:31.342; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 236
INFO  - 2020-02-14 15:59:31.346; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 15:59:31.346; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 15:59:34.621; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 15:59:37.051; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 10345 ms
INFO  - 2020-02-14 15:59:37.249; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-14 15:59:38.101; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-14 15:59:38.871; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1621 ms
INFO  - 2020-02-14 16:00:01.522; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-14 16:05:53.769; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 16:05:53.803; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 16:05:53.804; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 16:05:55.676; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-14 16:06:00.996; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-14 16:06:01.299; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 16:06:01.784; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 16:06:03.514; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 16:06:03.653; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 16:06:03.653; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 16:06:03.679; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 16:06:04.131; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 16:06:04.143; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 16:06:04.148; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 16:06:04.149; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 16:06:04.149; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:06:04.212; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 238
INFO  - 2020-02-14 16:06:04.216; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 16:06:04.216; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 16:06:07.530; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 16:06:10.053; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 9054 ms
INFO  - 2020-02-14 16:06:10.298; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-14 16:06:11.206; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-14 16:06:11.720; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1421 ms
INFO  - 2020-02-14 16:06:31.924; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 16:06:31.932; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 16:06:31.934; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 16:06:39.362; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-14 16:06:39.714; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 16:06:40.417; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 16:06:42.192; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 16:06:42.316; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 16:06:42.317; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 16:06:42.325; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 16:06:42.709; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 16:06:42.749; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 16:06:42.754; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 16:06:42.754; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 16:06:42.755; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:06:43.236; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 240
INFO  - 2020-02-14 16:06:43.241; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 16:06:43.242; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 16:06:46.383; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 16:06:48.757; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 9385 ms
INFO  - 2020-02-14 16:06:48.970; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-14 16:06:49.814; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-14 16:06:50.280; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1310 ms
INFO  - 2020-02-14 16:06:56.794; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 16:06:56.800; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 16:06:56.802; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 16:07:09.221; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-14 16:07:09.684; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 16:07:10.303; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 16:07:12.538; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 16:07:12.735; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 16:07:12.735; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 16:07:12.752; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 16:07:13.222; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 16:07:13.226; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 16:07:13.238; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 16:07:13.239; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 16:07:13.239; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:07:13.333; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 242
INFO  - 2020-02-14 16:07:13.337; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 16:07:13.338; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 16:07:17.136; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 16:07:19.956; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 10724 ms
INFO  - 2020-02-14 16:07:20.235; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-14 16:07:20.895; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-14 16:07:21.835; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1600 ms
INFO  - 2020-02-14 16:07:35.000; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 16:07:35.009; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 16:07:35.011; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 16:08:50.365; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-14 16:08:50.771; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 16:08:51.387; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 16:08:53.462; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 16:08:53.583; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 16:08:53.583; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 16:08:53.594; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 16:08:53.973; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 16:08:53.977; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 16:08:53.982; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 16:08:53.982; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 16:08:53.982; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:08:54.012; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 244
INFO  - 2020-02-14 16:08:54.018; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 16:08:54.018; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 16:08:58.140; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 16:09:00.971; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 10603 ms
INFO  - 2020-02-14 16:09:01.288; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-14 16:09:01.979; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-14 16:09:03.197; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1909 ms
INFO  - 2020-02-14 16:09:14.287; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 16:09:14.298; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 16:09:14.300; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 16:09:19.003; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-14 16:09:19.544; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 16:09:20.180; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 16:09:22.054; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 16:09:22.275; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 16:09:22.277; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 16:09:22.295; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 16:09:22.788; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 16:09:22.797; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 16:09:22.807; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 16:09:22.808; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 16:09:22.809; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:09:22.851; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 246
INFO  - 2020-02-14 16:09:22.856; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 16:09:22.857; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 16:09:26.076; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 16:09:28.551; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 9542 ms
INFO  - 2020-02-14 16:09:28.728; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-14 16:09:29.346; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-14 16:09:29.785; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1057 ms
INFO  - 2020-02-14 16:09:44.848; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 16:09:44.863; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 16:09:44.866; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 16:09:48.959; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-14 16:09:49.273; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 16:09:49.746; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 16:09:51.616; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 16:09:51.722; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 16:09:51.722; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 16:09:51.736; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 16:09:52.142; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 16:09:52.149; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 16:09:52.160; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 16:09:52.161; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 16:09:52.161; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:09:52.188; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 248
INFO  - 2020-02-14 16:09:52.190; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 16:09:52.190; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 16:09:55.607; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 16:09:57.844; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 8882 ms
INFO  - 2020-02-14 16:09:58.040; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
WARN  - 2020-02-14 16:09:58.297; org.springframework.context.support.AbstractApplicationContext; Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'articleController' defined in file [C:\Users\Legna\workspace\yangjinjing-cms\target\classes\com\yangjinjing\cms\controller\ArticleController.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.yangjinjing.cms.controller.ArticleController]: Constructor threw exception; nested exception is java.lang.Error: Unresolved compilation problems: 
	Syntax error, insert "Identifier (" to complete MethodHeaderName
	Syntax error, insert ")" to complete MethodDeclaration
	Syntax error, insert "VariableDeclarators" to complete LocalVariableDeclaration
	Syntax error, insert ";" to complete BlockStatements
	void is an invalid type for the variable $missing$

ERROR - 2020-02-14 16:09:58.298; org.springframework.web.servlet.FrameworkServlet; Context initialization failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'articleController' defined in file [C:\Users\Legna\workspace\yangjinjing-cms\target\classes\com\yangjinjing\cms\controller\ArticleController.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.yangjinjing.cms.controller.ArticleController]: Constructor threw exception; nested exception is java.lang.Error: Unresolved compilation problems: 
	Syntax error, insert "Identifier (" to complete MethodHeaderName
	Syntax error, insert ")" to complete MethodDeclaration
	Syntax error, insert "VariableDeclarators" to complete LocalVariableDeclaration
	Syntax error, insert ";" to complete BlockStatements
	void is an invalid type for the variable $missing$

	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1287)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1181)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549)
	at org.springframework.web.servlet.FrameworkServlet.configureAndRefreshWebApplicationContext(FrameworkServlet.java:701)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:667)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:715)
	at org.springframework.web.servlet.FrameworkServlet.initWebApplicationContext(FrameworkServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.initServletBean(FrameworkServlet.java:529)
	at org.springframework.web.servlet.HttpServletBean.init(HttpServletBean.java:169)
	at javax.servlet.GenericServlet.init(GenericServlet.java:244)
	at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:669)
	at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:426)
	at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:760)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:374)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.startWebapp(JettyWebAppContext.java:360)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:785)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:287)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.doStart(JettyWebAppContext.java:428)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo.restartWebApp(JettyRunMojo.java:553)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo$1.onPathWatchEvents(JettyRunMojo.java:405)
	at org.eclipse.jetty.util.PathWatcher.notifyEvents(PathWatcher.java:1366)
	at org.eclipse.jetty.util.PathWatcher.run(PathWatcher.java:1190)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.yangjinjing.cms.controller.ArticleController]: Constructor threw exception; nested exception is java.lang.Error: Unresolved compilation problems: 
	Syntax error, insert "Identifier (" to complete MethodHeaderName
	Syntax error, insert ")" to complete MethodDeclaration
	Syntax error, insert "VariableDeclarators" to complete LocalVariableDeclaration
	Syntax error, insert ";" to complete BlockStatements
	void is an invalid type for the variable $missing$

	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:184)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:87)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1279)
	... 34 more
Caused by: java.lang.Error: Unresolved compilation problems: 
	Syntax error, insert "Identifier (" to complete MethodHeaderName
	Syntax error, insert ")" to complete MethodDeclaration
	Syntax error, insert "VariableDeclarators" to complete LocalVariableDeclaration
	Syntax error, insert ";" to complete BlockStatements
	void is an invalid type for the variable $missing$

	at com.yangjinjing.cms.controller.ArticleController.<init>(ArticleController.java:90)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:172)
	... 36 more
INFO  - 2020-02-14 16:10:01.219; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 16:10:01.226; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 16:10:01.228; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 16:10:05.289; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-14 16:10:05.722; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 16:10:06.369; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 16:10:08.327; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 16:10:08.449; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 16:10:08.449; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 16:10:08.462; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 16:10:08.932; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 16:10:08.935; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 16:10:08.939; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 16:10:08.939; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 16:10:08.940; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:10:08.960; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 250
INFO  - 2020-02-14 16:10:08.962; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 16:10:08.963; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 16:10:11.950; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 16:10:14.781; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 9488 ms
INFO  - 2020-02-14 16:10:14.971; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-14 16:10:15.653; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-14 16:10:16.079; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1107 ms
INFO  - 2020-02-14 16:10:34.227; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 16:10:34.237; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 16:10:34.238; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 16:10:50.790; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-14 16:10:51.090; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 16:10:51.618; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 16:10:53.566; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 16:10:53.668; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 16:10:53.668; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 16:10:53.677; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 16:10:53.929; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 16:10:53.932; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 16:10:53.936; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 16:10:53.937; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 16:10:53.937; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:10:53.951; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 252
INFO  - 2020-02-14 16:10:53.953; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 16:10:53.954; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 16:10:57.357; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 16:10:59.923; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 9130 ms
INFO  - 2020-02-14 16:11:00.219; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
WARN  - 2020-02-14 16:11:00.519; org.springframework.context.support.AbstractApplicationContext; Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'articleController' defined in file [C:\Users\Legna\workspace\yangjinjing-cms\target\classes\com\yangjinjing\cms\controller\ArticleController.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.yangjinjing.cms.controller.ArticleController]: Constructor threw exception; nested exception is java.lang.Error: Unresolved compilation problem: 
	Syntax error, insert ";" to complete FieldDeclaration

ERROR - 2020-02-14 16:11:00.529; org.springframework.web.servlet.FrameworkServlet; Context initialization failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'articleController' defined in file [C:\Users\Legna\workspace\yangjinjing-cms\target\classes\com\yangjinjing\cms\controller\ArticleController.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.yangjinjing.cms.controller.ArticleController]: Constructor threw exception; nested exception is java.lang.Error: Unresolved compilation problem: 
	Syntax error, insert ";" to complete FieldDeclaration

	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1287)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1181)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549)
	at org.springframework.web.servlet.FrameworkServlet.configureAndRefreshWebApplicationContext(FrameworkServlet.java:701)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:667)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:715)
	at org.springframework.web.servlet.FrameworkServlet.initWebApplicationContext(FrameworkServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.initServletBean(FrameworkServlet.java:529)
	at org.springframework.web.servlet.HttpServletBean.init(HttpServletBean.java:169)
	at javax.servlet.GenericServlet.init(GenericServlet.java:244)
	at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:669)
	at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:426)
	at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:760)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:374)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.startWebapp(JettyWebAppContext.java:360)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:785)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:287)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.doStart(JettyWebAppContext.java:428)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo.restartWebApp(JettyRunMojo.java:553)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo$1.onPathWatchEvents(JettyRunMojo.java:405)
	at org.eclipse.jetty.util.PathWatcher.notifyEvents(PathWatcher.java:1366)
	at org.eclipse.jetty.util.PathWatcher.run(PathWatcher.java:1190)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.yangjinjing.cms.controller.ArticleController]: Constructor threw exception; nested exception is java.lang.Error: Unresolved compilation problem: 
	Syntax error, insert ";" to complete FieldDeclaration

	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:184)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:87)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1279)
	... 34 more
Caused by: java.lang.Error: Unresolved compilation problem: 
	Syntax error, insert ";" to complete FieldDeclaration

	at com.yangjinjing.cms.controller.ArticleController.<init>(ArticleController.java:92)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:172)
	... 36 more
INFO  - 2020-02-14 16:11:04.007; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 16:11:04.013; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 16:11:04.015; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 16:11:11.102; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-14 16:11:11.374; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 16:11:12.327; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 16:11:14.163; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 16:11:14.290; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 16:11:14.290; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 16:11:14.298; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 16:11:15.298; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 16:11:15.302; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 16:11:15.310; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 16:11:15.311; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 16:11:15.312; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:11:15.340; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 254
INFO  - 2020-02-14 16:11:15.343; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 16:11:15.343; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 16:11:18.547; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 16:11:27.963; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 16855 ms
INFO  - 2020-02-14 16:11:28.142; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
WARN  - 2020-02-14 16:11:28.683; org.springframework.context.support.AbstractApplicationContext; Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'articleController' defined in file [C:\Users\Legna\workspace\yangjinjing-cms\target\classes\com\yangjinjing\cms\controller\ArticleController.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.yangjinjing.cms.controller.ArticleController]: Constructor threw exception; nested exception is java.lang.Error: Unresolved compilation problems: 
	Syntax error, insert "enum Identifier" to complete EnumHeaderName
	Syntax error, insert "EnumBody" to complete ClassBodyDeclarations

ERROR - 2020-02-14 16:11:28.685; org.springframework.web.servlet.FrameworkServlet; Context initialization failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'articleController' defined in file [C:\Users\Legna\workspace\yangjinjing-cms\target\classes\com\yangjinjing\cms\controller\ArticleController.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.yangjinjing.cms.controller.ArticleController]: Constructor threw exception; nested exception is java.lang.Error: Unresolved compilation problems: 
	Syntax error, insert "enum Identifier" to complete EnumHeaderName
	Syntax error, insert "EnumBody" to complete ClassBodyDeclarations

	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1287)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1181)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549)
	at org.springframework.web.servlet.FrameworkServlet.configureAndRefreshWebApplicationContext(FrameworkServlet.java:701)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:667)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:715)
	at org.springframework.web.servlet.FrameworkServlet.initWebApplicationContext(FrameworkServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.initServletBean(FrameworkServlet.java:529)
	at org.springframework.web.servlet.HttpServletBean.init(HttpServletBean.java:169)
	at javax.servlet.GenericServlet.init(GenericServlet.java:244)
	at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:669)
	at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:426)
	at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:760)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:374)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.startWebapp(JettyWebAppContext.java:360)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:785)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:287)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.doStart(JettyWebAppContext.java:428)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo.restartWebApp(JettyRunMojo.java:553)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo$1.onPathWatchEvents(JettyRunMojo.java:405)
	at org.eclipse.jetty.util.PathWatcher.notifyEvents(PathWatcher.java:1366)
	at org.eclipse.jetty.util.PathWatcher.run(PathWatcher.java:1190)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.yangjinjing.cms.controller.ArticleController]: Constructor threw exception; nested exception is java.lang.Error: Unresolved compilation problems: 
	Syntax error, insert "enum Identifier" to complete EnumHeaderName
	Syntax error, insert "EnumBody" to complete ClassBodyDeclarations

	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:184)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:87)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1279)
	... 34 more
Caused by: java.lang.Error: Unresolved compilation problems: 
	Syntax error, insert "enum Identifier" to complete EnumHeaderName
	Syntax error, insert "EnumBody" to complete ClassBodyDeclarations

	at com.yangjinjing.cms.controller.ArticleController.<init>(ArticleController.java:91)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:172)
	... 36 more
INFO  - 2020-02-14 16:11:32.355; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 16:11:32.363; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 16:11:32.364; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 16:11:44.473; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-14 16:11:45.053; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 16:11:46.299; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 16:11:49.486; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 16:11:49.580; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 16:11:49.580; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 16:11:49.587; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 16:11:50.642; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 16:11:50.646; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 16:11:50.655; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 16:11:50.656; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 16:11:50.656; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:11:50.707; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 256
INFO  - 2020-02-14 16:11:50.711; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 16:11:50.712; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 16:11:55.640; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
ERROR - 2020-02-14 16:12:03.664; org.springframework.data.elasticsearch.repository.support.AbstractElasticsearchRepository; failed to load elasticsearch nodes : org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes are available: [{#transport#-1}{P4G-DiLsR1Sh74gAdYtzYQ}{192.168.198.128}{192.168.198.128:9300}]
INFO  - 2020-02-14 16:12:05.276; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 20800 ms
INFO  - 2020-02-14 16:12:06.333; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-14 16:12:11.095; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-14 16:12:15.438; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 9105 ms
INFO  - 2020-02-14 16:12:29.836; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 16:12:29.848; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 16:12:29.849; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 16:19:20.609; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-14 16:19:21.197; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 16:19:22.204; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 16:19:24.152; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 16:19:24.326; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 16:19:24.326; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 16:19:24.336; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 16:19:24.773; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 16:19:24.776; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 16:19:24.785; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 16:19:24.787; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 16:19:24.788; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:19:24.833; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 258
INFO  - 2020-02-14 16:19:24.838; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 16:19:24.839; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 16:19:29.187; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 16:19:31.619; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 11006 ms
INFO  - 2020-02-14 16:19:31.899; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-14 16:19:32.639; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-14 16:19:33.189; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1290 ms
INFO  - 2020-02-14 16:19:42.954; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-14 16:22:53.918; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 16:22:53.929; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 16:22:53.932; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 16:22:55.090; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-14 16:22:57.733; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-14 16:22:58.125; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 16:22:58.685; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 16:23:01.022; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 16:23:01.239; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 16:23:01.240; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 16:23:01.247; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 16:23:01.631; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 16:23:01.634; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 16:23:01.638; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 16:23:01.638; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 16:23:01.638; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:23:01.652; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 260
INFO  - 2020-02-14 16:23:01.658; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 16:23:01.658; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 16:23:04.861; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 16:23:07.094; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 9356 ms
INFO  - 2020-02-14 16:23:07.378; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-14 16:23:08.025; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-14 16:23:08.596; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1218 ms
INFO  - 2020-02-14 16:23:21.889; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 16:23:21.898; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 16:23:21.899; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 16:23:26.531; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-14 16:23:26.790; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 16:23:27.457; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 16:23:29.504; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 16:23:29.637; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 16:23:29.637; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 16:23:29.648; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 16:23:30.038; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 16:23:30.042; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 16:23:30.048; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 16:23:30.048; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 16:23:30.048; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:23:30.094; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 262
INFO  - 2020-02-14 16:23:30.098; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 16:23:30.099; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 16:24:13.493; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-14 16:24:13.905; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 16:24:14.477; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 16:24:16.451; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 16:24:16.583; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 16:24:16.584; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 16:24:16.602; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 16:24:16.945; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 16:24:16.949; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 16:24:16.956; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 16:24:16.956; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 16:24:16.957; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:24:17.157; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 264
INFO  - 2020-02-14 16:24:17.160; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 16:24:17.161; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 16:24:20.672; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 16:24:23.115; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 9613 ms
INFO  - 2020-02-14 16:24:23.550; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-14 16:24:25.293; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-14 16:24:25.847; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 2297 ms
INFO  - 2020-02-14 16:24:28.785; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-14 16:25:26.629; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2020-02-14 16:25:32.079; org.apache.kafka.clients.FetchSessionHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 0: org.apache.kafka.common.errors.DisconnectException.
INFO  - 2020-02-14 16:25:32.210; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
ERROR - 2020-02-14 16:25:33.790; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetCommitResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Offset commit failed on partition article-0 at offset 469: The coordinator is not aware of this member.
WARN  - 2020-02-14 16:25:33.791; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$4; [Consumer clientId=consumer-1, groupId=test-consumer-group] Asynchronous auto-commit of offsets {article-0=OffsetAndMetadata{offset=469, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
WARN  - 2020-02-14 16:25:33.791; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Synchronous auto-commit of offsets {article-0=OffsetAndMetadata{offset=469, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
INFO  - 2020-02-14 16:25:33.792; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions [article-0]
INFO  - 2020-02-14 16:25:33.792; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: [article-0]
INFO  - 2020-02-14 16:25:33.792; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:25:34.320; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 266
INFO  - 2020-02-14 16:25:34.322; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 16:25:34.322; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 16:31:55.537; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 16:31:55.547; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 16:31:55.549; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 16:31:57.332; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-14 16:32:00.846; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-14 16:32:01.321; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 16:32:02.250; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 16:32:04.244; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 16:32:04.368; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 16:32:04.369; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 16:32:04.381; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 16:32:04.716; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 16:32:04.719; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 16:32:04.724; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 16:32:04.724; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 16:32:04.725; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:32:04.753; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 268
INFO  - 2020-02-14 16:32:04.756; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 16:32:04.756; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 16:32:08.047; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 16:32:10.749; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 9899 ms
INFO  - 2020-02-14 16:32:11.012; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-14 16:32:11.688; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-14 16:32:12.066; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1054 ms
INFO  - 2020-02-14 16:37:22.222; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 16:37:22.230; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 16:37:22.232; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 16:37:33.756; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-14 16:37:34.172; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 16:37:34.962; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 16:37:57.697; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-14 16:37:58.237; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 16:37:58.816; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 16:38:01.223; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 16:38:01.365; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 16:38:01.365; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 16:38:01.376; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 16:38:01.747; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 16:38:01.754; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 16:38:01.765; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 16:38:01.766; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 16:38:01.767; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:38:01.848; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 270
INFO  - 2020-02-14 16:38:01.851; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 16:38:01.852; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 16:38:05.638; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 16:38:08.143; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 10441 ms
INFO  - 2020-02-14 16:38:08.387; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-14 16:38:09.535; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-14 16:38:11.044; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 2656 ms
INFO  - 2020-02-14 16:38:14.350; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-14 16:39:05.867; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 16:39:05.879; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 16:39:05.881; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 16:39:07.568; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-14 16:39:10.703; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-14 16:39:11.201; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 16:39:12.104; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 16:39:14.720; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 16:39:14.848; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 16:39:14.849; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 16:39:14.857; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 16:39:15.244; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 16:39:15.248; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 16:39:15.254; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 16:39:15.255; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 16:39:15.255; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:39:15.273; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 272
INFO  - 2020-02-14 16:39:15.275; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 16:39:15.276; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 16:39:18.511; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 16:39:20.787; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 10077 ms
INFO  - 2020-02-14 16:39:21.052; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-14 16:39:21.980; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-14 16:39:22.736; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1684 ms
INFO  - 2020-02-14 16:39:24.161; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-14 16:41:07.668; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 16:41:07.675; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 16:41:07.676; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 16:41:09.149; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-14 16:41:11.546; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-14 16:41:11.967; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 16:41:12.603; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 16:41:14.607; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 16:41:14.740; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 16:41:14.740; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 16:41:14.753; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 16:41:15.115; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 16:41:15.120; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 16:41:15.131; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 16:41:15.132; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 16:41:15.132; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:41:15.155; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 274
INFO  - 2020-02-14 16:41:15.158; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 16:41:15.159; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 16:41:18.386; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 16:41:20.832; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 9284 ms
INFO  - 2020-02-14 16:41:21.016; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
WARN  - 2020-02-14 16:41:21.291; org.springframework.context.support.AbstractApplicationContext; Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'articleController' defined in file [C:\Users\Legna\workspace\yangjinjing-cms\target\classes\com\yangjinjing\cms\controller\ArticleController.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.yangjinjing.cms.controller.ArticleController]: Constructor threw exception; nested exception is java.lang.Error: Unresolved compilation problem: 
	Syntax error on token ""/"", invalid MemberValuePair

ERROR - 2020-02-14 16:41:21.299; org.springframework.web.servlet.FrameworkServlet; Context initialization failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'articleController' defined in file [C:\Users\Legna\workspace\yangjinjing-cms\target\classes\com\yangjinjing\cms\controller\ArticleController.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.yangjinjing.cms.controller.ArticleController]: Constructor threw exception; nested exception is java.lang.Error: Unresolved compilation problem: 
	Syntax error on token ""/"", invalid MemberValuePair

	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1287)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1181)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549)
	at org.springframework.web.servlet.FrameworkServlet.configureAndRefreshWebApplicationContext(FrameworkServlet.java:701)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:667)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:715)
	at org.springframework.web.servlet.FrameworkServlet.initWebApplicationContext(FrameworkServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.initServletBean(FrameworkServlet.java:529)
	at org.springframework.web.servlet.HttpServletBean.init(HttpServletBean.java:169)
	at javax.servlet.GenericServlet.init(GenericServlet.java:244)
	at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:669)
	at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:426)
	at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:760)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:374)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.startWebapp(JettyWebAppContext.java:360)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:785)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:287)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.doStart(JettyWebAppContext.java:428)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo.restartWebApp(JettyRunMojo.java:553)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo$1.onPathWatchEvents(JettyRunMojo.java:405)
	at org.eclipse.jetty.util.PathWatcher.notifyEvents(PathWatcher.java:1366)
	at org.eclipse.jetty.util.PathWatcher.run(PathWatcher.java:1190)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.yangjinjing.cms.controller.ArticleController]: Constructor threw exception; nested exception is java.lang.Error: Unresolved compilation problem: 
	Syntax error on token ""/"", invalid MemberValuePair

	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:184)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:87)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1279)
	... 34 more
Caused by: java.lang.Error: Unresolved compilation problem: 
	Syntax error on token ""/"", invalid MemberValuePair

	at com.yangjinjing.cms.controller.ArticleController.<init>(ArticleController.java:91)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:172)
	... 36 more
INFO  - 2020-02-14 16:41:23.675; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 16:41:23.695; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 16:41:23.698; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 16:41:27.881; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-14 16:41:28.173; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 16:41:28.738; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 16:41:31.019; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 16:41:31.192; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 16:41:31.193; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 16:41:31.202; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 16:41:31.581; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 16:41:31.584; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 16:41:31.588; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 16:41:31.588; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 16:41:31.588; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:41:31.623; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 276
INFO  - 2020-02-14 16:41:31.628; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 16:41:31.629; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 16:41:35.712; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 16:41:38.204; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 10321 ms
INFO  - 2020-02-14 16:41:38.420; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
WARN  - 2020-02-14 16:41:38.774; org.springframework.context.support.AbstractApplicationContext; Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'articleController' defined in file [C:\Users\Legna\workspace\yangjinjing-cms\target\classes\com\yangjinjing\cms\controller\ArticleController.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.yangjinjing.cms.controller.ArticleController]: Constructor threw exception; nested exception is java.lang.Error: Unresolved compilation problem: 
	String literal is not properly closed by a double-quote

ERROR - 2020-02-14 16:41:38.776; org.springframework.web.servlet.FrameworkServlet; Context initialization failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'articleController' defined in file [C:\Users\Legna\workspace\yangjinjing-cms\target\classes\com\yangjinjing\cms\controller\ArticleController.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.yangjinjing.cms.controller.ArticleController]: Constructor threw exception; nested exception is java.lang.Error: Unresolved compilation problem: 
	String literal is not properly closed by a double-quote

	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1287)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1181)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549)
	at org.springframework.web.servlet.FrameworkServlet.configureAndRefreshWebApplicationContext(FrameworkServlet.java:701)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:667)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:715)
	at org.springframework.web.servlet.FrameworkServlet.initWebApplicationContext(FrameworkServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.initServletBean(FrameworkServlet.java:529)
	at org.springframework.web.servlet.HttpServletBean.init(HttpServletBean.java:169)
	at javax.servlet.GenericServlet.init(GenericServlet.java:244)
	at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:669)
	at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:426)
	at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:760)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:374)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.startWebapp(JettyWebAppContext.java:360)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:785)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:287)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.doStart(JettyWebAppContext.java:428)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo.restartWebApp(JettyRunMojo.java:553)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo$1.onPathWatchEvents(JettyRunMojo.java:405)
	at org.eclipse.jetty.util.PathWatcher.notifyEvents(PathWatcher.java:1366)
	at org.eclipse.jetty.util.PathWatcher.run(PathWatcher.java:1190)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.yangjinjing.cms.controller.ArticleController]: Constructor threw exception; nested exception is java.lang.Error: Unresolved compilation problem: 
	String literal is not properly closed by a double-quote

	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:184)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:87)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1279)
	... 34 more
Caused by: java.lang.Error: Unresolved compilation problem: 
	String literal is not properly closed by a double-quote

	at com.yangjinjing.cms.controller.ArticleController.<init>(ArticleController.java:91)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:172)
	... 36 more
INFO  - 2020-02-14 16:41:41.654; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 16:41:41.661; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 16:41:41.662; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 16:41:46.292; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-14 16:41:46.674; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 16:41:47.389; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 16:41:49.656; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 16:41:49.798; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 16:41:49.798; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 16:41:49.809; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 16:41:50.386; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 16:41:50.394; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 16:41:50.401; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 16:41:50.402; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 16:41:50.403; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:41:50.453; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 278
INFO  - 2020-02-14 16:41:50.462; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 16:41:50.464; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 16:41:54.151; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 16:41:56.914; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 10618 ms
INFO  - 2020-02-14 16:41:57.144; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-14 16:41:57.980; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-14 16:41:58.827; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1683 ms
INFO  - 2020-02-14 16:42:37.277; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 16:42:37.329; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 16:42:37.331; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 16:42:46.242; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-14 16:42:47.705; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 16:42:48.894; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 16:42:50.470; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-14 16:42:51.834; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
INFO  - 2020-02-14 16:42:53.007; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

WARN  - 2020-02-14 16:42:53.016; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 16:42:53.298; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 16:42:53.299; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 16:42:53.312; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 16:42:54.217; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 16:42:54.222; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 16:42:54.229; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 16:42:54.229; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 16:42:54.230; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:42:54.312; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 280
INFO  - 2020-02-14 16:42:54.320; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 16:42:54.321; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 16:42:56.847; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 16:42:57.043; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 16:42:57.044; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 16:42:57.077; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 16:42:57.637; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 16:42:57.643; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 16:42:57.649; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 16:42:57.649; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 16:42:57.650; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:43:00.322; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Attempt to heartbeat failed since group is rebalancing
INFO  - 2020-02-14 16:43:00.338; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions [article-0]
INFO  - 2020-02-14 16:43:00.338; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: [article-0]
INFO  - 2020-02-14 16:43:00.338; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:43:00.383; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 281
INFO  - 2020-02-14 16:43:00.383; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 281
INFO  - 2020-02-14 16:43:00.384; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 16:43:00.385; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 16:43:00.387; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-14 16:43:00.387; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-14 16:43:00.984; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 16:43:02.866; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 16:43:07.226; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 20972 ms
INFO  - 2020-02-14 16:43:08.099; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-14 16:43:12.037; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-14 16:43:13.234; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 5134 ms
ERROR - 2020-02-14 16:43:18.859; org.springframework.data.elasticsearch.repository.support.AbstractElasticsearchRepository; failed to load elasticsearch nodes : NoNodeAvailableException[None of the configured nodes were available: [{vdjHyu9}{vdjHyu9rTyiZkpRqeeazIw}{3ww9Uf_1S-qw8Ey2hfbZ4Q}{192.168.198.128}{192.168.198.128:9300}{ml.machine_memory=1813213184, ml.max_open_jobs=20, xpack.installed=true, ml.enabled=true}]]; nested: NodeDisconnectedException[[vdjHyu9][192.168.198.128:9300][indices:admin/mapping/put] disconnected];; org.elasticsearch.transport.NodeDisconnectedException: [vdjHyu9][192.168.198.128:9300][indices:admin/mapping/put] disconnected
INFO  - 2020-02-14 16:43:27.013; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 36535 ms
INFO  - 2020-02-14 16:43:30.909; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Attempt to heartbeat failed since group is rebalancing
INFO  - 2020-02-14 16:43:30.912; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 16:43:30.912; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 16:43:30.912; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:43:31.635; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 282
INFO  - 2020-02-14 16:43:31.640; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 16:43:31.640; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 16:43:31.643; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-14 16:44:12.819; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-14 16:44:13.441; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 16:44:14.010; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 16:44:16.072; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 16:44:16.217; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 16:44:16.217; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 16:44:16.228; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 16:44:16.686; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 16:44:16.692; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 16:44:16.701; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 16:44:16.702; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 16:44:16.704; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:44:16.741; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 284
INFO  - 2020-02-14 16:44:16.744; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 16:44:16.745; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 16:44:20.377; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 16:44:22.776; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 9948 ms
INFO  - 2020-02-14 16:44:23.006; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-14 16:44:23.808; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-14 16:44:24.359; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1353 ms
INFO  - 2020-02-14 16:46:52.936; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 16:46:52.952; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 16:46:52.954; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 16:46:57.906; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-14 16:46:58.292; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 16:46:59.061; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 16:47:01.631; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 16:47:01.783; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 16:47:01.783; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 16:47:01.795; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 16:47:02.158; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 16:47:02.161; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 16:47:02.166; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 16:47:02.166; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 16:47:02.167; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:47:02.200; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 286
INFO  - 2020-02-14 16:47:02.203; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 16:47:02.203; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 16:47:05.603; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 16:47:22.109; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-14 16:47:22.534; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 16:47:23.146; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 16:47:25.300; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 16:47:25.467; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 16:47:25.469; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 16:47:25.492; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 16:47:25.909; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 16:47:25.914; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 16:47:25.931; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 16:47:25.932; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 16:47:25.932; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:47:25.979; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 288
INFO  - 2020-02-14 16:47:25.985; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 16:47:25.986; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 16:47:29.785; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 16:47:32.223; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 10109 ms
INFO  - 2020-02-14 16:47:32.475; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-14 16:47:33.166; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-14 16:47:33.709; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1233 ms
INFO  - 2020-02-14 16:47:41.253; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-14 16:48:36.884; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 16:48:36.894; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 16:48:36.896; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 16:48:38.324; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-14 16:48:41.236; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-14 16:48:41.543; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 16:48:42.241; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 16:49:35.822; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-14 16:49:36.379; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 16:49:36.996; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 16:49:39.758; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 16:49:39.931; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 16:49:39.932; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 16:49:39.957; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 16:49:40.385; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 16:49:40.394; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 16:49:40.401; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 16:49:40.403; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 16:49:40.404; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:49:40.445; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 290
INFO  - 2020-02-14 16:49:40.453; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 16:49:40.453; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 16:49:44.482; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 16:49:46.976; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 11146 ms
INFO  - 2020-02-14 16:49:47.285; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-14 16:49:47.967; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-14 16:49:48.421; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1136 ms
INFO  - 2020-02-14 16:49:49.269; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-14 16:54:25.632; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-14 16:54:25.663; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@53f65459, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@3b088d51, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@1786dec2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@74650e52, org.springframework.test.context.transaction.TransactionalTestExecutionListener@15d0c81b, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@6acdbdf5]
INFO  - 2020-02-14 16:54:26.262; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 16:54:26.962; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 16:54:29.353; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 16:54:30.357; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 16:54:30.358; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 16:54:30.369; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 16:54:30.796; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 16:54:30.798; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 16:54:30.804; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 16:54:30.805; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 16:54:30.805; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:54:31.503; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Attempt to heartbeat failed since group is rebalancing
INFO  - 2020-02-14 16:54:31.506; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions [article-0]
INFO  - 2020-02-14 16:54:31.506; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: [article-0]
INFO  - 2020-02-14 16:54:31.506; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:54:31.513; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 291
INFO  - 2020-02-14 16:54:31.513; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 291
INFO  - 2020-02-14 16:54:31.514; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-14 16:54:31.514; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-14 16:54:31.519; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 16:54:31.520; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 16:54:35.225; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 16:54:38.160; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-14 16:54:58.481; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-14 16:54:58.514; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@6895a785, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@184f6be2, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@56aac163, org.springframework.test.context.support.DirtiesContextTestExecutionListener@1f7030a6, org.springframework.test.context.transaction.TransactionalTestExecutionListener@5a1c0542, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@396f6598]
INFO  - 2020-02-14 16:54:59.005; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 16:55:00.474; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 16:55:03.519; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 16:55:04.519; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 16:55:04.519; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 16:55:04.522; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Attempt to heartbeat failed since group is rebalancing
INFO  - 2020-02-14 16:55:04.522; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 16:55:04.522; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 16:55:04.523; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:55:04.527; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 292
INFO  - 2020-02-14 16:55:04.528; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 16:55:04.528; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 16:55:04.531; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 16:55:05.087; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 16:55:05.090; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 16:55:05.097; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 16:55:05.097; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 16:55:05.098; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:55:07.532; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Attempt to heartbeat failed since group is rebalancing
INFO  - 2020-02-14 16:55:07.535; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions [article-0]
INFO  - 2020-02-14 16:55:07.536; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: [article-0]
INFO  - 2020-02-14 16:55:07.536; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:55:07.563; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 293
INFO  - 2020-02-14 16:55:07.563; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 293
INFO  - 2020-02-14 16:55:07.564; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 16:55:07.564; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 16:55:07.567; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-14 16:55:07.568; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-14 16:55:10.657; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 16:55:13.893; org.apache.kafka.common.config.AbstractConfig; ProducerConfig values: 
	acks = 1
	batch.size = 1638
	bootstrap.servers = [192.168.198.128:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  - 2020-02-14 16:55:13.942; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 16:55:13.943; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 16:55:13.995; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
ERROR - 2020-02-14 16:55:15.709; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = article, partition = 0, offset = 491, CreateTime = 1581670515133, serialized key size = -1, serialized value size = 804, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"articleType":0,"categoryId":1,"channelId":1,"commentCnt":0,"complainCnt":0,"content":"3605000APP... ...  1535","created":1581670513611,"deleted":0,"hits":615998534,"hot":0,"picture":"20191224/f018506e-41ff-4f22-b988-2d0ea0b41c1d","status":0,"title":"3605000APP","updated":1581670513611,"userId":68})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.yangjinjing.cms.dao.ArticleMapper.add-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article(title,content,picture,channel_id,category_id,user_id,hits,hot,status,deleted,created,updated,commentCnt,articleType) VALUES(?,?,?,?,?,?,0,0,0,0,now(),now(),0,?)
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy43.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy44.add(Unknown Source)
	at com.yangjinjing.cms.service.impl.ArticleServiceImpl.add(ArticleServiceImpl.java:65)
	at sun.reflect.GeneratedMethodAccessor100.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
	at com.sun.proxy.$Proxy48.add(Unknown Source)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:30)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:1)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor92.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy75.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor101.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 29 more
ERROR - 2020-02-14 16:55:16.073; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = article, partition = 0, offset = 502, CreateTime = 1581670515688, serialized key size = -1, serialized value size = 745, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"articleType":0,"categoryId":1,"channelId":1,"commentCnt":0,"complainCnt":0,"content":"81App Store5002.01  App Store500 2008App Store","created":1581670513611,"deleted":0,"hits":621321401,"hot":1,"picture":"20191224/f018506e-41ff-4f22-b988-2d0ea0b41c1d","status":0,"title":"81App Store5002","updated":1581670513611,"userId":68})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.yangjinjing.cms.dao.ArticleMapper.add-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article(title,content,picture,channel_id,category_id,user_id,hits,hot,status,deleted,created,updated,commentCnt,articleType) VALUES(?,?,?,?,?,?,0,0,0,0,now(),now(),0,?)
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy43.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy44.add(Unknown Source)
	at com.yangjinjing.cms.service.impl.ArticleServiceImpl.add(ArticleServiceImpl.java:65)
	at sun.reflect.GeneratedMethodAccessor100.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
	at com.sun.proxy.$Proxy48.add(Unknown Source)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:30)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:1)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor92.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy75.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor101.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 29 more
ERROR - 2020-02-14 16:55:16.119; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = article, partition = 0, offset = 504, CreateTime = 1581670515767, serialized key size = -1, serialized value size = 739, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"articleType":0,"categoryId":1,"channelId":1,"commentCnt":0,"complainCnt":0,"content":"91 | 20197000  20197000 QuestMobile201912316985.86","created":1581670513611,"deleted":0,"hits":-1827738221,"hot":0,"picture":"20191224/f018506e-41ff-4f22-b988-2d0ea0b41c1d","status":0,"title":"91  20197000","updated":1581670513611,"userId":68})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.yangjinjing.cms.dao.ArticleMapper.add-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article(title,content,picture,channel_id,category_id,user_id,hits,hot,status,deleted,created,updated,commentCnt,articleType) VALUES(?,?,?,?,?,?,0,0,0,0,now(),now(),0,?)
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy43.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy44.add(Unknown Source)
	at com.yangjinjing.cms.service.impl.ArticleServiceImpl.add(ArticleServiceImpl.java:65)
	at sun.reflect.GeneratedMethodAccessor100.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
	at com.sun.proxy.$Proxy48.add(Unknown Source)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:30)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:1)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor92.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy75.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor101.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 29 more
ERROR - 2020-02-14 16:55:16.362; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = article, partition = 0, offset = 512, CreateTime = 1581670516133, serialized key size = -1, serialized value size = 720, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"articleType":0,"categoryId":1,"channelId":1,"commentCnt":0,"complainCnt":0,"content":"Facebook  AI TikTok   |  8  TikTok    TikTok ","created":1581670513611,"deleted":0,"hits":1706871408,"hot":1,"picture":"20191224/f018506e-41ff-4f22-b988-2d0ea0b41c1d","status":0,"title":"Facebook  AI TikTok     8 ","updated":1581670513611,"userId":68})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.yangjinjing.cms.dao.ArticleMapper.add-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article(title,content,picture,channel_id,category_id,user_id,hits,hot,status,deleted,created,updated,commentCnt,articleType) VALUES(?,?,?,?,?,?,0,0,0,0,now(),now(),0,?)
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy43.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy44.add(Unknown Source)
	at com.yangjinjing.cms.service.impl.ArticleServiceImpl.add(ArticleServiceImpl.java:65)
	at sun.reflect.GeneratedMethodAccessor100.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
	at com.sun.proxy.$Proxy48.add(Unknown Source)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:30)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:1)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor92.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy75.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor101.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 29 more
ERROR - 2020-02-14 16:55:16.367; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = article, partition = 0, offset = 513, CreateTime = 1581670516200, serialized key size = -1, serialized value size = 645, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"articleType":0,"categoryId":1,"channelId":1,"commentCnt":0,"complainCnt":0,"content":"Galaxy S20 /Galaxy Z Flip 100   Galaxy S20  S20 Galaxy Z Flip  Galaxy Z Flip","created":1581670513611,"deleted":0,"hits":396931313,"hot":0,"picture":"20191224/f018506e-41ff-4f22-b988-2d0ea0b41c1d","status":0,"title":"Galaxy S20 Galaxy Z Flip 100 ","updated":1581670513611,"userId":68})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.yangjinjing.cms.dao.ArticleMapper.add-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article(title,content,picture,channel_id,category_id,user_id,hits,hot,status,deleted,created,updated,commentCnt,articleType) VALUES(?,?,?,?,?,?,0,0,0,0,now(),now(),0,?)
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy43.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy44.add(Unknown Source)
	at com.yangjinjing.cms.service.impl.ArticleServiceImpl.add(ArticleServiceImpl.java:65)
	at sun.reflect.GeneratedMethodAccessor100.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
	at com.sun.proxy.$Proxy48.add(Unknown Source)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:30)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:1)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor92.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy75.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor101.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 29 more
ERROR - 2020-02-14 16:55:19.778; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = article, partition = 0, offset = 555, CreateTime = 1581670518145, serialized key size = -1, serialized value size = 728, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"articleType":0,"categoryId":1,"channelId":1,"commentCnt":0,"complainCnt":0,"content":"App Store20195005858 2008App Store155020191","created":1581670513611,"deleted":0,"hits":-1444430637,"hot":0,"picture":"20191224/f018506e-41ff-4f22-b988-2d0ea0b41c1d","status":0,"title":"App Store20195005858","updated":1581670513611,"userId":68})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.yangjinjing.cms.dao.ArticleMapper.add-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article(title,content,picture,channel_id,category_id,user_id,hits,hot,status,deleted,created,updated,commentCnt,articleType) VALUES(?,?,?,?,?,?,0,0,0,0,now(),now(),0,?)
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy43.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy44.add(Unknown Source)
	at com.yangjinjing.cms.service.impl.ArticleServiceImpl.add(ArticleServiceImpl.java:65)
	at sun.reflect.GeneratedMethodAccessor100.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
	at com.sun.proxy.$Proxy48.add(Unknown Source)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:30)
	at com.yangjinjing.listener.MsgListener.onMessage(MsgListener.java:1)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor92.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy75.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor101.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 29 more
INFO  - 2020-02-14 16:55:23.170; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-14 16:55:23.187; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-14 16:55:23.189; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-14 16:55:24.322; org.apache.kafka.clients.producer.KafkaProducer; [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
INFO  - 2020-02-14 16:55:25.702; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Attempt to heartbeat failed since group is rebalancing
INFO  - 2020-02-14 16:55:25.786; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions [article-0]
INFO  - 2020-02-14 16:55:25.786; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: [article-0]
INFO  - 2020-02-14 16:55:25.786; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:55:25.791; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 294
INFO  - 2020-02-14 16:55:25.793; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 16:55:25.794; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 16:56:34.258; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-14 16:56:35.031; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-14 16:56:35.849; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-14 16:56:38.001; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-14 16:56:38.136; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-14 16:56:38.136; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-14 16:56:38.145; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-14 16:56:38.609; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-14 16:56:38.615; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-14 16:56:38.627; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-14 16:56:38.628; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-14 16:56:38.628; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:56:38.697; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 296
INFO  - 2020-02-14 16:56:38.700; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 16:56:38.701; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 16:56:42.640; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-14 16:56:45.050; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 10784 ms
INFO  - 2020-02-14 16:56:45.364; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-14 16:56:46.263; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-14 16:56:46.930; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1565 ms
INFO  - 2020-02-14 16:56:49.830; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-14 16:59:11.809; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2020-02-14 16:59:16.681; org.apache.kafka.clients.FetchSessionHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 0: org.apache.kafka.common.errors.DisconnectException.
INFO  - 2020-02-14 16:59:16.744; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
ERROR - 2020-02-14 16:59:16.751; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetCommitResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Offset commit failed on partition article-0 at offset 622: The coordinator is not aware of this member.
WARN  - 2020-02-14 16:59:16.752; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$4; [Consumer clientId=consumer-1, groupId=test-consumer-group] Asynchronous auto-commit of offsets {article-0=OffsetAndMetadata{offset=622, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
WARN  - 2020-02-14 16:59:16.754; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Synchronous auto-commit of offsets {article-0=OffsetAndMetadata{offset=622, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
INFO  - 2020-02-14 16:59:16.755; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions [article-0]
INFO  - 2020-02-14 16:59:16.756; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: [article-0]
INFO  - 2020-02-14 16:59:16.757; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-14 16:59:16.807; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 298
INFO  - 2020-02-14 16:59:16.808; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-14 16:59:16.809; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-14 17:06:25.889; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2020-02-14 17:06:44.799; org.apache.kafka.clients.FetchSessionHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 0: org.apache.kafka.common.errors.DisconnectException.
WARN  - 2020-02-14 17:07:05.903; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-14 17:07:27.007; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-14 17:07:48.211; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-14 17:08:09.670; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-14 17:08:31.633; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-14 17:08:53.745; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-14 17:09:15.810; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-14 17:09:37.877; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-14 17:10:00.049; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
INFO  - 2020-02-17 10:37:07.355; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-17 10:37:07.901; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 10:37:08.424; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 10:37:10.180; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 10:37:10.285; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 10:37:10.286; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 10:37:10.299; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 10:37:10.792; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 10:37:10.817; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 10:37:10.822; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 10:37:10.824; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 10:37:10.824; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 10:37:11.048; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 300
INFO  - 2020-02-17 10:37:11.050; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 10:37:11.050; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 10:37:13.721; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 10:37:19.226; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 11866 ms
INFO  - 2020-02-17 10:37:19.628; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-17 10:37:20.261; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-17 10:37:20.700; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1072 ms
INFO  - 2020-02-17 10:37:43.976; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-17 10:41:50.323; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 10:41:50.344; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 10:41:50.346; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 10:41:52.335; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-17 10:41:54.828; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-17 10:41:55.160; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 10:41:55.674; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 10:41:57.389; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 10:41:57.495; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 10:41:57.495; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 10:41:57.503; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 10:41:57.771; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 10:41:57.781; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 10:41:57.786; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 10:41:57.787; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 10:41:57.787; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 10:41:57.858; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 302
INFO  - 2020-02-17 10:41:57.864; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 10:41:57.864; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 10:42:00.957; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 10:42:03.179; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 8347 ms
INFO  - 2020-02-17 10:42:03.384; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-17 10:42:03.950; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-17 10:42:04.361; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 977 ms
INFO  - 2020-02-17 10:43:34.215; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-17 10:44:21.613; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 10:44:21.683; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 10:44:21.684; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 10:44:23.479; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-17 10:44:27.340; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-17 10:44:27.588; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 10:44:28.046; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 10:44:29.532; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 10:44:29.646; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 10:44:29.646; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 10:44:29.658; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 10:44:29.978; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 10:44:29.980; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 10:44:29.989; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 10:44:29.989; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 10:44:29.989; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 10:44:30.022; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 304
INFO  - 2020-02-17 10:44:30.024; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 10:44:30.025; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 10:44:32.955; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 10:44:35.085; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 7740 ms
INFO  - 2020-02-17 10:44:35.289; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-17 10:44:35.798; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-17 10:44:36.160; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 871 ms
INFO  - 2020-02-17 10:45:16.515; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-17 10:57:47.053; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 10:57:47.058; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 10:57:47.060; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 10:57:48.822; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-17 10:57:54.160; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-17 10:57:54.387; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 10:57:54.804; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 10:57:56.356; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 10:57:56.440; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 10:57:56.441; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 10:57:56.448; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 10:57:56.686; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 10:57:56.701; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 10:57:56.705; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 10:57:56.705; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 10:57:56.705; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 10:57:56.880; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 306
INFO  - 2020-02-17 10:57:56.883; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 10:57:56.883; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 10:57:59.471; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 10:58:01.415; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 7252 ms
INFO  - 2020-02-17 10:58:01.600; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-17 10:58:02.075; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-17 10:58:02.362; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 762 ms
INFO  - 2020-02-17 10:59:28.256; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-17 12:31:09.146; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-17 12:31:09.499; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 12:31:09.902; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 12:31:11.390; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 12:31:11.490; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 12:31:11.491; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 12:31:11.499; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 12:31:11.755; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 12:31:11.758; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 12:31:11.762; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 12:31:11.763; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 12:31:11.763; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 12:31:11.779; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 308
INFO  - 2020-02-17 12:31:11.782; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 12:31:11.782; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 12:31:14.521; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 12:31:16.478; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 7330 ms
INFO  - 2020-02-17 12:31:16.715; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-17 12:31:17.224; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-17 12:31:17.533; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 818 ms
INFO  - 2020-02-17 12:31:23.251; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-17 12:54:30.860; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-17 12:54:31.317; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 12:54:31.719; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 12:54:33.289; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 12:54:33.391; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 12:54:33.391; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 12:54:33.399; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 12:54:33.612; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 12:54:33.615; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 12:54:33.619; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 12:54:33.620; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 12:54:33.620; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 12:54:35.471; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 315
INFO  - 2020-02-17 12:54:35.474; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 12:54:35.475; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 12:54:36.251; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 12:54:38.371; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 7507 ms
INFO  - 2020-02-17 12:54:38.684; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-17 12:54:39.267; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-17 12:54:39.665; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 980 ms
INFO  - 2020-02-17 12:54:53.841; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-17 13:52:34.662; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-17 13:52:34.688; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@131276c2, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@26aa12dd, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3fd7a715, org.springframework.test.context.support.DirtiesContextTestExecutionListener@711f39f9, org.springframework.test.context.transaction.TransactionalTestExecutionListener@71bbf57e, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@7f13d6e]
INFO  - 2020-02-17 13:52:35.361; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 13:52:36.140; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 13:52:38.560; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 13:52:39.722; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 13:52:39.722; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 13:52:39.730; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 13:52:49.601; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
WARN  - 2020-02-17 13:53:01.576; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
ERROR - 2020-02-17 13:53:12.809; org.springframework.data.elasticsearch.repository.support.AbstractElasticsearchRepository; failed to load elasticsearch nodes : org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes are available: [{#transport#-1}{uJWBC50cRNqC-K_dEVDPTQ}{192.168.198.128}{192.168.198.128:9300}]
INFO  - 2020-02-17 13:53:13.238; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 13:53:13.244; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 13:53:13.246; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 14:15:37.434; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-17 14:15:37.460; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@51cdd8a, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@d44fc21, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@23faf8f2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2d6eabae, org.springframework.test.context.transaction.TransactionalTestExecutionListener@4e7dc304, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@64729b1e]
INFO  - 2020-02-17 14:15:37.907; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 14:15:38.613; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 14:15:40.597; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 14:15:41.506; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 14:15:41.507; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 14:15:41.520; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 14:15:45.895; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 14:15:48.472; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 14:15:48.481; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 14:15:48.483; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 14:16:59.450; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-17 14:16:59.488; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@51cdd8a, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@d44fc21, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@23faf8f2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2d6eabae, org.springframework.test.context.transaction.TransactionalTestExecutionListener@4e7dc304, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@64729b1e]
INFO  - 2020-02-17 14:17:00.147; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 14:17:00.875; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 14:17:02.850; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 14:17:03.770; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 14:17:03.770; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 14:17:03.783; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 14:17:04.383; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 14:17:04.385; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 14:17:04.390; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 14:17:04.390; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 14:17:04.391; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 14:17:06.515; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 331
INFO  - 2020-02-17 14:17:06.518; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-17 14:17:06.518; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-17 14:17:08.010; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 14:17:14.233; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 14:17:14.242; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 14:17:14.243; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 14:18:21.674; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-17 14:18:21.717; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@51cdd8a, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@d44fc21, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@23faf8f2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2d6eabae, org.springframework.test.context.transaction.TransactionalTestExecutionListener@4e7dc304, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@64729b1e]
INFO  - 2020-02-17 14:18:22.353; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 14:18:22.987; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 14:18:25.028; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 14:18:25.941; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 14:18:25.943; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 14:18:25.951; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 14:18:26.312; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 14:18:26.314; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 14:18:26.319; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 14:18:26.320; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 14:18:26.321; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 14:18:27.745; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 333
INFO  - 2020-02-17 14:18:27.749; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 14:18:27.749; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 14:18:30.402; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 14:18:32.890; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 14:18:32.897; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 14:18:32.899; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 14:19:50.682; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-17 14:19:50.708; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@51cdd8a, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@d44fc21, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@23faf8f2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2d6eabae, org.springframework.test.context.transaction.TransactionalTestExecutionListener@4e7dc304, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@64729b1e]
INFO  - 2020-02-17 14:19:51.151; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 14:19:51.726; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 14:19:53.447; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 14:19:54.326; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 14:19:54.326; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 14:19:54.337; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 14:19:54.706; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 14:19:54.711; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 14:19:54.717; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 14:19:54.718; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 14:19:54.718; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 14:19:54.801; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 335
INFO  - 2020-02-17 14:19:54.803; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 14:19:54.803; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 14:19:58.315; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 14:20:09.167; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-17 14:20:09.660; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 14:20:09.667; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 14:20:09.668; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 14:20:10.875; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-17 14:21:28.903; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-17 14:21:28.934; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@51cdd8a, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@d44fc21, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@23faf8f2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2d6eabae, org.springframework.test.context.transaction.TransactionalTestExecutionListener@4e7dc304, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@64729b1e]
INFO  - 2020-02-17 14:21:29.358; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 14:21:29.926; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 14:21:31.665; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 14:21:32.514; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 14:21:32.514; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 14:21:32.530; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 14:21:32.807; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 14:21:32.809; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 14:21:32.812; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 14:21:32.812; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 14:21:32.812; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 14:21:33.869; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 337
INFO  - 2020-02-17 14:21:33.871; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 14:21:33.871; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 14:21:36.505; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 14:21:44.135; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 14:21:44.149; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 14:21:44.151; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 14:23:01.211; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-17 14:23:01.243; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@51cdd8a, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@d44fc21, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@23faf8f2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2d6eabae, org.springframework.test.context.transaction.TransactionalTestExecutionListener@4e7dc304, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@64729b1e]
INFO  - 2020-02-17 14:23:01.720; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 14:23:02.326; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 14:23:04.175; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 14:23:05.067; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 14:23:05.067; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 14:23:05.074; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 14:23:05.367; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 14:23:05.369; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 14:23:05.372; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 14:23:05.373; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 14:23:05.373; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 14:23:06.918; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 339
INFO  - 2020-02-17 14:23:06.923; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 14:23:06.924; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 14:23:09.012; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 14:23:11.206; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 14:23:11.219; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 14:23:11.221; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 14:27:52.508; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-17 14:27:52.545; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@51cdd8a, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@d44fc21, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@23faf8f2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2d6eabae, org.springframework.test.context.transaction.TransactionalTestExecutionListener@4e7dc304, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@64729b1e]
INFO  - 2020-02-17 14:27:53.020; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 14:27:53.667; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 14:27:55.423; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 14:27:56.345; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 14:27:56.345; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 14:27:56.352; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 14:27:56.606; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 14:27:56.607; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 14:27:56.610; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 14:27:56.610; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 14:27:56.611; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 14:27:58.045; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 341
INFO  - 2020-02-17 14:27:58.048; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 14:27:58.048; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 14:28:00.234; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 14:28:02.715; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 14:28:02.732; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 14:28:02.737; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 14:30:01.360; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-17 14:30:01.386; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@51cdd8a, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@d44fc21, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@23faf8f2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2d6eabae, org.springframework.test.context.transaction.TransactionalTestExecutionListener@4e7dc304, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@64729b1e]
INFO  - 2020-02-17 14:30:01.861; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 14:30:02.512; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 14:30:04.246; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 14:30:05.115; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 14:30:05.116; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 14:30:05.126; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 14:30:05.466; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 14:30:05.468; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 14:30:05.471; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 14:30:05.471; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 14:30:05.472; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 14:30:07.114; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 343
INFO  - 2020-02-17 14:30:07.117; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 14:30:07.117; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 14:30:09.217; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 14:30:11.545; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 14:30:11.555; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 14:30:11.556; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 14:32:57.231; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-17 14:32:57.287; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@51cdd8a, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@d44fc21, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@23faf8f2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2d6eabae, org.springframework.test.context.transaction.TransactionalTestExecutionListener@4e7dc304, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@64729b1e]
INFO  - 2020-02-17 14:32:57.858; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 14:32:58.555; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 14:33:00.398; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 14:33:01.292; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 14:33:01.293; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 14:33:01.302; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 14:33:01.678; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 14:33:01.680; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 14:33:01.685; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 14:33:01.685; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 14:33:01.686; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 14:33:04.263; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 345
INFO  - 2020-02-17 14:33:04.268; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 14:33:04.268; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 14:33:05.321; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 14:33:07.846; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 14:33:07.874; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 14:33:07.877; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 14:39:10.155; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-17 14:39:10.188; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@51cdd8a, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@d44fc21, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@23faf8f2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2d6eabae, org.springframework.test.context.transaction.TransactionalTestExecutionListener@4e7dc304, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@64729b1e]
INFO  - 2020-02-17 14:39:10.654; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 14:39:11.282; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 14:39:13.309; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 14:39:14.224; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 14:39:14.225; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 14:39:14.242; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 14:39:14.586; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 14:39:14.590; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 14:39:14.596; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 14:39:14.596; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 14:39:14.596; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 14:39:16.462; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 347
INFO  - 2020-02-17 14:39:16.464; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 14:39:16.464; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 14:39:18.223; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 14:39:20.733; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 14:39:20.740; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 14:39:20.741; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 14:45:22.922; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-17 14:45:22.953; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@51cdd8a, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@d44fc21, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@23faf8f2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2d6eabae, org.springframework.test.context.transaction.TransactionalTestExecutionListener@4e7dc304, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@64729b1e]
INFO  - 2020-02-17 14:45:23.559; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 14:45:24.456; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 14:45:26.191; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 14:45:27.300; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 14:45:27.300; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 14:45:27.311; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 14:45:27.675; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 14:45:27.677; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 14:45:27.682; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 14:45:27.682; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 14:45:27.683; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 14:45:28.631; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 349
INFO  - 2020-02-17 14:45:28.634; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 14:45:28.635; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 14:45:31.445; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 14:45:33.890; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 14:45:33.898; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 14:45:33.899; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 14:46:07.614; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-17 14:46:07.639; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@51cdd8a, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@d44fc21, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@23faf8f2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2d6eabae, org.springframework.test.context.transaction.TransactionalTestExecutionListener@4e7dc304, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@64729b1e]
INFO  - 2020-02-17 14:46:08.210; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 14:46:08.878; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 14:46:10.652; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 14:46:11.577; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 14:46:11.578; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 14:46:11.591; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 14:46:12.156; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 14:46:12.161; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 14:46:12.166; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 14:46:12.166; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 14:46:12.166; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 14:46:13.675; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 351
INFO  - 2020-02-17 14:46:13.680; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 14:46:13.680; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 14:46:16.578; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 14:46:19.149; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
ERROR - 2020-02-17 14:46:19.333; com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread; create connection error
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

Last packet sent to the server was 0 ms ago.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2103)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:718)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:46)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:302)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:282)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1375)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1431)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:1844)
Caused by: java.net.SocketException: Network is unreachable: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:244)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:253)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:280)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2026)
	... 12 more
ERROR - 2020-02-17 14:46:19.341; com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread; create connection error
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

Last packet sent to the server was 0 ms ago.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2103)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:718)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:46)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:302)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:282)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1375)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1431)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:1844)
Caused by: java.net.SocketException: Network is unreachable: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:244)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:253)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:280)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2026)
	... 12 more
ERROR - 2020-02-17 14:46:19.343; com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread; create connection error
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

Last packet sent to the server was 0 ms ago.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2103)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:718)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:46)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:302)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:282)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1375)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1431)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:1844)
Caused by: java.net.SocketException: Network is unreachable: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:244)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:253)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:280)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2026)
	... 12 more
ERROR - 2020-02-17 14:46:19.345; com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread; create connection error
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

Last packet sent to the server was 0 ms ago.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2103)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:718)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:46)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:302)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:282)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1375)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1431)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:1844)
Caused by: java.net.SocketException: Network is unreachable: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:244)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:253)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:280)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2026)
	... 12 more
ERROR - 2020-02-17 14:46:19.347; com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread; create connection error
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

Last packet sent to the server was 0 ms ago.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2103)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:718)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:46)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:302)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:282)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1375)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1431)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:1844)
Caused by: java.net.SocketException: Network is unreachable: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:244)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:253)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:280)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2026)
	... 12 more
ERROR - 2020-02-17 14:46:19.349; com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread; create connection error
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

Last packet sent to the server was 0 ms ago.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2103)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:718)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:46)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:302)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:282)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1375)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1431)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:1844)
Caused by: java.net.SocketException: Network is unreachable: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:244)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:253)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:280)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2026)
	... 12 more
ERROR - 2020-02-17 14:46:19.352; com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread; create connection error
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

Last packet sent to the server was 0 ms ago.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2103)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:718)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:46)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:302)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:282)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1375)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1431)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:1844)
Caused by: java.net.SocketException: Network is unreachable: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:244)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:253)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:280)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2026)
	... 12 more
ERROR - 2020-02-17 14:46:19.358; com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread; create connection error
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

Last packet sent to the server was 0 ms ago.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2103)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:718)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:46)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:302)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:282)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1375)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1431)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:1844)
Caused by: java.net.SocketException: Network is unreachable: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:244)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:253)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:280)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2026)
	... 12 more
ERROR - 2020-02-17 14:46:19.361; com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread; create connection error
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

Last packet sent to the server was 0 ms ago.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2103)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:718)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:46)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:302)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:282)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1375)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1431)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:1844)
Caused by: java.net.SocketException: Network is unreachable: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:244)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:253)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:280)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2026)
	... 12 more
ERROR - 2020-02-17 14:46:19.373; com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread; create connection error
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

Last packet sent to the server was 1 ms ago.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2103)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:718)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:46)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:302)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:282)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1375)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1431)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:1844)
Caused by: java.net.SocketException: Network is unreachable: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:244)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:253)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:280)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2026)
	... 12 more
ERROR - 2020-02-17 14:46:19.377; com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread; create connection error
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

Last packet sent to the server was 0 ms ago.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2103)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:718)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:46)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:302)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:282)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1375)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1431)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:1844)
Caused by: java.net.SocketException: Network is unreachable: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:244)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:253)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:280)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2026)
	... 12 more
ERROR - 2020-02-17 14:46:19.382; com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread; create connection error
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

Last packet sent to the server was 0 ms ago.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2103)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:718)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:46)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:302)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:282)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1375)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1431)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:1844)
Caused by: java.net.SocketException: Network is unreachable: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:244)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:253)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:280)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2026)
	... 12 more
ERROR - 2020-02-17 14:46:19.385; com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread; create connection error
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

Last packet sent to the server was 0 ms ago.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2103)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:718)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:46)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:302)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:282)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1375)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1431)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:1844)
Caused by: java.net.SocketException: Network is unreachable: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:244)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:253)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:280)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2026)
	... 12 more
ERROR - 2020-02-17 14:46:19.390; com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread; create connection error
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

Last packet sent to the server was 0 ms ago.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2103)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:718)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:46)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:302)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:282)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1375)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1431)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:1844)
Caused by: java.net.SocketException: Network is unreachable: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:244)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:253)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:280)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2026)
	... 12 more
ERROR - 2020-02-17 14:46:19.393; com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread; create connection error
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

Last packet sent to the server was 0 ms ago.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2103)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:718)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:46)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:302)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:282)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1375)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1431)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:1844)
Caused by: java.net.SocketException: Network is unreachable: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:244)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:253)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:280)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2026)
	... 12 more
ERROR - 2020-02-17 14:46:19.400; com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread; create connection error
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

Last packet sent to the server was 0 ms ago.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2103)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:718)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:46)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:302)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:282)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1375)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1431)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:1844)
Caused by: java.net.SocketException: Network is unreachable: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:244)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:253)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:280)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2026)
	... 12 more
ERROR - 2020-02-17 14:46:19.403; com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread; create connection error
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

Last packet sent to the server was 0 ms ago.
	at sun.reflect.GeneratedConstructorAccessor20.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2103)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:718)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:46)
	at sun.reflect.GeneratedConstructorAccessor17.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:302)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:282)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1375)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1431)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:1844)
Caused by: java.net.SocketException: Network is unreachable: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:244)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:253)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:280)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2026)
	... 11 more
ERROR - 2020-02-17 14:46:19.407; com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread; create connection error
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

Last packet sent to the server was 0 ms ago.
	at sun.reflect.GeneratedConstructorAccessor20.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2103)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:718)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:46)
	at sun.reflect.GeneratedConstructorAccessor17.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:302)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:282)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1375)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1431)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:1844)
Caused by: java.net.SocketException: Network is unreachable: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:244)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:253)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:280)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2026)
	... 11 more
ERROR - 2020-02-17 14:46:19.411; com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread; create connection error
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

Last packet sent to the server was 0 ms ago.
	at sun.reflect.GeneratedConstructorAccessor20.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2103)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:718)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:46)
	at sun.reflect.GeneratedConstructorAccessor17.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:302)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:282)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1375)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1431)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:1844)
Caused by: java.net.SocketException: Network is unreachable: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:244)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:253)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:280)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2026)
	... 11 more
ERROR - 2020-02-17 14:46:19.414; com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread; create connection error
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

Last packet sent to the server was 0 ms ago.
	at sun.reflect.GeneratedConstructorAccessor20.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2103)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:718)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:46)
	at sun.reflect.GeneratedConstructorAccessor17.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:302)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:282)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1375)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1431)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:1844)
Caused by: java.net.SocketException: Network is unreachable: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:244)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:253)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:280)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2026)
	... 11 more
ERROR - 2020-02-17 14:46:19.417; com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread; create connection error
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

Last packet sent to the server was 0 ms ago.
	at sun.reflect.GeneratedConstructorAccessor20.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2103)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:718)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:46)
	at sun.reflect.GeneratedConstructorAccessor17.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:302)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:282)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1375)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1431)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:1844)
Caused by: java.net.SocketException: Network is unreachable: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:244)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:253)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:280)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2026)
	... 11 more
ERROR - 2020-02-17 14:46:19.433; com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread; create connection error
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

Last packet sent to the server was 0 ms ago.
	at sun.reflect.GeneratedConstructorAccessor20.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2103)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:718)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:46)
	at sun.reflect.GeneratedConstructorAccessor17.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:302)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:282)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1375)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1431)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:1844)
Caused by: java.net.SocketException: Network is unreachable: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:244)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:253)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:280)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2026)
	... 11 more
ERROR - 2020-02-17 14:46:19.438; com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread; create connection error
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

Last packet sent to the server was 0 ms ago.
	at sun.reflect.GeneratedConstructorAccessor20.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2103)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:718)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:46)
	at sun.reflect.GeneratedConstructorAccessor17.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:302)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:282)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1375)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1431)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:1844)
Caused by: java.net.SocketException: Network is unreachable: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:244)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:253)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:280)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2026)
	... 11 more
ERROR - 2020-02-17 14:46:19.443; com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread; create connection error
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

Last packet sent to the server was 0 ms ago.
	at sun.reflect.GeneratedConstructorAccessor20.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2103)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:718)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:46)
	at sun.reflect.GeneratedConstructorAccessor17.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:302)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:282)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1375)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1431)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:1844)
Caused by: java.net.SocketException: Network is unreachable: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:244)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:253)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:280)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2026)
	... 11 more
ERROR - 2020-02-17 14:46:19.444; com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread; create connection error
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

Last packet sent to the server was 0 ms ago.
	at sun.reflect.GeneratedConstructorAccessor20.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2103)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:718)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:46)
	at sun.reflect.GeneratedConstructorAccessor17.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:302)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:282)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1375)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1431)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:1844)
Caused by: java.net.SocketException: Network is unreachable: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:244)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:253)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:280)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2026)
	... 11 more
ERROR - 2020-02-17 14:46:19.447; com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread; create connection error
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

Last packet sent to the server was 0 ms ago.
	at sun.reflect.GeneratedConstructorAccessor20.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2103)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:718)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:46)
	at sun.reflect.GeneratedConstructorAccessor17.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:302)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:282)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1375)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1431)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:1844)
Caused by: java.net.SocketException: Network is unreachable: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:244)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:253)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:280)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2026)
	... 11 more
ERROR - 2020-02-17 14:46:19.449; com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread; create connection error
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

Last packet sent to the server was 0 ms ago.
	at sun.reflect.GeneratedConstructorAccessor20.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2103)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:718)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:46)
	at sun.reflect.GeneratedConstructorAccessor17.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:302)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:282)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1375)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1431)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:1844)
Caused by: java.net.SocketException: Network is unreachable: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:244)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:253)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:280)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2026)
	... 11 more
ERROR - 2020-02-17 14:46:19.451; com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread; create connection error
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

Last packet sent to the server was 0 ms ago.
	at sun.reflect.GeneratedConstructorAccessor20.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2103)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:718)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:46)
	at sun.reflect.GeneratedConstructorAccessor17.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:302)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:282)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1375)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1431)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:1844)
Caused by: java.net.SocketException: Network is unreachable: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:244)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:253)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:280)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2026)
	... 11 more
ERROR - 2020-02-17 14:46:19.454; com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread; create connection error
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

Last packet sent to the server was 1 ms ago.
	at sun.reflect.GeneratedConstructorAccessor20.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2103)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:718)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:46)
	at sun.reflect.GeneratedConstructorAccessor17.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:302)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:282)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1375)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1431)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:1844)
Caused by: java.net.SocketException: Network is unreachable: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:244)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:253)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:280)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2026)
	... 11 more
ERROR - 2020-02-17 14:46:19.458; com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread; create connection error
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

Last packet sent to the server was 0 ms ago.
	at sun.reflect.GeneratedConstructorAccessor20.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2103)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:718)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:46)
	at sun.reflect.GeneratedConstructorAccessor17.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:302)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:282)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1375)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1431)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:1844)
Caused by: java.net.SocketException: Network is unreachable: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:244)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:253)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:280)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2026)
	... 11 more
ERROR - 2020-02-17 14:46:19.460; com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread; create connection error
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

Last packet sent to the server was 0 ms ago.
	at sun.reflect.GeneratedConstructorAccessor20.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2103)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:718)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:46)
	at sun.reflect.GeneratedConstructorAccessor17.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:302)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:282)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1375)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1431)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:1844)
Caused by: java.net.SocketException: Network is unreachable: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:244)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:253)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:280)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2026)
	... 11 more
ERROR - 2020-02-17 14:46:49.462; com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread; create connection error
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

Last packet sent to the server was 0 ms ago.
	at sun.reflect.GeneratedConstructorAccessor20.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2103)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:718)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:46)
	at sun.reflect.GeneratedConstructorAccessor17.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:302)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:282)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1375)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1431)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:1844)
Caused by: java.net.SocketException: Network is unreachable: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:244)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:253)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:280)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2026)
	... 11 more
ERROR - 2020-02-17 14:47:19.467; com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread; create connection error
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

Last packet sent to the server was 0 ms ago.
	at sun.reflect.GeneratedConstructorAccessor20.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2103)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:718)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:46)
	at sun.reflect.GeneratedConstructorAccessor17.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:302)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:282)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1375)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1431)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:1844)
Caused by: java.net.SocketException: Network is unreachable: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:244)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:253)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:280)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2026)
	... 11 more
INFO  - 2020-02-17 14:47:50.136; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 14:47:50.143; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 14:47:50.147; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 14:47:51.496; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-17 14:59:19.797; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-17 14:59:19.852; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@167fdd33, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@1e965684, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@53f65459, org.springframework.test.context.transaction.TransactionalTestExecutionListener@3b088d51, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1786dec2]
INFO  - 2020-02-17 14:59:20.441; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 14:59:21.098; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 14:59:23.115; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 14:59:24.095; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 14:59:24.095; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 14:59:24.106; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 14:59:24.598; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 14:59:24.604; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 14:59:24.611; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 14:59:24.613; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 14:59:24.615; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 14:59:25.385; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 353
INFO  - 2020-02-17 14:59:25.387; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-17 14:59:25.387; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-17 14:59:28.235; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 14:59:30.777; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-17 14:59:31.287; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 14:59:31.304; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 14:59:31.313; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 14:59:32.756; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-17 15:01:08.054; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-17 15:01:08.080; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@167fdd33, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@1e965684, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@53f65459, org.springframework.test.context.transaction.TransactionalTestExecutionListener@3b088d51, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1786dec2]
INFO  - 2020-02-17 15:01:08.562; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 15:01:09.127; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 15:01:10.889; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 15:01:11.769; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 15:01:11.769; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 15:01:11.776; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 15:01:12.091; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 15:01:12.094; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 15:01:12.102; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 15:01:12.103; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 15:01:12.104; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 15:01:13.510; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 355
INFO  - 2020-02-17 15:01:13.513; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 15:01:13.514; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 15:01:15.793; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 15:01:18.012; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 15:01:18.028; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 15:01:18.029; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 15:02:20.260; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-17 15:02:20.301; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@167fdd33, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@1e965684, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@53f65459, org.springframework.test.context.transaction.TransactionalTestExecutionListener@3b088d51, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1786dec2]
INFO  - 2020-02-17 15:02:20.800; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 15:02:21.465; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 15:02:23.297; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 15:02:24.209; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 15:02:24.209; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 15:02:24.219; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 15:02:24.602; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 15:02:24.611; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 15:02:24.622; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 15:02:24.623; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 15:02:24.623; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 15:02:25.570; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 357
INFO  - 2020-02-17 15:02:25.573; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 15:02:25.574; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 15:02:28.065; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 15:02:30.416; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 15:02:30.432; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 15:02:30.435; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 15:05:55.968; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-17 15:05:55.999; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@167fdd33, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@1e965684, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@53f65459, org.springframework.test.context.transaction.TransactionalTestExecutionListener@3b088d51, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1786dec2]
INFO  - 2020-02-17 15:05:56.500; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 15:05:57.075; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 15:05:59.001; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 15:05:59.905; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 15:05:59.905; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 15:05:59.921; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 15:06:00.456; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 15:06:00.461; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 15:06:00.467; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 15:06:00.467; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 15:06:00.468; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 15:06:01.690; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 359
INFO  - 2020-02-17 15:06:01.695; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 15:06:01.696; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 15:06:04.205; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 15:06:06.811; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 15:06:06.822; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 15:06:06.823; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 15:08:05.555; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-17 15:08:05.592; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@167fdd33, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@1e965684, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@53f65459, org.springframework.test.context.transaction.TransactionalTestExecutionListener@3b088d51, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1786dec2]
INFO  - 2020-02-17 15:08:06.072; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 15:08:06.782; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 15:08:08.595; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 15:08:09.466; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 15:08:09.466; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 15:08:09.474; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 15:08:09.768; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 15:08:09.770; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 15:08:09.778; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 15:08:09.778; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 15:08:09.778; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 15:08:10.758; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 361
INFO  - 2020-02-17 15:08:10.764; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 15:08:10.764; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 15:08:13.405; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 15:08:15.859; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 15:08:15.884; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 15:08:15.889; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 15:08:33.932; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-17 15:08:33.953; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@6895a785, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@184f6be2, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@56aac163, org.springframework.test.context.support.DirtiesContextTestExecutionListener@1f7030a6, org.springframework.test.context.transaction.TransactionalTestExecutionListener@5a1c0542, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@396f6598]
INFO  - 2020-02-17 15:08:34.437; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 15:08:35.019; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 15:08:36.768; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 15:08:37.633; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 15:08:37.633; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 15:08:37.642; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 15:08:37.948; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 15:08:37.953; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 15:08:37.958; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 15:08:37.959; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 15:08:37.959; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 15:08:40.806; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 363
INFO  - 2020-02-17 15:08:40.809; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 15:08:40.809; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 15:08:41.403; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 15:08:43.773; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 15:08:43.791; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 15:08:43.793; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 15:13:01.322; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-17 15:13:01.364; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@167fdd33, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@1e965684, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@53f65459, org.springframework.test.context.transaction.TransactionalTestExecutionListener@3b088d51, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1786dec2]
INFO  - 2020-02-17 15:13:01.854; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 15:13:02.456; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 15:13:04.250; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 15:13:07.968; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 15:13:07.968; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 15:13:07.977; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 15:13:08.266; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 15:13:08.269; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 15:13:08.274; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 15:13:08.275; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 15:13:08.276; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 15:13:10.980; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 365
INFO  - 2020-02-17 15:13:10.982; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-17 15:13:10.984; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-17 15:13:12.858; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 15:13:23.270; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-17 15:13:24.004; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 15:13:24.020; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 15:13:24.022; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 15:13:25.774; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-17 15:15:00.084; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-17 15:15:00.142; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@167fdd33, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@1e965684, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@53f65459, org.springframework.test.context.transaction.TransactionalTestExecutionListener@3b088d51, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1786dec2]
INFO  - 2020-02-17 15:15:00.659; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 15:15:01.270; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 15:15:03.619; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 15:15:04.494; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 15:15:04.494; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 15:15:04.501; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 15:15:04.906; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 15:15:04.909; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 15:15:04.915; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 15:15:04.915; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 15:15:04.916; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 15:15:05.107; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 367
INFO  - 2020-02-17 15:15:05.110; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 15:15:05.111; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 15:15:09.081; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 15:15:11.529; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-17 15:15:12.145; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 15:15:12.163; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 15:15:12.163; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 15:15:13.702; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-17 15:18:15.281; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-17 15:18:15.317; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@167fdd33, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@1e965684, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@53f65459, org.springframework.test.context.transaction.TransactionalTestExecutionListener@3b088d51, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1786dec2]
INFO  - 2020-02-17 15:18:15.760; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 15:18:16.421; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 15:18:18.598; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 15:18:19.540; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 15:18:19.541; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 15:18:19.548; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 15:18:19.841; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 15:18:19.843; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 15:18:19.846; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 15:18:19.846; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 15:18:19.846; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 15:18:20.214; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 369
INFO  - 2020-02-17 15:18:20.219; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 15:18:20.219; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 15:18:23.500; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 15:18:26.019; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 15:18:26.028; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 15:18:26.034; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 15:19:53.357; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-17 15:19:53.434; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@167fdd33, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@1e965684, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@53f65459, org.springframework.test.context.transaction.TransactionalTestExecutionListener@3b088d51, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1786dec2]
INFO  - 2020-02-17 15:19:54.035; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 15:19:54.859; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 15:19:57.169; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 15:19:58.016; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 15:19:58.016; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 15:19:58.029; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 15:19:58.347; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 15:19:58.352; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 15:19:58.360; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 15:19:58.360; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 15:19:58.361; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 15:19:59.281; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 371
INFO  - 2020-02-17 15:19:59.284; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 15:19:59.284; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 15:20:02.646; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 15:20:05.324; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 15:20:05.336; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 15:20:05.350; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 15:21:47.361; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-17 15:21:47.405; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@167fdd33, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@1e965684, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@53f65459, org.springframework.test.context.transaction.TransactionalTestExecutionListener@3b088d51, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1786dec2]
INFO  - 2020-02-17 15:21:47.851; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 15:21:48.513; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 15:21:50.411; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 15:21:51.328; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 15:21:51.328; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 15:21:51.338; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 15:21:51.663; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 15:21:51.665; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 15:21:51.671; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 15:21:51.672; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 15:21:51.672; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 15:21:53.362; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 373
INFO  - 2020-02-17 15:21:53.365; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 15:21:53.366; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 15:21:55.300; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 15:21:57.682; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 15:21:57.692; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 15:21:57.694; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 15:22:39.782; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-17 15:22:39.824; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@167fdd33, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@1e965684, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@53f65459, org.springframework.test.context.transaction.TransactionalTestExecutionListener@3b088d51, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1786dec2]
INFO  - 2020-02-17 15:22:40.400; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 15:22:41.082; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 15:22:43.087; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 15:22:44.089; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 15:22:44.090; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 15:22:44.100; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 15:22:44.577; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 15:22:44.579; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 15:22:44.585; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 15:22:44.585; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 15:22:44.586; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 15:22:47.394; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 375
INFO  - 2020-02-17 15:22:47.399; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 15:22:47.400; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 15:22:48.222; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 15:22:50.792; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 15:22:50.820; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 15:22:50.824; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 15:23:29.683; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-17 15:23:29.719; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@167fdd33, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@1e965684, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@53f65459, org.springframework.test.context.transaction.TransactionalTestExecutionListener@3b088d51, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1786dec2]
INFO  - 2020-02-17 15:23:30.160; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 15:23:30.908; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 15:23:32.657; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 15:23:33.547; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 15:23:33.548; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 15:23:33.558; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 15:23:33.923; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 15:23:33.925; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 15:23:33.930; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 15:23:33.932; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 15:23:33.933; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 15:23:35.447; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 377
INFO  - 2020-02-17 15:23:35.449; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 15:23:35.450; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 15:23:37.618; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 15:23:40.151; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 15:23:40.168; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 15:23:40.170; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 15:24:12.997; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-17 15:24:13.037; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@167fdd33, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@1e965684, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@53f65459, org.springframework.test.context.transaction.TransactionalTestExecutionListener@3b088d51, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1786dec2]
INFO  - 2020-02-17 15:24:13.524; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 15:24:14.208; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 15:24:16.040; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 15:24:16.913; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 15:24:16.913; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 15:24:16.922; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 15:24:17.237; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 15:24:17.240; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 15:24:17.246; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 15:24:17.246; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 15:24:17.246; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 15:24:17.481; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 379
INFO  - 2020-02-17 15:24:17.484; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 15:24:17.484; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 15:24:20.861; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 15:24:23.599; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 15:24:23.612; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 15:24:23.613; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 15:25:43.941; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-17 15:25:43.980; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@167fdd33, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@1e965684, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@53f65459, org.springframework.test.context.transaction.TransactionalTestExecutionListener@3b088d51, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1786dec2]
INFO  - 2020-02-17 15:25:44.496; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 15:25:45.125; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 15:25:47.205; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 15:25:48.155; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 15:25:48.155; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 15:25:48.163; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 15:25:48.596; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 15:25:48.601; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 15:25:48.610; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 15:25:48.611; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 15:25:48.611; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 15:25:50.535; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 381
INFO  - 2020-02-17 15:25:50.539; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 15:25:50.539; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 15:25:52.483; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 15:25:55.348; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 15:25:55.373; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 15:25:55.401; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 15:48:46.262; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-17 15:48:46.306; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@167fdd33, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@1e965684, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@53f65459, org.springframework.test.context.transaction.TransactionalTestExecutionListener@3b088d51, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1786dec2]
INFO  - 2020-02-17 15:48:46.839; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 15:48:47.559; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 15:48:49.607; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 15:48:50.558; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 15:48:50.558; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 15:48:50.568; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 15:48:50.898; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 15:48:50.900; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 15:48:50.903; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 15:48:50.904; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 15:48:50.904; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 15:48:51.063; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 383
INFO  - 2020-02-17 15:48:51.066; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 15:48:51.067; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 15:48:54.598; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 15:48:57.048; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-17 15:49:02.895; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 15:49:02.909; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 15:49:02.912; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 15:49:04.258; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-17 15:51:50.329; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-17 15:51:50.368; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@167fdd33, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@1e965684, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@4d95d2a2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@53f65459, org.springframework.test.context.transaction.TransactionalTestExecutionListener@3b088d51, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1786dec2]
INFO  - 2020-02-17 15:51:50.805; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 15:51:51.450; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 15:51:53.405; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 15:51:54.440; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 15:51:54.440; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 15:51:54.448; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 15:51:54.738; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 15:51:54.740; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 15:51:54.745; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 15:51:54.746; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 15:51:54.746; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 15:51:57.194; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 385
INFO  - 2020-02-17 15:51:57.199; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 15:51:57.199; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 15:51:59.023; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 15:52:01.710; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 15:52:01.725; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 15:52:01.728; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 16:01:30.333; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-17 16:01:30.375; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@17579e0f, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@4d41cee, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3712b94, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2833cc44, org.springframework.test.context.transaction.TransactionalTestExecutionListener@33f88ab, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@27a8c74e]
INFO  - 2020-02-17 16:01:30.819; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 16:01:31.457; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 16:01:33.277; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 16:01:34.156; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 16:01:34.156; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 16:01:34.163; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 16:01:34.506; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 16:01:34.510; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 16:01:34.516; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 16:01:34.517; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 16:01:34.520; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 16:01:36.423; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 387
INFO  - 2020-02-17 16:01:36.426; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 16:01:36.426; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 16:01:38.306; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-17 16:01:41.134; org.apache.kafka.common.config.AbstractConfig; ProducerConfig values: 
	acks = 1
	batch.size = 1638
	bootstrap.servers = [192.168.198.128:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  - 2020-02-17 16:01:41.193; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 16:01:41.193; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 16:01:41.231; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 16:01:41.744; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-17 16:01:42.525; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 16:01:42.560; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 16:01:42.591; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 16:01:43.892; org.apache.kafka.clients.producer.KafkaProducer; [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
INFO  - 2020-02-17 16:01:43.904; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-17 16:17:59.780; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-17 16:17:59.812; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@17579e0f, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@4d41cee, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3712b94, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2833cc44, org.springframework.test.context.transaction.TransactionalTestExecutionListener@33f88ab, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@27a8c74e]
INFO  - 2020-02-17 16:18:00.528; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 16:18:01.566; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 16:18:04.885; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 16:18:06.039; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 16:18:06.040; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 16:18:06.062; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 16:18:07.354; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 16:18:07.373; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 16:18:07.394; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 16:18:07.395; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 16:18:07.395; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 16:18:10.489; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 395
INFO  - 2020-02-17 16:18:10.499; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 16:18:10.499; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 16:18:18.179; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
ERROR - 2020-02-17 16:18:22.916; org.springframework.data.elasticsearch.repository.support.AbstractElasticsearchRepository; failed to load elasticsearch nodes : org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes are available: [{#transport#-1}{hxemhkC8SNSkmkrzJS0nmQ}{192.168.198.128}{192.168.198.128:9300}]
INFO  - 2020-02-17 16:18:23.847; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-17 16:18:29.747; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 16:18:29.764; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 16:18:29.767; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 16:18:32.579; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-17 16:19:40.872; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-17 16:19:40.927; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@17579e0f, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@4d41cee, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3712b94, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2833cc44, org.springframework.test.context.transaction.TransactionalTestExecutionListener@33f88ab, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@27a8c74e]
INFO  - 2020-02-17 16:19:41.550; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 16:19:42.285; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 16:19:44.339; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 16:19:45.269; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 16:19:45.269; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 16:19:45.286; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 16:19:45.674; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 16:19:45.677; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 16:19:45.683; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 16:19:45.683; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 16:19:45.684; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 16:19:46.543; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 397
INFO  - 2020-02-17 16:19:46.549; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 16:19:46.550; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 16:19:49.764; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
ERROR - 2020-02-17 16:19:53.758; org.springframework.data.elasticsearch.repository.support.AbstractElasticsearchRepository; failed to load elasticsearch nodes : org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes are available: [{#transport#-1}{Nz7YNQmtTyCqXpogtd5U_Q}{192.168.198.128}{192.168.198.128:9300}]
INFO  - 2020-02-17 16:19:54.158; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-17 16:19:55.904; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 16:19:55.917; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 16:19:55.918; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 16:19:57.008; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-17 16:20:13.834; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-17 16:20:13.882; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@17579e0f, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@4d41cee, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3712b94, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2833cc44, org.springframework.test.context.transaction.TransactionalTestExecutionListener@33f88ab, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@27a8c74e]
INFO  - 2020-02-17 16:20:14.600; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 16:20:15.262; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 16:20:17.621; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 16:20:18.527; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 16:20:18.527; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 16:20:18.536; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 16:20:19.017; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 16:20:19.019; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 16:20:19.025; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 16:20:19.025; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 16:20:19.025; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 16:20:19.624; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 399
INFO  - 2020-02-17 16:20:19.638; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 16:20:19.641; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 16:20:23.305; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
ERROR - 2020-02-17 16:20:27.129; org.springframework.data.elasticsearch.repository.support.AbstractElasticsearchRepository; failed to load elasticsearch nodes : org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes are available: [{#transport#-1}{Sxmn5saHQfqR7zxcURC9VA}{192.168.198.128}{192.168.198.128:9300}]
INFO  - 2020-02-17 16:20:27.778; org.apache.kafka.common.config.AbstractConfig; ProducerConfig values: 
	acks = 1
	batch.size = 1638
	bootstrap.servers = [192.168.198.128:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  - 2020-02-17 16:20:27.830; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 16:20:27.830; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 16:20:27.854; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 16:20:27.966; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-17 16:20:27.982; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-17 16:20:27.988; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-17 16:20:30.535; org.apache.kafka.clients.producer.KafkaProducer; [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
INFO  - 2020-02-17 16:24:12.606; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-17 16:24:13.350; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 16:24:14.599; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 16:24:16.830; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 16:24:17.203; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 16:24:17.203; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 16:24:17.216; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 16:24:17.760; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 16:24:17.764; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 16:24:17.773; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 16:24:17.773; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 16:24:17.774; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 16:24:17.821; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 402
INFO  - 2020-02-17 16:24:17.831; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 16:24:17.832; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 16:24:21.677; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
ERROR - 2020-02-17 16:24:25.730; org.springframework.data.elasticsearch.repository.support.AbstractElasticsearchRepository; failed to load elasticsearch nodes : org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes are available: [{#transport#-1}{muJRy8J6TZ2mYGlEP7T9qg}{192.168.198.128}{192.168.198.128:9300}]
INFO  - 2020-02-17 16:24:26.051; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 13438 ms
INFO  - 2020-02-17 16:24:26.464; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-17 16:24:27.421; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-17 16:24:28.196; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1731 ms
INFO  - 2020-02-17 16:24:28.947; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-17 19:27:12.524; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-17 19:27:13.017; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-17 19:27:13.685; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-17 19:27:15.582; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-17 19:27:15.679; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-17 19:27:15.679; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-17 19:27:15.685; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 19:27:19.272; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
WARN  - 2020-02-17 19:27:36.914; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
ERROR - 2020-02-17 19:27:41.993; org.springframework.data.elasticsearch.repository.support.AbstractElasticsearchRepository; failed to load elasticsearch nodes : org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes are available: [{#transport#-1}{WM_bby9MRK-S8sMpxq6tvg}{192.168.198.128}{192.168.198.128:9300}]
INFO  - 2020-02-17 19:27:42.176; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-17 19:27:42.369; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 29840 ms
INFO  - 2020-02-17 19:27:42.702; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-17 19:27:43.303; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-17 19:27:43.727; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1025 ms
WARN  - 2020-02-17 19:27:57.971; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-17 19:28:19.129; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2020-02-17 19:28:34.011; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
WARN  - 2020-02-17 19:28:40.338; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-17 19:29:01.748; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-17 19:29:23.717; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-17 19:29:45.938; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-17 19:30:08.114; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-17 19:30:30.028; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-17 19:30:52.210; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-17 19:31:14.382; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-17 19:31:36.552; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2020-02-17 19:31:37.557; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-17 19:31:37.564; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-17 19:31:37.570; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 19:31:37.571; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 19:31:37.571; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 19:31:38.930; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 404
INFO  - 2020-02-17 19:31:38.937; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-17 19:31:38.937; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-17 19:37:12.006; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Attempt to heartbeat failed since group is rebalancing
INFO  - 2020-02-17 19:37:12.006; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 19:37:12.006; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 19:37:12.007; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 19:37:12.327; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 405
INFO  - 2020-02-17 19:37:12.328; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 19:37:12.329; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 19:37:24.331; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Attempt to heartbeat failed since group is rebalancing
INFO  - 2020-02-17 19:37:24.332; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions [article-0]
INFO  - 2020-02-17 19:37:24.332; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: [article-0]
INFO  - 2020-02-17 19:37:24.332; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 19:37:24.381; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 406
INFO  - 2020-02-17 19:37:24.382; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-17 19:37:24.382; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-17 19:39:21.404; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Attempt to heartbeat failed since group is rebalancing
INFO  - 2020-02-17 19:39:21.413; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-17 19:39:21.414; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-17 19:39:21.415; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 19:39:21.420; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 407
INFO  - 2020-02-17 19:39:21.421; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-17 19:39:21.421; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-17 19:39:49.154; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Attempt to heartbeat failed since group is rebalancing
INFO  - 2020-02-17 19:39:49.157; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions [article-0]
INFO  - 2020-02-17 19:39:49.157; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: [article-0]
INFO  - 2020-02-17 19:39:49.157; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-17 19:39:49.162; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 408
INFO  - 2020-02-17 19:39:49.163; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-17 19:39:49.163; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-17 20:50:14.002; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
WARN  - 2020-02-17 20:50:53.965; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 20:51:15.076; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 20:51:36.346; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 20:51:57.758; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 20:52:19.626; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 20:52:41.847; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 20:53:03.866; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 20:53:25.885; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 20:53:48.008; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 20:54:09.991; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 20:54:31.961; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 20:54:53.877; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 20:55:15.799; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 20:55:38.019; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 20:56:00.088; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 20:56:22.309; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 20:56:44.480; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 20:57:06.552; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 20:57:28.775; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 20:57:50.793; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 20:58:12.860; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 20:58:34.986; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 20:58:57.006; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 20:59:18.922; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 20:59:40.839; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:00:02.958; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:00:24.827; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:00:46.997; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:01:08.863; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:01:30.776; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:01:52.794; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:02:14.705; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:02:36.568; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:02:58.429; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:03:20.291; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:03:42.252; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:04:04.315; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:04:26.479; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:04:48.644; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:05:10.806; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:05:32.874; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:05:54.933; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:06:17.148; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:06:39.008; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:07:00.972; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:07:23.085; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:07:45.250; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:08:07.417; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:08:29.329; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:08:51.142; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:09:13.356; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:09:35.471; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:09:57.685; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:10:19.749; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:10:41.964; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:11:03.925; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:11:26.041; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:11:48.203; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:12:10.218; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:12:32.029; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:12:53.894; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:13:15.859; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:13:37.973; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:14:00.088; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:14:22.004; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:14:43.916; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:15:05.978; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:15:28.092; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:15:50.256; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:16:12.371; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:16:34.335; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:16:56.198; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:17:18.264; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:17:40.328; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:18:02.293; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:18:24.207; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:18:46.173; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:19:08.042; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:19:30.166; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:19:52.388; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:20:14.360; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:20:36.431; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:20:58.604; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:21:20.775; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:21:42.844; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:22:05.016; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:22:26.934; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:22:49.053; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:23:11.031; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:23:32.957; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:23:55.028; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:24:16.945; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:24:38.811; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:25:00.883; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:25:22.953; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:25:45.184; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:26:07.407; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:26:29.375; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:26:51.444; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:27:13.413; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:27:35.285; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:27:57.153; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:28:19.125; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:28:41.144; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:29:03.062; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:29:25.180; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:29:47.251; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:30:09.322; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:30:31.397; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:30:53.318; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:31:15.537; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:31:37.554; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:31:59.575; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:32:21.605; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:32:43.474; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:33:05.402; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:33:27.374; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:33:49.300; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:34:11.317; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:34:33.287; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:34:55.255; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:35:17.231; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:35:39.406; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:36:01.272; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:36:23.292; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:36:45.309; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:37:07.435; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:37:29.452; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:37:51.377; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:38:13.194; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:38:35.420; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:38:57.438; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:39:19.508; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:39:41.681; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:40:03.650; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:40:25.820; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:40:47.942; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:41:09.810; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:41:31.980; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:41:53.850; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:42:15.921; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:42:37.989; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:43:00.165; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:43:22.083; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:43:44.202; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:44:06.019; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:44:27.885; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:44:49.855; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:45:11.973; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:45:34.146; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:45:56.266; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:46:18.183; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:46:40.198; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:47:02.325; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:47:24.345; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:47:46.365; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:48:08.587; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:48:30.654; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:48:52.726; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:49:14.642; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:49:36.814; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:49:58.936; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:50:21.006; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-17 21:50:43.131; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
INFO  - 2020-02-18 08:51:40.561; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-18 08:51:41.154; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 08:51:41.755; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 08:51:44.258; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 08:51:44.447; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 08:51:44.449; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 08:51:44.454; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 08:51:48.644; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
WARN  - 2020-02-18 08:52:05.920; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
ERROR - 2020-02-18 08:52:11.403; org.springframework.data.elasticsearch.repository.support.AbstractElasticsearchRepository; failed to load elasticsearch nodes : org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes are available: [{#transport#-1}{-TUunvU7QzatOySC_JmWSQ}{192.168.198.128}{192.168.198.128:9300}]
INFO  - 2020-02-18 08:52:11.608; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 08:52:11.835; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 31267 ms
INFO  - 2020-02-18 08:52:12.193; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-18 08:52:13.140; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-18 08:52:13.637; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1444 ms
WARN  - 2020-02-18 08:52:26.980; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 08:52:48.086; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2020-02-18 08:52:49.498; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
WARN  - 2020-02-18 08:53:09.291; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 08:53:30.698; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 08:53:52.511; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 08:54:14.479; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 08:54:36.495; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 08:54:58.463; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2020-02-18 08:54:59.658; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-18 08:54:59.676; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-18 08:54:59.683; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-18 08:54:59.685; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-18 08:54:59.685; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-18 08:55:00.294; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 410
INFO  - 2020-02-18 08:55:00.298; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-18 08:55:00.299; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-18 09:32:20.237; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-18 09:32:20.720; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 09:32:21.308; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
WARN  - 2020-02-18 09:32:23.218; org.springframework.context.support.AbstractApplicationContext; Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'messageListenerContainer' defined in class path resource [consumer.xml]: Cannot resolve reference to bean 'containerProperties' while setting constructor argument; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'containerProperties' defined in class path resource [consumer.xml]: Cannot resolve reference to bean 'msgListener' while setting bean property 'messageListener'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'msgListener': Unsatisfied dependency expressed through field 'service'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleServiceImpl': Unsatisfied dependency expressed through field 'dao'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleMapper' defined in file [C:\Users\Legna\workspace\yangjinjing-cms\target\classes\com\yangjinjing\cms\dao\ArticleMapper.class]: Unsatisfied dependency expressed through bean property 'sqlSessionFactory'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [spring-beans.xml]: Invocation of init method failed; nested exception is org.springframework.core.NestedIOException: Failed to parse config resource: class path resource [mybatis.xml]; nested exception is org.apache.ibatis.builder.BuilderException: Error parsing SQL Mapper Configuration. Cause: org.apache.ibatis.type.TypeException: The alias 'Collection' is already mapped to the value 'java.util.Collection'.
ERROR - 2020-02-18 09:32:23.226; org.springframework.web.context.ContextLoader; Context initialization failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'messageListenerContainer' defined in class path resource [consumer.xml]: Cannot resolve reference to bean 'containerProperties' while setting constructor argument; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'containerProperties' defined in class path resource [consumer.xml]: Cannot resolve reference to bean 'msgListener' while setting bean property 'messageListener'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'msgListener': Unsatisfied dependency expressed through field 'service'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleServiceImpl': Unsatisfied dependency expressed through field 'dao'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleMapper' defined in file [C:\Users\Legna\workspace\yangjinjing-cms\target\classes\com\yangjinjing\cms\dao\ArticleMapper.class]: Unsatisfied dependency expressed through bean property 'sqlSessionFactory'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [spring-beans.xml]: Invocation of init method failed; nested exception is org.springframework.core.NestedIOException: Failed to parse config resource: class path resource [mybatis.xml]; nested exception is org.apache.ibatis.builder.BuilderException: Error parsing SQL Mapper Configuration. Cause: org.apache.ibatis.type.TypeException: The alias 'Collection' is already mapped to the value 'java.util.Collection'.
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:378)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:110)
	at org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:676)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:188)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1325)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1171)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549)
	at org.springframework.web.context.ContextLoader.configureAndRefreshWebApplicationContext(ContextLoader.java:400)
	at org.springframework.web.context.ContextLoader.initWebApplicationContext(ContextLoader.java:291)
	at org.springframework.web.context.ContextLoaderListener.contextInitialized(ContextLoaderListener.java:103)
	at org.eclipse.jetty.server.handler.ContextHandler.callContextInitialized(ContextHandler.java:890)
	at org.eclipse.jetty.servlet.ServletContextHandler.callContextInitialized(ServletContextHandler.java:558)
	at org.eclipse.jetty.server.handler.ContextHandler.startContext(ContextHandler.java:853)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:370)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.startWebapp(JettyWebAppContext.java:360)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:785)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:287)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.doStart(JettyWebAppContext.java:428)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:138)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)
	at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:113)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.doStart(ContextHandlerCollection.java:167)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:138)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)
	at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:113)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:138)
	at org.eclipse.jetty.server.Server.start(Server.java:419)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:108)
	at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:113)
	at org.eclipse.jetty.server.Server.doStart(Server.java:386)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.maven.plugin.AbstractJettyMojo.startJetty(AbstractJettyMojo.java:467)
	at org.eclipse.jetty.maven.plugin.AbstractJettyMojo.execute(AbstractJettyMojo.java:329)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo.execute(JettyRunMojo.java:179)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:210)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:156)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:148)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:117)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:305)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:957)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:289)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:193)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'containerProperties' defined in class path resource [consumer.xml]: Cannot resolve reference to bean 'msgListener' while setting bean property 'messageListener'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'msgListener': Unsatisfied dependency expressed through field 'service'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleServiceImpl': Unsatisfied dependency expressed through field 'dao'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleMapper' defined in file [C:\Users\Legna\workspace\yangjinjing-cms\target\classes\com\yangjinjing\cms\dao\ArticleMapper.class]: Unsatisfied dependency expressed through bean property 'sqlSessionFactory'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [spring-beans.xml]: Invocation of init method failed; nested exception is org.springframework.core.NestedIOException: Failed to parse config resource: class path resource [mybatis.xml]; nested exception is org.apache.ibatis.builder.BuilderException: Error parsing SQL Mapper Configuration. Cause: org.apache.ibatis.type.TypeException: The alias 'Collection' is already mapped to the value 'java.util.Collection'.
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:378)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:110)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1665)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1417)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:367)
	... 69 more
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'msgListener': Unsatisfied dependency expressed through field 'service'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleServiceImpl': Unsatisfied dependency expressed through field 'dao'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleMapper' defined in file [C:\Users\Legna\workspace\yangjinjing-cms\target\classes\com\yangjinjing\cms\dao\ArticleMapper.class]: Unsatisfied dependency expressed through bean property 'sqlSessionFactory'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [spring-beans.xml]: Invocation of init method failed; nested exception is org.springframework.core.NestedIOException: Failed to parse config resource: class path resource [mybatis.xml]; nested exception is org.apache.ibatis.builder.BuilderException: Error parsing SQL Mapper Configuration. Cause: org.apache.ibatis.type.TypeException: The alias 'Collection' is already mapped to the value 'java.util.Collection'.
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:596)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:374)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1395)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:367)
	... 79 more
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleServiceImpl': Unsatisfied dependency expressed through field 'dao'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleMapper' defined in file [C:\Users\Legna\workspace\yangjinjing-cms\target\classes\com\yangjinjing\cms\dao\ArticleMapper.class]: Unsatisfied dependency expressed through bean property 'sqlSessionFactory'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [spring-beans.xml]: Invocation of init method failed; nested exception is org.springframework.core.NestedIOException: Failed to parse config resource: class path resource [mybatis.xml]; nested exception is org.apache.ibatis.builder.BuilderException: Error parsing SQL Mapper Configuration. Cause: org.apache.ibatis.type.TypeException: The alias 'Collection' is already mapped to the value 'java.util.Collection'.
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:596)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:374)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1395)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:277)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1247)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1167)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:593)
	... 89 more
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleMapper' defined in file [C:\Users\Legna\workspace\yangjinjing-cms\target\classes\com\yangjinjing\cms\dao\ArticleMapper.class]: Unsatisfied dependency expressed through bean property 'sqlSessionFactory'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [spring-beans.xml]: Invocation of init method failed; nested exception is org.springframework.core.NestedIOException: Failed to parse config resource: class path resource [mybatis.xml]; nested exception is org.apache.ibatis.builder.BuilderException: Error parsing SQL Mapper Configuration. Cause: org.apache.ibatis.type.TypeException: The alias 'Collection' is already mapped to the value 'java.util.Collection'.
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireByType(AbstractAutowireCapableBeanFactory.java:1499)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1379)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:277)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1247)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1167)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:593)
	... 102 more
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [spring-beans.xml]: Invocation of init method failed; nested exception is org.springframework.core.NestedIOException: Failed to parse config resource: class path resource [mybatis.xml]; nested exception is org.apache.ibatis.builder.BuilderException: Error parsing SQL Mapper Configuration. Cause: org.apache.ibatis.type.TypeException: The alias 'Collection' is already mapped to the value 'java.util.Collection'.
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1762)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:593)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:277)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1247)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1167)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireByType(AbstractAutowireCapableBeanFactory.java:1484)
	... 113 more
Caused by: org.springframework.core.NestedIOException: Failed to parse config resource: class path resource [mybatis.xml]; nested exception is org.apache.ibatis.builder.BuilderException: Error parsing SQL Mapper Configuration. Cause: org.apache.ibatis.type.TypeException: The alias 'Collection' is already mapped to the value 'java.util.Collection'.
	at org.mybatis.spring.SqlSessionFactoryBean.buildSqlSessionFactory(SqlSessionFactoryBean.java:499)
	at org.mybatis.spring.SqlSessionFactoryBean.afterPropertiesSet(SqlSessionFactoryBean.java:381)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1821)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1758)
	... 123 more
Caused by: org.apache.ibatis.builder.BuilderException: Error parsing SQL Mapper Configuration. Cause: org.apache.ibatis.type.TypeException: The alias 'Collection' is already mapped to the value 'java.util.Collection'.
	at org.apache.ibatis.builder.xml.XMLConfigBuilder.parseConfiguration(XMLConfigBuilder.java:120)
	at org.apache.ibatis.builder.xml.XMLConfigBuilder.parse(XMLConfigBuilder.java:98)
	at org.mybatis.spring.SqlSessionFactoryBean.buildSqlSessionFactory(SqlSessionFactoryBean.java:493)
	... 126 more
Caused by: org.apache.ibatis.type.TypeException: The alias 'Collection' is already mapped to the value 'java.util.Collection'.
	at org.apache.ibatis.type.TypeAliasRegistry.registerAlias(TypeAliasRegistry.java:157)
	at org.apache.ibatis.type.TypeAliasRegistry.registerAlias(TypeAliasRegistry.java:147)
	at org.apache.ibatis.type.TypeAliasRegistry.registerAliases(TypeAliasRegistry.java:136)
	at org.apache.ibatis.type.TypeAliasRegistry.registerAliases(TypeAliasRegistry.java:125)
	at org.apache.ibatis.builder.xml.XMLConfigBuilder.typeAliasesElement(XMLConfigBuilder.java:158)
	at org.apache.ibatis.builder.xml.XMLConfigBuilder.parseConfiguration(XMLConfigBuilder.java:108)
	... 128 more
INFO  - 2020-02-18 09:34:15.123; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-18 09:34:15.567; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 09:34:16.105; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 09:34:18.053; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 09:34:18.363; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 09:34:18.364; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 09:34:18.371; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 09:34:22.297; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
WARN  - 2020-02-18 09:34:39.674; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
ERROR - 2020-02-18 09:34:45.102; org.springframework.data.elasticsearch.repository.support.AbstractElasticsearchRepository; failed to load elasticsearch nodes : org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes are available: [{#transport#-1}{t0Z3-2c7QmWexu5xP6WpzQ}{192.168.198.128}{192.168.198.128:9300}]
INFO  - 2020-02-18 09:34:45.288; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 09:34:45.318; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 30188 ms
INFO  - 2020-02-18 09:34:45.698; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-18 09:34:46.744; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-18 09:34:47.353; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1654 ms
WARN  - 2020-02-18 09:35:00.793; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2020-02-18 09:35:09.758; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
WARN  - 2020-02-18 09:35:21.951; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 09:35:43.208; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 09:36:04.576; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2020-02-18 09:44:28.757; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-18 09:44:29.179; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 09:44:29.823; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 09:44:32.338; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 09:44:32.448; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 09:44:32.449; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 09:44:32.455; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 09:44:36.493; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
WARN  - 2020-02-18 09:44:53.802; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
ERROR - 2020-02-18 09:44:59.307; org.springframework.data.elasticsearch.repository.support.AbstractElasticsearchRepository; failed to load elasticsearch nodes : org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes are available: [{#transport#-1}{5zwLqdB6T8SaKlo0SQqWKQ}{192.168.198.128}{192.168.198.128:9300}]
INFO  - 2020-02-18 09:44:59.671; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 09:44:59.717; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 30954 ms
INFO  - 2020-02-18 09:44:59.971; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-18 09:45:00.872; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-18 09:45:01.519; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1547 ms
INFO  - 2020-02-18 09:45:10.672; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
WARN  - 2020-02-18 09:45:14.866; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 09:45:35.972; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 09:45:57.177; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 09:46:18.636; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 09:46:40.296; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 09:47:02.160; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 09:47:24.384; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 09:47:46.559; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 09:48:08.526; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 09:48:30.441; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 09:48:52.505; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 09:49:14.522; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 09:49:36.541; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 09:49:58.453; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 09:50:20.570; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 09:50:42.532; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 09:51:04.447; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 09:51:26.362; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 09:51:48.229; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 09:52:10.247; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 09:52:32.266; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 09:52:54.386; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2020-02-18 09:53:12.154; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 09:53:12.161; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-18 09:53:12.162; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 09:53:12.163; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-18 09:53:12.188; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-18 09:53:14.707; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-18 09:53:15.045; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 09:53:15.825; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 09:53:17.774; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 09:53:17.893; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 09:53:17.893; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 09:53:17.899; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 09:53:22.092; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
WARN  - 2020-02-18 09:53:39.238; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
ERROR - 2020-02-18 09:53:44.881; org.springframework.data.elasticsearch.repository.support.AbstractElasticsearchRepository; failed to load elasticsearch nodes : org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes are available: [{#transport#-1}{MfN0wRRzQaSmAjuUUHY2ow}{192.168.198.128}{192.168.198.128:9300}]
INFO  - 2020-02-18 09:53:45.038; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 09:53:45.070; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 30357 ms
INFO  - 2020-02-18 09:53:45.282; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-18 09:53:45.990; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-18 09:53:46.508; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1226 ms
INFO  - 2020-02-18 09:53:51.904; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 09:53:51.908; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-18 09:53:51.910; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 09:53:51.911; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-18 10:26:37.480; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-18 10:26:37.529; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@51cdd8a, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@d44fc21, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@23faf8f2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2d6eabae, org.springframework.test.context.transaction.TransactionalTestExecutionListener@4e7dc304, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@64729b1e]
INFO  - 2020-02-18 10:26:38.103; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 10:26:38.911; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 10:26:40.927; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 10:26:41.998; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 10:26:41.998; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 10:26:42.008; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 10:26:46.574; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
WARN  - 2020-02-18 10:27:03.440; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
ERROR - 2020-02-18 10:27:09.656; org.springframework.data.elasticsearch.repository.support.AbstractElasticsearchRepository; failed to load elasticsearch nodes : org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes are available: [{#transport#-1}{CLDjzZTORyCHZWRT7Gi3HQ}{192.168.198.128}{192.168.198.128:9300}]
INFO  - 2020-02-18 10:27:09.882; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 10:27:10.049; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-18 10:27:10.479; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 10:27:10.484; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-18 10:27:10.486; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 10:27:10.488; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-18 10:27:31.451; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-18 10:30:06.937; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-18 10:30:06.995; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@51cdd8a, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@d44fc21, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@23faf8f2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2d6eabae, org.springframework.test.context.transaction.TransactionalTestExecutionListener@4e7dc304, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@64729b1e]
INFO  - 2020-02-18 10:30:07.941; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 10:30:09.016; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 10:30:11.535; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 10:30:12.535; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 10:30:12.536; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 10:30:12.544; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 10:30:17.112; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-18 10:31:38.510; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-18 10:31:38.569; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@51cdd8a, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@d44fc21, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@23faf8f2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2d6eabae, org.springframework.test.context.transaction.TransactionalTestExecutionListener@4e7dc304, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@64729b1e]
INFO  - 2020-02-18 10:31:39.129; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 10:31:39.890; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 10:31:41.889; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 10:31:42.792; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 10:31:42.792; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 10:31:42.802; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 10:31:47.059; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
WARN  - 2020-02-18 10:32:04.101; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
ERROR - 2020-02-18 10:32:09.976; org.springframework.data.elasticsearch.repository.support.AbstractElasticsearchRepository; failed to load elasticsearch nodes : org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes are available: [{#transport#-1}{vsJYCsqQQuOx0PhmRxQMtw}{192.168.198.128}{192.168.198.128:9300}]
INFO  - 2020-02-18 10:32:10.212; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 10:32:10.376; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-18 10:32:10.842; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 10:32:10.848; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-18 10:32:10.849; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 10:32:10.851; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-18 10:32:31.802; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-18 10:33:37.197; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-18 10:33:37.230; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@51cdd8a, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@d44fc21, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@23faf8f2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2d6eabae, org.springframework.test.context.transaction.TransactionalTestExecutionListener@4e7dc304, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@64729b1e]
INFO  - 2020-02-18 10:33:37.847; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 10:33:38.660; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 10:33:40.627; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 10:33:41.562; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 10:33:41.562; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 10:33:41.570; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 10:33:45.845; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
WARN  - 2020-02-18 10:34:02.931; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
ERROR - 2020-02-18 10:34:08.980; org.springframework.data.elasticsearch.repository.support.AbstractElasticsearchRepository; failed to load elasticsearch nodes : org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes are available: [{#transport#-1}{x1S4HHqPTk6MFCYNV0k1VA}{192.168.198.128}{192.168.198.128:9300}]
INFO  - 2020-02-18 10:34:09.263; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 10:34:09.448; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-18 10:34:09.890; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 10:34:09.894; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-18 10:34:09.895; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 10:34:09.897; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-18 10:34:30.657; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-18 10:36:21.869; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-18 10:36:21.919; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@51cdd8a, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@d44fc21, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@23faf8f2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2d6eabae, org.springframework.test.context.transaction.TransactionalTestExecutionListener@4e7dc304, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@64729b1e]
INFO  - 2020-02-18 10:36:22.479; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 10:36:23.462; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 10:36:25.356; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 10:36:26.260; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 10:36:26.260; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 10:36:26.267; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 10:36:30.749; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
WARN  - 2020-02-18 10:36:47.588; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
ERROR - 2020-02-18 10:36:53.689; org.springframework.data.elasticsearch.repository.support.AbstractElasticsearchRepository; failed to load elasticsearch nodes : org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes are available: [{#transport#-1}{zLxD2UtQQoS6pAitN_IHzw}{192.168.198.128}{192.168.198.128:9300}]
INFO  - 2020-02-18 10:36:53.840; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 10:36:53.926; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 10:36:53.933; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-18 10:36:53.935; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 10:36:53.938; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-18 10:37:32.646; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-18 10:37:32.693; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@51cdd8a, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@d44fc21, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@23faf8f2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2d6eabae, org.springframework.test.context.transaction.TransactionalTestExecutionListener@4e7dc304, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@64729b1e]
INFO  - 2020-02-18 10:37:33.254; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 10:37:34.050; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 10:37:35.933; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 10:37:36.835; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 10:37:36.836; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 10:37:36.843; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 10:37:41.009; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
WARN  - 2020-02-18 10:37:58.139; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
ERROR - 2020-02-18 10:38:03.912; org.springframework.data.elasticsearch.repository.support.AbstractElasticsearchRepository; failed to load elasticsearch nodes : org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes are available: [{#transport#-1}{OJ00dwYxQ0ie5JNM7ndTKw}{192.168.198.128}{192.168.198.128:9300}]
INFO  - 2020-02-18 10:38:04.144; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 10:38:04.297; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-18 10:38:04.719; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 10:38:04.724; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-18 10:38:04.725; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 10:38:04.727; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-18 10:38:24.753; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-18 10:52:31.718; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-18 10:52:32.286; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 10:52:32.874; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 10:52:35.013; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 10:52:35.397; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 10:52:35.398; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 10:52:35.407; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 10:52:39.655; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
WARN  - 2020-02-18 10:52:56.885; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
ERROR - 2020-02-18 10:53:02.709; org.springframework.data.elasticsearch.repository.support.AbstractElasticsearchRepository; failed to load elasticsearch nodes : org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes are available: [{#transport#-1}{oV_WZcpZTlClE2kAZTDWvw}{192.168.198.128}{192.168.198.128:9300}]
INFO  - 2020-02-18 10:53:02.891; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 10:53:02.927; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 31205 ms
INFO  - 2020-02-18 10:53:03.306; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-18 10:53:04.344; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-18 10:53:04.830; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1524 ms
INFO  - 2020-02-18 10:53:05.397; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
WARN  - 2020-02-18 10:53:17.948; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 10:53:39.107; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 10:54:00.313; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 10:54:21.722; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 10:54:43.635; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 10:55:05.806; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 10:55:27.975; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 10:55:49.886; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 10:56:11.800; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 10:56:33.662; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 10:56:55.779; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 10:57:17.698; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 10:57:39.521; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 10:58:01.386; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 10:58:23.400; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 10:58:45.575; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 10:59:07.540; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 10:59:29.456; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 10:59:51.572; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:00:13.538; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:00:35.501; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:00:57.721; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:01:19.747; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:01:41.862; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:02:03.895; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:02:25.865; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:02:47.829; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:03:09.999; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:03:32.065; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:03:54.084; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:04:16.154; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:04:38.020; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:05:00.186; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:05:22.249; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:05:44.221; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:06:06.246; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:06:28.428; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:06:50.393; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:07:12.358; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:07:34.535; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:07:56.716; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:08:18.734; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:08:40.645; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:09:02.862; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:09:25.039; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2020-02-18 11:09:32.653; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 11:09:32.658; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-18 11:09:32.662; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 11:09:32.663; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-18 11:09:51.517; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-18 11:09:54.203; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-18 11:09:54.673; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 11:09:55.452; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 11:09:58.005; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 11:09:58.225; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 11:09:58.226; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 11:09:58.240; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 11:10:02.605; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
WARN  - 2020-02-18 11:10:19.769; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
ERROR - 2020-02-18 11:10:25.709; org.springframework.data.elasticsearch.repository.support.AbstractElasticsearchRepository; failed to load elasticsearch nodes : org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes are available: [{#transport#-1}{skiGJTsNSGG1t3A1FI_QWg}{192.168.198.128}{192.168.198.128:9300}]
INFO  - 2020-02-18 11:10:25.992; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 11:10:26.029; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 31817 ms
INFO  - 2020-02-18 11:10:26.261; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-18 11:10:27.025; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-18 11:10:27.612; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1351 ms
INFO  - 2020-02-18 11:21:21.024; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-18 11:21:21.555; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 11:21:22.337; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 11:21:24.418; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 11:21:24.567; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 11:21:24.568; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 11:21:24.577; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 11:21:28.744; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
WARN  - 2020-02-18 11:21:45.947; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
ERROR - 2020-02-18 11:21:51.566; org.springframework.data.elasticsearch.repository.support.AbstractElasticsearchRepository; failed to load elasticsearch nodes : org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes are available: [{#transport#-1}{YCxQ6BTCTJmJktdIluWe6w}{192.168.198.128}{192.168.198.128:9300}]
INFO  - 2020-02-18 11:21:51.940; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 11:21:51.984; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 30952 ms
INFO  - 2020-02-18 11:21:52.314; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-18 11:21:53.828; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-18 11:21:54.627; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 2313 ms
INFO  - 2020-02-18 11:22:04.227; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
WARN  - 2020-02-18 11:22:07.005; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:22:28.124; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:22:49.340; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:23:10.870; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:23:32.792; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:23:54.911; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:24:16.978; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:24:38.993; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:25:01.011; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2020-02-18 11:25:07.583; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 11:25:07.588; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-18 11:25:07.588; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 11:25:07.589; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-18 11:25:14.438; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-18 11:25:17.469; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-18 11:25:17.862; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 11:25:18.458; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 11:25:20.430; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 11:25:20.549; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 11:25:20.549; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 11:25:20.555; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 11:25:24.117; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
WARN  - 2020-02-18 11:25:41.890; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
ERROR - 2020-02-18 11:25:47.041; org.springframework.data.elasticsearch.repository.support.AbstractElasticsearchRepository; failed to load elasticsearch nodes : org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes are available: [{#transport#-1}{McBhP9cjSGCPMdn0vzUQew}{192.168.198.128}{192.168.198.128:9300}]
INFO  - 2020-02-18 11:25:47.320; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 11:25:47.379; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 29906 ms
INFO  - 2020-02-18 11:25:47.589; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-18 11:25:48.364; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-18 11:25:48.961; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1371 ms
INFO  - 2020-02-18 11:25:59.784; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
WARN  - 2020-02-18 11:26:02.950; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:26:24.059; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:26:45.277; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:27:06.635; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:27:28.547; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:27:50.666; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:28:12.528; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:28:34.547; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:28:56.619; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:29:18.785; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:29:40.748; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2020-02-18 11:29:53.889; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 11:29:53.894; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-18 11:29:53.896; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 11:29:53.897; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-18 11:30:02.788; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-18 11:30:05.617; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-18 11:30:06.102; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 11:30:06.682; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 11:30:09.188; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 11:30:09.326; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 11:30:09.328; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 11:30:09.363; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 11:30:13.432; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
WARN  - 2020-02-18 11:30:30.925; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
ERROR - 2020-02-18 11:30:36.135; org.springframework.data.elasticsearch.repository.support.AbstractElasticsearchRepository; failed to load elasticsearch nodes : org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes are available: [{#transport#-1}{AdXjZb-uToWSCDUf3lOC1w}{192.168.198.128}{192.168.198.128:9300}]
INFO  - 2020-02-18 11:30:36.289; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 11:30:36.320; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 30698 ms
INFO  - 2020-02-18 11:30:36.553; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-18 11:30:37.434; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-18 11:30:38.170; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1617 ms
INFO  - 2020-02-18 11:30:42.224; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
WARN  - 2020-02-18 11:30:52.004; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:31:13.115; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:31:34.324; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:31:55.783; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:32:17.652; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2020-02-18 11:32:38.838; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 11:32:38.841; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-18 11:32:38.843; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 11:32:38.844; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-18 11:32:41.989; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-18 11:32:44.554; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-18 11:32:45.008; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 11:32:45.643; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 11:32:47.879; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 11:32:48.060; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 11:32:48.061; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 11:32:48.084; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 11:32:52.529; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
WARN  - 2020-02-18 11:33:09.950; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
ERROR - 2020-02-18 11:33:15.421; org.springframework.data.elasticsearch.repository.support.AbstractElasticsearchRepository; failed to load elasticsearch nodes : org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes are available: [{#transport#-1}{Pm2CXBrQRGuMHpufsuIWDQ}{192.168.198.128}{192.168.198.128:9300}]
INFO  - 2020-02-18 11:33:15.607; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 11:33:15.665; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 31107 ms
INFO  - 2020-02-18 11:33:15.930; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-18 11:33:16.608; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-18 11:33:17.132; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1202 ms
INFO  - 2020-02-18 11:33:30.818; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
WARN  - 2020-02-18 11:33:31.017; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:33:52.121; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:34:13.333; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:34:34.794; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:34:56.714; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:35:18.782; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2020-02-18 11:35:40.851; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2020-02-18 11:35:50.693; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 11:35:50.696; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-18 11:35:50.697; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 11:35:50.698; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-18 11:35:51.716; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-18 11:35:53.931; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-18 11:35:54.205; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 11:35:54.760; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 11:35:56.359; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 11:35:56.476; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 11:35:56.477; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 11:35:56.484; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 11:36:00.185; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
WARN  - 2020-02-18 11:36:17.812; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
ERROR - 2020-02-18 11:36:23.141; org.springframework.data.elasticsearch.repository.support.AbstractElasticsearchRepository; failed to load elasticsearch nodes : org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes are available: [{#transport#-1}{8PfCjqlZTQ6j_XrxijnQ7A}{192.168.198.128}{192.168.198.128:9300}]
INFO  - 2020-02-18 11:36:23.416; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 11:36:23.455; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 29521 ms
INFO  - 2020-02-18 11:36:23.725; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-18 11:36:24.456; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-18 11:36:24.914; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1189 ms
INFO  - 2020-02-18 11:36:28.585; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 11:36:28.587; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-18 11:36:28.590; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 11:36:28.591; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-18 11:36:47.047; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-18 11:36:47.437; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 11:36:48.075; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 11:36:49.742; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 11:36:49.871; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 11:36:49.871; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 11:36:49.880; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 11:36:54.046; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-18 11:49:29.638; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-18 11:49:30.199; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 11:49:30.812; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 11:49:33.242; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 11:49:33.405; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 11:49:33.406; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 11:49:33.412; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 11:49:37.682; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-18 11:49:40.407; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 11:49:40.477; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 10832 ms
INFO  - 2020-02-18 11:49:41.117; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-18 11:49:42.277; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-18 11:49:42.903; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1785 ms
INFO  - 2020-02-18 11:49:53.251; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
WARN  - 2020-02-18 11:49:54.745; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2020-02-18 11:49:54.886; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-18 11:49:54.899; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-18 11:49:54.905; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-18 11:49:54.907; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-18 11:49:54.907; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-18 11:49:57.125; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 412
INFO  - 2020-02-18 11:49:57.132; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-18 11:49:57.132; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-18 11:50:44.810; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 11:50:44.819; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-18 11:50:44.826; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 11:50:44.828; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-18 11:50:46.383; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-18 11:50:54.080; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-18 11:50:54.675; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 11:50:55.433; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 11:50:57.822; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 11:50:57.952; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 11:50:57.952; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 11:50:57.963; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 11:50:58.366; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-18 11:50:58.382; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-18 11:50:58.392; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-18 11:50:58.393; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-18 11:50:58.393; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-18 11:51:00.220; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 414
INFO  - 2020-02-18 11:51:00.226; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-18 11:51:00.227; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-18 11:51:02.457; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-18 11:51:05.514; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 11:51:05.539; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 11454 ms
INFO  - 2020-02-18 11:51:05.795; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-18 11:51:06.995; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-18 11:51:07.668; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1872 ms
INFO  - 2020-02-18 11:51:17.354; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 11:51:17.364; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-18 11:51:17.366; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 11:51:17.367; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-18 11:51:34.287; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-18 11:51:34.913; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 11:51:35.847; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 11:51:38.130; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 11:51:38.318; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 11:51:38.318; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 11:51:38.332; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 11:51:38.975; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-18 11:51:38.981; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-18 11:51:38.990; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-18 11:51:38.991; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-18 11:51:38.991; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-18 11:51:39.274; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 416
INFO  - 2020-02-18 11:51:39.277; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-18 11:51:39.278; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-18 11:51:44.252; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-18 11:51:48.048; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 11:51:48.120; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 13826 ms
INFO  - 2020-02-18 11:51:48.586; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-18 11:51:49.446; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-18 11:52:32.883; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-18 11:52:33.479; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 11:52:34.120; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 11:52:36.522; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 11:52:36.707; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 11:52:36.708; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 11:52:36.722; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 11:52:37.306; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-18 11:52:37.310; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-18 11:52:37.317; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-18 11:52:37.317; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-18 11:52:37.317; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-18 11:52:39.346; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 418
INFO  - 2020-02-18 11:52:39.348; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-18 11:52:39.348; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-18 11:52:41.046; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-18 11:52:43.785; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 11:52:43.828; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 10937 ms
INFO  - 2020-02-18 11:52:44.125; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-18 11:52:44.915; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-18 11:52:46.401; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 2275 ms
INFO  - 2020-02-18 11:52:47.041; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-18 11:55:41.493; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 11:55:41.502; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-18 11:55:41.504; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 11:55:41.507; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-18 11:55:43.256; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-18 11:55:46.057; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-18 11:55:46.409; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 11:55:47.280; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 11:55:49.637; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 11:55:49.827; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 11:55:49.828; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 11:55:49.838; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 11:55:50.264; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-18 11:55:50.269; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-18 11:55:50.275; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-18 11:55:50.276; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-18 11:55:50.276; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-18 11:55:51.501; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 420
INFO  - 2020-02-18 11:55:51.505; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-18 11:55:51.505; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-18 11:55:54.183; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-18 11:55:56.794; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 11:55:56.852; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 10781 ms
INFO  - 2020-02-18 11:55:57.152; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-18 11:55:58.109; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-18 11:55:59.748; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 2596 ms
INFO  - 2020-02-18 11:56:25.061; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 11:56:25.069; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-18 11:56:25.071; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 11:56:25.072; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-18 11:56:34.136; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-18 11:56:34.674; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 11:56:36.729; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 11:56:39.177; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 11:56:39.380; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 11:56:39.381; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 11:56:39.402; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 11:56:39.878; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-18 11:56:39.883; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-18 11:56:39.892; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-18 11:56:39.894; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-18 11:56:39.895; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-18 11:56:42.799; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 422
INFO  - 2020-02-18 11:56:42.802; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-18 11:56:42.803; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-18 11:56:43.451; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-18 11:56:47.123; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 11:56:47.199; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 13059 ms
INFO  - 2020-02-18 11:56:47.602; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
WARN  - 2020-02-18 11:56:48.225; org.springframework.context.support.AbstractApplicationContext; Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleController': Unsatisfied dependency expressed through method 'getDetail' parameter 0; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'java.lang.Integer' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
ERROR - 2020-02-18 11:56:48.227; org.springframework.web.servlet.FrameworkServlet; Context initialization failed
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleController': Unsatisfied dependency expressed through method 'getDetail' parameter 0; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'java.lang.Integer' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredMethodElement.inject(AutowiredAnnotationBeanPostProcessor.java:676)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:374)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1395)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549)
	at org.springframework.web.servlet.FrameworkServlet.configureAndRefreshWebApplicationContext(FrameworkServlet.java:701)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:667)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:715)
	at org.springframework.web.servlet.FrameworkServlet.initWebApplicationContext(FrameworkServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.initServletBean(FrameworkServlet.java:529)
	at org.springframework.web.servlet.HttpServletBean.init(HttpServletBean.java:169)
	at javax.servlet.GenericServlet.init(GenericServlet.java:244)
	at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:669)
	at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:426)
	at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:760)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:374)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.startWebapp(JettyWebAppContext.java:360)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:785)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:287)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.doStart(JettyWebAppContext.java:428)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo.restartWebApp(JettyRunMojo.java:553)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo$1.onPathWatchEvents(JettyRunMojo.java:405)
	at org.eclipse.jetty.util.PathWatcher.notifyEvents(PathWatcher.java:1366)
	at org.eclipse.jetty.util.PathWatcher.run(PathWatcher.java:1190)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'java.lang.Integer' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.raiseNoMatchingBeanFound(DefaultListableBeanFactory.java:1654)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1213)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1167)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredMethodElement.inject(AutowiredAnnotationBeanPostProcessor.java:668)
	... 36 more
INFO  - 2020-02-18 11:57:54.982; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 11:57:54.991; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-18 11:57:54.992; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 11:57:54.993; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-18 11:58:03.366; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-18 11:58:03.728; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 11:58:04.589; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 11:58:06.676; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 11:58:06.858; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 11:58:06.858; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 11:58:06.868; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 11:58:07.240; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-18 11:58:07.242; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-18 11:58:07.247; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-18 11:58:07.248; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-18 11:58:07.248; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-18 11:58:09.865; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 424
INFO  - 2020-02-18 11:58:09.868; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-18 11:58:09.868; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-18 11:58:10.655; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-18 11:58:13.157; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 11:58:13.214; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 9842 ms
INFO  - 2020-02-18 11:58:13.487; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
WARN  - 2020-02-18 11:58:13.758; org.springframework.context.support.AbstractApplicationContext; Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleController': Unsatisfied dependency expressed through method 'getDetail' parameter 0; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'java.lang.Integer' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
ERROR - 2020-02-18 11:58:13.762; org.springframework.web.servlet.FrameworkServlet; Context initialization failed
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleController': Unsatisfied dependency expressed through method 'getDetail' parameter 0; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'java.lang.Integer' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredMethodElement.inject(AutowiredAnnotationBeanPostProcessor.java:676)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:374)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1395)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549)
	at org.springframework.web.servlet.FrameworkServlet.configureAndRefreshWebApplicationContext(FrameworkServlet.java:701)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:667)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:715)
	at org.springframework.web.servlet.FrameworkServlet.initWebApplicationContext(FrameworkServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.initServletBean(FrameworkServlet.java:529)
	at org.springframework.web.servlet.HttpServletBean.init(HttpServletBean.java:169)
	at javax.servlet.GenericServlet.init(GenericServlet.java:244)
	at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:669)
	at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:426)
	at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:760)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:374)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.startWebapp(JettyWebAppContext.java:360)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:785)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:287)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.doStart(JettyWebAppContext.java:428)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo.restartWebApp(JettyRunMojo.java:553)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo$1.onPathWatchEvents(JettyRunMojo.java:405)
	at org.eclipse.jetty.util.PathWatcher.notifyEvents(PathWatcher.java:1366)
	at org.eclipse.jetty.util.PathWatcher.run(PathWatcher.java:1190)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'java.lang.Integer' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.raiseNoMatchingBeanFound(DefaultListableBeanFactory.java:1654)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1213)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1167)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredMethodElement.inject(AutowiredAnnotationBeanPostProcessor.java:668)
	... 36 more
INFO  - 2020-02-18 11:58:20.136; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 11:58:20.156; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-18 11:58:20.158; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 11:58:20.163; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-18 11:58:38.378; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-18 11:58:38.820; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 11:58:39.539; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 11:58:41.713; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 11:58:41.934; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 11:58:41.935; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 11:58:41.942; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 11:58:42.784; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-18 11:58:42.788; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-18 11:58:42.798; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-18 11:58:42.798; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-18 11:58:42.798; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-18 11:58:44.252; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 426
INFO  - 2020-02-18 11:58:44.254; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-18 11:58:44.254; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-18 11:58:49.658; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-18 11:58:53.096; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 11:58:53.135; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 14751 ms
INFO  - 2020-02-18 11:58:53.392; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
WARN  - 2020-02-18 11:58:53.631; org.springframework.context.support.AbstractApplicationContext; Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleController': Unsatisfied dependency expressed through method 'getDetail' parameter 0; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'java.lang.Integer' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
ERROR - 2020-02-18 11:58:53.634; org.springframework.web.servlet.FrameworkServlet; Context initialization failed
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleController': Unsatisfied dependency expressed through method 'getDetail' parameter 0; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'java.lang.Integer' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredMethodElement.inject(AutowiredAnnotationBeanPostProcessor.java:676)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:374)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1395)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549)
	at org.springframework.web.servlet.FrameworkServlet.configureAndRefreshWebApplicationContext(FrameworkServlet.java:701)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:667)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:715)
	at org.springframework.web.servlet.FrameworkServlet.initWebApplicationContext(FrameworkServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.initServletBean(FrameworkServlet.java:529)
	at org.springframework.web.servlet.HttpServletBean.init(HttpServletBean.java:169)
	at javax.servlet.GenericServlet.init(GenericServlet.java:244)
	at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:669)
	at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:426)
	at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:760)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:374)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.startWebapp(JettyWebAppContext.java:360)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:785)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:287)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.doStart(JettyWebAppContext.java:428)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo.restartWebApp(JettyRunMojo.java:553)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo$1.onPathWatchEvents(JettyRunMojo.java:405)
	at org.eclipse.jetty.util.PathWatcher.notifyEvents(PathWatcher.java:1366)
	at org.eclipse.jetty.util.PathWatcher.run(PathWatcher.java:1190)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'java.lang.Integer' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.raiseNoMatchingBeanFound(DefaultListableBeanFactory.java:1654)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1213)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1167)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredMethodElement.inject(AutowiredAnnotationBeanPostProcessor.java:668)
	... 36 more
INFO  - 2020-02-18 11:59:44.350; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-18 11:59:45.045; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 11:59:45.795; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 11:59:48.577; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 11:59:48.735; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 11:59:48.735; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 11:59:48.746; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 11:59:49.186; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-18 11:59:49.191; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-18 11:59:49.200; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-18 11:59:49.201; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-18 11:59:49.201; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-18 11:59:50.358; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 428
INFO  - 2020-02-18 11:59:50.361; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-18 11:59:50.362; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-18 11:59:53.692; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-18 11:59:56.687; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 11:59:56.750; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 12395 ms
INFO  - 2020-02-18 11:59:57.182; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
WARN  - 2020-02-18 11:59:57.618; org.springframework.context.support.AbstractApplicationContext; Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleController': Unsatisfied dependency expressed through method 'getDetail' parameter 0; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'java.lang.Integer' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
ERROR - 2020-02-18 11:59:57.621; org.springframework.web.servlet.FrameworkServlet; Context initialization failed
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleController': Unsatisfied dependency expressed through method 'getDetail' parameter 0; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'java.lang.Integer' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredMethodElement.inject(AutowiredAnnotationBeanPostProcessor.java:676)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:374)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1395)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549)
	at org.springframework.web.servlet.FrameworkServlet.configureAndRefreshWebApplicationContext(FrameworkServlet.java:701)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:667)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:715)
	at org.springframework.web.servlet.FrameworkServlet.initWebApplicationContext(FrameworkServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.initServletBean(FrameworkServlet.java:529)
	at org.springframework.web.servlet.HttpServletBean.init(HttpServletBean.java:169)
	at javax.servlet.GenericServlet.init(GenericServlet.java:244)
	at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:669)
	at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:426)
	at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:760)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:374)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.startWebapp(JettyWebAppContext.java:360)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:785)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:287)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.doStart(JettyWebAppContext.java:428)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:138)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)
	at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:113)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.doStart(ContextHandlerCollection.java:167)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:138)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)
	at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:113)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:138)
	at org.eclipse.jetty.server.Server.start(Server.java:419)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:108)
	at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:113)
	at org.eclipse.jetty.server.Server.doStart(Server.java:386)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.maven.plugin.AbstractJettyMojo.startJetty(AbstractJettyMojo.java:467)
	at org.eclipse.jetty.maven.plugin.AbstractJettyMojo.execute(AbstractJettyMojo.java:329)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo.execute(JettyRunMojo.java:179)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:210)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:156)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:148)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:117)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:305)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:957)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:289)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:193)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'java.lang.Integer' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.raiseNoMatchingBeanFound(DefaultListableBeanFactory.java:1654)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1213)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1167)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredMethodElement.inject(AutowiredAnnotationBeanPostProcessor.java:668)
	... 71 more
INFO  - 2020-02-18 12:00:25.498; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 12:00:25.513; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-18 12:00:25.518; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 12:00:25.520; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-18 12:00:29.990; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-18 12:00:30.369; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 12:00:31.092; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 12:00:33.056; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 12:00:33.193; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 12:00:33.193; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 12:00:33.207; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 12:00:33.685; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-18 12:00:33.691; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-18 12:00:33.697; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-18 12:00:33.698; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-18 12:00:33.698; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-18 12:00:35.511; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 430
INFO  - 2020-02-18 12:00:35.515; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-18 12:00:35.515; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-18 12:00:37.265; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-18 12:00:39.857; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 12:00:39.888; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 9889 ms
INFO  - 2020-02-18 12:00:40.100; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
WARN  - 2020-02-18 12:00:40.511; org.springframework.context.support.AbstractApplicationContext; Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleController': Unsatisfied dependency expressed through method 'getDetail' parameter 0; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'java.lang.Integer' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
ERROR - 2020-02-18 12:00:40.513; org.springframework.web.servlet.FrameworkServlet; Context initialization failed
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleController': Unsatisfied dependency expressed through method 'getDetail' parameter 0; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'java.lang.Integer' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredMethodElement.inject(AutowiredAnnotationBeanPostProcessor.java:676)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:374)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1395)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549)
	at org.springframework.web.servlet.FrameworkServlet.configureAndRefreshWebApplicationContext(FrameworkServlet.java:701)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:667)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:715)
	at org.springframework.web.servlet.FrameworkServlet.initWebApplicationContext(FrameworkServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.initServletBean(FrameworkServlet.java:529)
	at org.springframework.web.servlet.HttpServletBean.init(HttpServletBean.java:169)
	at javax.servlet.GenericServlet.init(GenericServlet.java:244)
	at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:669)
	at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:426)
	at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:760)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:374)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.startWebapp(JettyWebAppContext.java:360)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:785)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:287)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.doStart(JettyWebAppContext.java:428)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo.restartWebApp(JettyRunMojo.java:553)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo$1.onPathWatchEvents(JettyRunMojo.java:405)
	at org.eclipse.jetty.util.PathWatcher.notifyEvents(PathWatcher.java:1366)
	at org.eclipse.jetty.util.PathWatcher.run(PathWatcher.java:1190)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'java.lang.Integer' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.raiseNoMatchingBeanFound(DefaultListableBeanFactory.java:1654)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1213)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1167)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredMethodElement.inject(AutowiredAnnotationBeanPostProcessor.java:668)
	... 36 more
INFO  - 2020-02-18 12:01:08.817; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 12:01:08.827; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-18 12:01:08.828; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 12:01:08.829; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-18 12:01:12.611; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-18 12:01:13.038; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 12:01:13.594; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 12:01:15.681; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 12:01:15.850; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 12:01:15.851; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 12:01:15.907; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 12:01:16.343; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-18 12:01:16.348; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-18 12:01:16.353; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-18 12:01:16.353; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-18 12:01:16.354; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-18 12:01:17.620; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 432
INFO  - 2020-02-18 12:01:17.622; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-18 12:01:17.623; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-18 12:01:20.174; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-18 12:01:22.692; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 12:01:22.763; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 10149 ms
INFO  - 2020-02-18 12:01:23.023; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
WARN  - 2020-02-18 12:01:23.337; org.springframework.context.support.AbstractApplicationContext; Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleController': Unsatisfied dependency expressed through method 'getDetail' parameter 0; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'java.lang.Integer' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
ERROR - 2020-02-18 12:01:23.338; org.springframework.web.servlet.FrameworkServlet; Context initialization failed
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleController': Unsatisfied dependency expressed through method 'getDetail' parameter 0; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'java.lang.Integer' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredMethodElement.inject(AutowiredAnnotationBeanPostProcessor.java:676)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:374)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1395)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549)
	at org.springframework.web.servlet.FrameworkServlet.configureAndRefreshWebApplicationContext(FrameworkServlet.java:701)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:667)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:715)
	at org.springframework.web.servlet.FrameworkServlet.initWebApplicationContext(FrameworkServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.initServletBean(FrameworkServlet.java:529)
	at org.springframework.web.servlet.HttpServletBean.init(HttpServletBean.java:169)
	at javax.servlet.GenericServlet.init(GenericServlet.java:244)
	at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:669)
	at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:426)
	at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:760)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:374)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.startWebapp(JettyWebAppContext.java:360)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:785)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:287)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.doStart(JettyWebAppContext.java:428)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo.restartWebApp(JettyRunMojo.java:553)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo$1.onPathWatchEvents(JettyRunMojo.java:405)
	at org.eclipse.jetty.util.PathWatcher.notifyEvents(PathWatcher.java:1366)
	at org.eclipse.jetty.util.PathWatcher.run(PathWatcher.java:1190)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'java.lang.Integer' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.raiseNoMatchingBeanFound(DefaultListableBeanFactory.java:1654)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1213)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1167)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredMethodElement.inject(AutowiredAnnotationBeanPostProcessor.java:668)
	... 36 more
INFO  - 2020-02-18 12:02:03.205; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-18 12:02:03.741; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 12:02:04.370; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 12:02:06.978; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 12:02:07.161; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 12:02:07.161; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 12:02:07.169; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 12:02:07.670; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-18 12:02:07.674; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-18 12:02:07.680; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-18 12:02:07.680; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-18 12:02:07.681; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-18 12:02:08.790; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 434
INFO  - 2020-02-18 12:02:08.794; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-18 12:02:08.795; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-18 12:02:11.937; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-18 12:02:14.616; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 12:02:14.668; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 11454 ms
INFO  - 2020-02-18 12:02:14.994; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
WARN  - 2020-02-18 12:02:15.411; org.springframework.context.support.AbstractApplicationContext; Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleController': Unsatisfied dependency expressed through method 'getDetail' parameter 0; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'java.lang.Integer' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
ERROR - 2020-02-18 12:02:15.413; org.springframework.web.servlet.FrameworkServlet; Context initialization failed
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleController': Unsatisfied dependency expressed through method 'getDetail' parameter 0; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'java.lang.Integer' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredMethodElement.inject(AutowiredAnnotationBeanPostProcessor.java:676)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:374)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1395)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549)
	at org.springframework.web.servlet.FrameworkServlet.configureAndRefreshWebApplicationContext(FrameworkServlet.java:701)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:667)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:715)
	at org.springframework.web.servlet.FrameworkServlet.initWebApplicationContext(FrameworkServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.initServletBean(FrameworkServlet.java:529)
	at org.springframework.web.servlet.HttpServletBean.init(HttpServletBean.java:169)
	at javax.servlet.GenericServlet.init(GenericServlet.java:244)
	at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:669)
	at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:426)
	at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:760)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:374)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.startWebapp(JettyWebAppContext.java:360)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:785)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:287)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.doStart(JettyWebAppContext.java:428)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:138)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)
	at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:113)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.doStart(ContextHandlerCollection.java:167)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:138)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)
	at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:113)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:138)
	at org.eclipse.jetty.server.Server.start(Server.java:419)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:108)
	at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:113)
	at org.eclipse.jetty.server.Server.doStart(Server.java:386)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.maven.plugin.AbstractJettyMojo.startJetty(AbstractJettyMojo.java:467)
	at org.eclipse.jetty.maven.plugin.AbstractJettyMojo.execute(AbstractJettyMojo.java:329)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo.execute(JettyRunMojo.java:179)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:210)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:156)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:148)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:117)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:305)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:957)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:289)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:193)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'java.lang.Integer' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.raiseNoMatchingBeanFound(DefaultListableBeanFactory.java:1654)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1213)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1167)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredMethodElement.inject(AutowiredAnnotationBeanPostProcessor.java:668)
	... 71 more
INFO  - 2020-02-18 12:03:01.431; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-18 12:03:02.026; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 12:03:02.818; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 12:03:05.345; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 12:03:05.497; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 12:03:05.498; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 12:03:05.507; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 12:03:05.977; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-18 12:03:05.982; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-18 12:03:05.990; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-18 12:03:05.990; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-18 12:03:05.990; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-18 12:03:08.910; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 436
INFO  - 2020-02-18 12:03:08.913; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-18 12:03:08.914; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-18 12:03:10.280; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-18 12:03:12.887; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 12:03:12.941; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 11503 ms
INFO  - 2020-02-18 12:03:13.231; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
WARN  - 2020-02-18 12:03:13.612; org.springframework.context.support.AbstractApplicationContext; Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleController': Unsatisfied dependency expressed through method 'getDetail' parameter 0; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'java.lang.Integer' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
ERROR - 2020-02-18 12:03:13.614; org.springframework.web.servlet.FrameworkServlet; Context initialization failed
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleController': Unsatisfied dependency expressed through method 'getDetail' parameter 0; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'java.lang.Integer' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredMethodElement.inject(AutowiredAnnotationBeanPostProcessor.java:676)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:374)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1395)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549)
	at org.springframework.web.servlet.FrameworkServlet.configureAndRefreshWebApplicationContext(FrameworkServlet.java:701)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:667)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:715)
	at org.springframework.web.servlet.FrameworkServlet.initWebApplicationContext(FrameworkServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.initServletBean(FrameworkServlet.java:529)
	at org.springframework.web.servlet.HttpServletBean.init(HttpServletBean.java:169)
	at javax.servlet.GenericServlet.init(GenericServlet.java:244)
	at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:669)
	at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:426)
	at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:760)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:374)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.startWebapp(JettyWebAppContext.java:360)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:785)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:287)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.doStart(JettyWebAppContext.java:428)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:138)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)
	at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:113)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.doStart(ContextHandlerCollection.java:167)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:138)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)
	at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:113)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:138)
	at org.eclipse.jetty.server.Server.start(Server.java:419)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:108)
	at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:113)
	at org.eclipse.jetty.server.Server.doStart(Server.java:386)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.maven.plugin.AbstractJettyMojo.startJetty(AbstractJettyMojo.java:467)
	at org.eclipse.jetty.maven.plugin.AbstractJettyMojo.execute(AbstractJettyMojo.java:329)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo.execute(JettyRunMojo.java:179)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:210)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:156)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:148)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:117)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:305)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:957)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:289)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:193)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'java.lang.Integer' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.raiseNoMatchingBeanFound(DefaultListableBeanFactory.java:1654)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1213)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1167)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredMethodElement.inject(AutowiredAnnotationBeanPostProcessor.java:668)
	... 71 more
INFO  - 2020-02-18 12:03:51.236; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 12:03:51.242; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-18 12:03:51.244; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 12:03:51.245; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-18 12:03:56.573; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-18 12:03:56.998; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 12:03:57.717; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 12:03:59.974; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 12:04:00.139; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 12:04:00.140; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 12:04:00.149; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 12:04:01.022; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-18 12:04:01.027; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-18 12:04:01.035; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-18 12:04:01.035; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-18 12:04:01.038; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-18 12:04:04.024; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-18 12:04:07.283; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 12:04:07.321; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 10742 ms
INFO  - 2020-02-18 12:04:07.553; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
WARN  - 2020-02-18 12:04:07.914; org.springframework.context.support.AbstractApplicationContext; Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleController': Unsatisfied dependency expressed through method 'getDetail' parameter 0; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'java.lang.Integer' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
ERROR - 2020-02-18 12:04:07.915; org.springframework.web.servlet.FrameworkServlet; Context initialization failed
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleController': Unsatisfied dependency expressed through method 'getDetail' parameter 0; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'java.lang.Integer' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredMethodElement.inject(AutowiredAnnotationBeanPostProcessor.java:676)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:374)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1395)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549)
	at org.springframework.web.servlet.FrameworkServlet.configureAndRefreshWebApplicationContext(FrameworkServlet.java:701)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:667)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:715)
	at org.springframework.web.servlet.FrameworkServlet.initWebApplicationContext(FrameworkServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.initServletBean(FrameworkServlet.java:529)
	at org.springframework.web.servlet.HttpServletBean.init(HttpServletBean.java:169)
	at javax.servlet.GenericServlet.init(GenericServlet.java:244)
	at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:669)
	at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:426)
	at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:760)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:374)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.startWebapp(JettyWebAppContext.java:360)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:785)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:287)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.doStart(JettyWebAppContext.java:428)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo.restartWebApp(JettyRunMojo.java:553)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo$1.onPathWatchEvents(JettyRunMojo.java:405)
	at org.eclipse.jetty.util.PathWatcher.notifyEvents(PathWatcher.java:1366)
	at org.eclipse.jetty.util.PathWatcher.run(PathWatcher.java:1190)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'java.lang.Integer' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.raiseNoMatchingBeanFound(DefaultListableBeanFactory.java:1654)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1213)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1167)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredMethodElement.inject(AutowiredAnnotationBeanPostProcessor.java:668)
	... 36 more
INFO  - 2020-02-18 12:04:12.430; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 438
INFO  - 2020-02-18 12:04:12.434; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-18 12:04:12.434; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-18 12:04:45.164; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 12:04:45.171; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-18 12:04:45.172; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 12:04:45.172; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-18 12:04:49.619; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-18 12:04:50.085; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 12:04:50.857; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 12:04:53.034; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 12:04:53.135; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 12:04:53.136; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 12:04:53.154; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 12:04:53.478; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-18 12:04:53.485; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-18 12:04:53.498; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-18 12:04:53.499; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-18 12:04:53.499; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-18 12:04:54.539; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 440
INFO  - 2020-02-18 12:04:54.544; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-18 12:04:54.544; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-18 12:04:56.959; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-18 12:04:59.428; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 12:04:59.474; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 9842 ms
INFO  - 2020-02-18 12:04:59.706; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
WARN  - 2020-02-18 12:04:59.983; org.springframework.context.support.AbstractApplicationContext; Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleController': Unsatisfied dependency expressed through method 'getDetail' parameter 0; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'java.lang.Integer' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
ERROR - 2020-02-18 12:04:59.985; org.springframework.web.servlet.FrameworkServlet; Context initialization failed
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleController': Unsatisfied dependency expressed through method 'getDetail' parameter 0; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'java.lang.Integer' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredMethodElement.inject(AutowiredAnnotationBeanPostProcessor.java:676)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:374)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1395)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549)
	at org.springframework.web.servlet.FrameworkServlet.configureAndRefreshWebApplicationContext(FrameworkServlet.java:701)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:667)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:715)
	at org.springframework.web.servlet.FrameworkServlet.initWebApplicationContext(FrameworkServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.initServletBean(FrameworkServlet.java:529)
	at org.springframework.web.servlet.HttpServletBean.init(HttpServletBean.java:169)
	at javax.servlet.GenericServlet.init(GenericServlet.java:244)
	at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:669)
	at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:426)
	at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:760)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:374)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.startWebapp(JettyWebAppContext.java:360)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:785)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:287)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.doStart(JettyWebAppContext.java:428)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo.restartWebApp(JettyRunMojo.java:553)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo$1.onPathWatchEvents(JettyRunMojo.java:405)
	at org.eclipse.jetty.util.PathWatcher.notifyEvents(PathWatcher.java:1366)
	at org.eclipse.jetty.util.PathWatcher.run(PathWatcher.java:1190)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'java.lang.Integer' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.raiseNoMatchingBeanFound(DefaultListableBeanFactory.java:1654)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1213)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1167)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredMethodElement.inject(AutowiredAnnotationBeanPostProcessor.java:668)
	... 36 more
INFO  - 2020-02-18 12:05:39.229; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-18 12:05:39.843; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 12:05:40.642; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 12:05:43.566; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 12:05:43.739; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 12:05:43.740; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 12:05:43.756; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 12:05:44.192; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-18 12:05:44.199; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-18 12:05:44.209; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-18 12:05:44.210; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-18 12:05:44.211; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-18 12:05:45.697; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 442
INFO  - 2020-02-18 12:05:45.703; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-18 12:05:45.703; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-18 12:05:49.234; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-18 12:05:51.845; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 12:05:51.896; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 12658 ms
INFO  - 2020-02-18 12:05:52.221; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
WARN  - 2020-02-18 12:05:52.597; org.springframework.context.support.AbstractApplicationContext; Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleController': Unsatisfied dependency expressed through method 'getDetail' parameter 0; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'java.lang.Integer' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
ERROR - 2020-02-18 12:05:52.599; org.springframework.web.servlet.FrameworkServlet; Context initialization failed
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'articleController': Unsatisfied dependency expressed through method 'getDetail' parameter 0; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'java.lang.Integer' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredMethodElement.inject(AutowiredAnnotationBeanPostProcessor.java:676)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:374)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1395)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549)
	at org.springframework.web.servlet.FrameworkServlet.configureAndRefreshWebApplicationContext(FrameworkServlet.java:701)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:667)
	at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:715)
	at org.springframework.web.servlet.FrameworkServlet.initWebApplicationContext(FrameworkServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.initServletBean(FrameworkServlet.java:529)
	at org.springframework.web.servlet.HttpServletBean.init(HttpServletBean.java:169)
	at javax.servlet.GenericServlet.init(GenericServlet.java:244)
	at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:669)
	at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:426)
	at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:760)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:374)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.startWebapp(JettyWebAppContext.java:360)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:785)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:287)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.maven.plugin.JettyWebAppContext.doStart(JettyWebAppContext.java:428)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:138)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)
	at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:113)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.doStart(ContextHandlerCollection.java:167)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:138)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)
	at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:113)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:138)
	at org.eclipse.jetty.server.Server.start(Server.java:419)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:108)
	at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:113)
	at org.eclipse.jetty.server.Server.doStart(Server.java:386)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.maven.plugin.AbstractJettyMojo.startJetty(AbstractJettyMojo.java:467)
	at org.eclipse.jetty.maven.plugin.AbstractJettyMojo.execute(AbstractJettyMojo.java:329)
	at org.eclipse.jetty.maven.plugin.JettyRunMojo.execute(JettyRunMojo.java:179)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:210)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:156)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:148)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:117)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:305)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:957)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:289)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:193)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'java.lang.Integer' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.raiseNoMatchingBeanFound(DefaultListableBeanFactory.java:1654)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1213)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1167)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredMethodElement.inject(AutowiredAnnotationBeanPostProcessor.java:668)
	... 71 more
INFO  - 2020-02-18 12:09:25.438; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-18 12:09:26.079; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 12:09:26.892; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 12:09:30.244; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 12:09:30.415; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 12:09:30.417; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 12:09:30.433; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 12:09:31.128; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-18 12:09:31.131; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-18 12:09:31.141; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-18 12:09:31.141; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-18 12:09:31.142; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-18 12:09:34.021; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 444
INFO  - 2020-02-18 12:09:34.023; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-18 12:09:34.023; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-18 12:09:35.722; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-18 12:09:39.109; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 12:09:39.140; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 13693 ms
INFO  - 2020-02-18 12:09:39.455; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-18 12:09:41.076; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-18 12:09:41.904; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 2449 ms
INFO  - 2020-02-18 12:10:21.606; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-18 12:15:24.524; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-18 12:15:24.635; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@51cdd8a, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@d44fc21, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@23faf8f2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2d6eabae, org.springframework.test.context.transaction.TransactionalTestExecutionListener@4e7dc304, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@64729b1e]
INFO  - 2020-02-18 12:15:25.328; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 12:15:26.148; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 12:15:28.875; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 12:15:30.019; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 12:15:30.019; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 12:15:30.046; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 12:15:30.612; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-18 12:15:30.614; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-18 12:15:30.620; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-18 12:15:30.621; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-18 12:15:30.621; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-18 12:15:31.102; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Attempt to heartbeat failed since group is rebalancing
INFO  - 2020-02-18 12:15:31.103; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-18 12:15:31.103; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-18 12:15:31.104; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-18 12:15:33.221; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 445
INFO  - 2020-02-18 12:15:33.221; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 445
INFO  - 2020-02-18 12:15:33.222; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-18 12:15:33.223; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-18 12:15:33.225; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-18 12:15:33.225; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-18 12:15:35.119; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-18 12:15:37.723; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 12:15:37.874; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-18 12:15:39.103; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 12:15:39.111; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-18 12:15:39.112; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 12:15:39.113; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-18 12:15:39.224; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Attempt to heartbeat failed since group is rebalancing
INFO  - 2020-02-18 12:15:39.225; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-18 12:15:39.225; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-18 12:15:39.225; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-18 12:15:39.818; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 446
INFO  - 2020-02-18 12:15:39.819; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-18 12:15:39.819; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-18 12:15:40.784; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-18 12:16:17.964; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-18 12:16:18.056; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@51cdd8a, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@d44fc21, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@23faf8f2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2d6eabae, org.springframework.test.context.transaction.TransactionalTestExecutionListener@4e7dc304, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@64729b1e]
INFO  - 2020-02-18 12:16:18.754; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 12:16:19.831; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 12:16:22.373; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 12:16:23.529; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 12:16:23.530; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 12:16:23.551; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 12:16:24.132; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-18 12:16:24.134; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-18 12:16:24.144; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-18 12:16:24.145; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-18 12:16:24.146; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-18 12:16:24.833; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Attempt to heartbeat failed since group is rebalancing
INFO  - 2020-02-18 12:16:24.835; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-18 12:16:24.835; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-18 12:16:24.836; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-18 12:16:24.856; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 447
INFO  - 2020-02-18 12:16:24.857; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-18 12:16:24.857; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-18 12:16:24.859; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 447
INFO  - 2020-02-18 12:16:24.863; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-18 12:16:24.864; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-18 12:16:28.711; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-18 12:16:31.326; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 12:16:31.562; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-18 12:16:32.331; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 12:16:32.340; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-18 12:16:32.343; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 12:16:32.345; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-18 12:16:33.482; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-18 12:16:33.860; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Attempt to heartbeat failed since group is rebalancing
INFO  - 2020-02-18 12:16:33.860; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-18 12:16:33.861; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-18 12:16:33.861; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-18 12:16:33.873; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 448
INFO  - 2020-02-18 12:16:33.873; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-18 12:16:33.874; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-18 12:16:52.933; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-18 12:16:52.994; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@51cdd8a, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@d44fc21, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@23faf8f2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2d6eabae, org.springframework.test.context.transaction.TransactionalTestExecutionListener@4e7dc304, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@64729b1e]
INFO  - 2020-02-18 12:16:53.893; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 12:16:54.945; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 12:16:57.259; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 12:16:58.263; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 12:16:58.264; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 12:16:58.272; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 12:16:58.603; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-18 12:16:58.607; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-18 12:16:58.623; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-18 12:16:58.623; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-18 12:16:58.624; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-18 12:17:00.883; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Attempt to heartbeat failed since group is rebalancing
INFO  - 2020-02-18 12:17:00.884; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-18 12:17:00.884; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-18 12:17:00.884; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-18 12:17:00.896; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 449
INFO  - 2020-02-18 12:17:00.896; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-18 12:17:00.897; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-18 12:17:00.900; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 449
INFO  - 2020-02-18 12:17:00.905; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-18 12:17:00.905; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-18 12:17:03.577; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-18 12:17:06.226; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 12:17:06.338; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 12:17:06.359; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-18 12:17:06.360; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 12:17:06.362; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-18 12:17:06.899; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Attempt to heartbeat failed since group is rebalancing
INFO  - 2020-02-18 12:17:06.900; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-18 12:17:06.900; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-18 12:17:06.901; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-18 12:17:06.910; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 450
INFO  - 2020-02-18 12:17:06.911; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-18 12:17:06.911; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-18 12:17:46.344; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-18 12:17:46.395; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@51cdd8a, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@d44fc21, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@23faf8f2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2d6eabae, org.springframework.test.context.transaction.TransactionalTestExecutionListener@4e7dc304, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@64729b1e]
INFO  - 2020-02-18 12:17:47.144; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 12:17:48.086; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 12:17:50.648; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 12:17:51.640; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 12:17:51.641; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 12:17:51.648; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 12:17:52.046; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-18 12:17:52.052; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-18 12:17:52.067; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-18 12:17:52.067; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-18 12:17:52.068; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-18 12:17:54.978; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 451
INFO  - 2020-02-18 12:17:54.982; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-18 12:17:54.983; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-18 12:17:56.353; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-18 12:17:58.968; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 12:17:59.060; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 12:17:59.071; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-18 12:17:59.073; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 12:17:59.074; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-18 12:18:17.822; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2020-02-18 12:18:17.891; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@51cdd8a, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@d44fc21, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@23faf8f2, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2d6eabae, org.springframework.test.context.transaction.TransactionalTestExecutionListener@4e7dc304, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@64729b1e]
INFO  - 2020-02-18 12:18:18.522; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 12:18:19.639; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 12:18:21.973; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 12:18:22.939; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 12:18:22.940; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 12:18:22.950; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 12:18:23.401; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-18 12:18:23.405; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-18 12:18:23.411; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-18 12:18:23.412; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-18 12:18:23.413; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-18 12:18:25.020; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 453
INFO  - 2020-02-18 12:18:25.023; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [article-0]
INFO  - 2020-02-18 12:18:25.023; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [article-0]
INFO  - 2020-02-18 12:18:27.780; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-18 12:18:30.444; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 12:18:30.691; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-18 12:18:31.191; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 12:18:31.202; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2020-02-18 12:18:31.203; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2020-02-18 12:18:31.204; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2020-02-18 12:18:32.510; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2020-02-18 12:20:09.207; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2020-02-18 12:20:09.726; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2020-02-18 12:20:10.401; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRep' and 'com.yangjinjing.cms.dao.ArticleRep' mapperInterface. Bean already defined with the same name!
INFO  - 2020-02-18 12:20:12.822; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.198.128:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2020-02-18 12:20:13.064; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2020-02-18 12:20:13.065; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2020-02-18 12:20:13.077; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 12:20:13.567; org.apache.kafka.clients.Metadata; Cluster ID: mpWSwi8yR_iy5fWZEWdhPw
INFO  - 2020-02-18 12:20:13.572; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null)
INFO  - 2020-02-18 12:20:13.578; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2020-02-18 12:20:13.578; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2020-02-18 12:20:13.579; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2020-02-18 12:20:16.256; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 455
INFO  - 2020-02-18 12:20:16.258; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2020-02-18 12:20:16.258; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2020-02-18 12:20:17.618; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.198.128:9300
INFO  - 2020-02-18 12:20:20.189; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2020-02-18 12:20:20.230; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 11018 ms
INFO  - 2020-02-18 12:20:20.521; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springmvc'
INFO  - 2020-02-18 12:20:21.386; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2020-02-18 12:20:22.378; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1857 ms
INFO  - 2020-02-18 12:20:36.548; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2020-02-18 12:32:07.378; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.198.128:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
WARN  - 2020-02-18 12:32:47.392; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:33:08.559; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:33:29.777; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:33:51.186; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:34:12.897; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:34:34.861; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:34:56.826; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:35:18.889; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:35:40.850; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:36:03.025; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:36:25.245; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:36:47.360; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:37:09.273; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:37:31.488; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:37:53.552; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:38:15.563; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:38:37.779; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:38:59.690; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:39:21.904; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:39:44.121; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:40:05.980; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:40:27.945; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:40:49.857; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:41:11.873; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:41:33.792; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:41:56.005; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:42:18.068; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:42:40.233; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:43:02.448; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:43:24.410; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:43:46.280; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:44:08.293; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:44:30.214; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:44:52.425; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:45:14.443; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:45:36.354; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:45:58.570; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:46:20.534; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:46:42.597; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:47:04.460; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:47:26.370; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:47:48.534; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:48:10.716; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:48:32.780; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:48:54.994; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:49:17.018; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:49:39.233; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:50:01.196; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:50:23.208; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:50:45.222; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:51:07.236; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:51:29.198; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:51:51.365; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:52:13.380; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:52:35.496; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:52:57.461; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:53:19.588; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:53:41.450; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:54:03.568; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:54:25.582; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:54:47.764; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:55:09.827; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:55:31.689; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:55:53.656; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:56:15.569; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:56:37.683; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:56:59.901; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:57:21.915; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:57:43.774; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:58:05.687; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:58:27.751; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:58:49.766; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:59:11.781; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:59:33.838; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 12:59:55.950; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:00:18.115; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:00:40.028; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:01:02.004; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:01:23.912; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:01:45.825; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:02:07.848; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:02:29.858; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:02:51.872; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:03:13.986; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:03:36.157; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:03:58.223; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:04:20.448; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:04:42.474; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:05:04.589; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:05:26.603; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:05:48.770; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:06:10.735; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:06:32.901; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:06:54.812; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:07:17.028; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:07:39.096; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:08:01.014; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:08:23.026; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:08:45.090; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:09:07.206; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:09:29.068; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:09:50.979; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:10:12.993; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:10:35.109; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:10:57.327; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:11:19.239; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:11:41.452; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:12:03.367; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:12:25.331; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:12:47.545; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:13:09.607; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:13:31.771; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:13:53.784; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:14:15.849; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:14:37.764; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:14:59.829; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:15:21.741; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:15:43.712; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:16:05.777; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:16:27.943; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:16:49.802; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:17:11.824; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:17:33.851; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:17:55.814; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:18:17.828; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:18:40.040; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:19:01.901; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:19:23.866; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:19:45.778; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:20:07.895; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:20:29.807; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:20:51.973; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:21:13.946; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:21:35.806; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:21:57.870; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:22:20.083; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:22:42.251; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:23:04.264; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:23:26.376; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:23:48.189; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:24:10.252; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:24:32.314; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:24:54.376; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:25:16.391; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:25:38.607; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:26:00.467; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:26:22.689; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:26:44.652; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:27:06.466; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:27:28.327; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:27:50.252; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:28:12.375; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:28:34.337; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:28:56.504; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:29:18.716; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:29:40.727; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:30:02.791; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:30:24.652; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:30:46.678; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:31:08.905; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:31:30.967; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:31:53.030; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:32:15.054; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:32:37.170; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:32:59.131; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:33:21.153; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:33:43.016; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:34:05.081; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:34:27.154; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:34:49.078; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:35:10.938; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:35:32.960; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:35:55.133; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:36:17.145; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:36:39.106; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:37:01.129; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:37:23.142; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:37:45.267; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:38:07.130; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:38:29.044; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:38:50.908; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:39:12.769; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:39:34.693; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:39:56.756; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:40:18.869; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:40:41.032; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:41:02.992; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:41:25.108; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:41:47.169; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:42:09.385; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:42:31.499; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:42:53.667; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:43:15.481; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:43:37.597; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:43:59.610; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:44:21.419; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:44:43.533; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:45:05.751; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:45:27.713; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:45:49.876; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:46:12.090; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:46:34.204; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:46:56.169; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:47:18.384; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:47:40.600; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:48:02.471; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:48:24.342; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:48:46.252; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:49:08.464; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:49:30.576; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:49:52.741; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:50:14.601; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:50:36.563; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:50:58.576; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:51:20.591; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:51:42.657; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:52:04.619; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:52:26.685; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:52:48.760; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:53:10.721; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:53:32.584; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:53:54.799; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:54:16.709; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:54:38.877; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:55:01.105; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:55:23.285; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:55:45.257; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:56:07.281; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:56:29.511; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:56:51.370; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:57:13.447; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:57:35.572; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:57:57.534; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:58:19.600; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:58:41.661; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:59:03.533; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:59:25.498; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 13:59:47.518; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:00:09.692; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:00:31.606; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:00:53.420; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:01:15.392; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:01:37.251; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:01:59.214; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:02:21.126; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:02:43.200; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:03:05.314; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:03:27.427; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:03:49.602; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:04:11.679; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:04:33.845; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:04:55.757; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:05:17.618; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:05:39.479; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:06:01.698; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:06:23.671; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:06:45.587; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:07:07.650; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:07:29.824; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:07:51.835; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:08:14.000; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:08:35.915; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:08:57.980; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:09:19.994; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:09:41.805; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:10:03.830; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:10:26.045; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:10:47.957; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:11:09.923; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:11:32.151; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:11:54.318; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:12:16.391; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:12:38.455; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:13:00.421; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:13:22.489; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:13:44.552; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:14:06.463; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:14:28.485; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:14:50.502; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:15:12.566; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:15:34.692; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:15:56.809; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:16:18.925; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:16:40.987; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:17:03.212; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:17:25.379; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:17:47.393; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:18:09.406; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:18:31.571; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:18:53.686; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:19:15.855; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:19:37.764; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:19:59.832; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:20:21.845; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:20:43.955; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:21:05.979; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:21:28.196; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:21:50.163; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:22:12.378; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:22:34.541; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:22:56.351; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:23:18.273; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:23:40.194; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:24:02.208; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:24:24.372; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:24:46.282; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:25:08.195; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:25:30.413; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:25:52.378; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:26:14.239; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:26:36.152; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:26:58.014; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:27:19.876; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:27:41.788; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:28:03.753; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:28:25.720; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:28:47.532; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:29:09.545; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:29:31.456; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:29:53.574; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:30:15.589; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:30:37.501; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:30:59.464; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:31:21.479; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:31:43.389; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:32:05.197; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:32:27.361; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:32:49.477; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:33:11.390; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:33:33.457; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:33:55.318; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:34:17.180; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:34:38.992; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:35:01.069; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:35:22.930; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:35:44.793; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:36:06.961; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:36:29.075; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:36:51.039; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:37:13.254; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:37:35.065; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:37:57.141; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:38:19.254; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:38:41.421; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:39:03.545; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:39:25.559; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:39:47.474; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:40:09.336; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:40:31.551; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:40:53.718; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:41:15.834; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:41:37.948; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:41:59.863; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:42:22.078; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:42:44.191; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:43:06.155; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:43:28.335; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:43:50.198; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:44:12.108; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:44:34.019; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:44:55.882; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:45:17.895; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:45:40.008; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:46:01.971; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:46:23.981; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:46:45.955; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:47:07.869; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:47:30.087; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:47:52.205; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:48:14.217; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:48:36.289; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:48:58.351; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:49:20.567; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:49:42.481; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:50:04.558; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:50:26.470; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:50:48.535; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:51:10.752; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:51:32.963; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:51:54.976; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:52:17.094; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:52:39.059; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:53:01.175; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:53:23.387; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:53:45.552; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:54:07.717; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:54:29.680; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:54:51.746; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:55:13.964; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:55:36.127; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:55:58.037; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:56:20.105; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:56:42.273; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:57:04.387; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:57:26.459; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:57:48.622; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:58:10.484; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:58:32.545; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2020-02-18 14:58:54.559; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
